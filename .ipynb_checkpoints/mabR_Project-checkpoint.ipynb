{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e30ed4-8a0e-4a6f-96eb-dfe116dfb2de",
   "metadata": {},
   "source": [
    "#### Import packages, set directories and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9c6377-5080-4c22-94db-feabe17cc47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from Bio import Entrez, SeqIO, AlignIO, pairwise2, Align, Seq, motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from Comparative_Analysis import Utilities as util\n",
    "from joblib import Parallel, delayed\n",
    "from Comparative_Analysis import Blast_Functions as blastfn\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from scipy.stats import chi2\n",
    "from Comparative_Analysis import Alignment as alignfn\n",
    "from Bio.Align.Applications import MuscleCommandline\n",
    "import subprocess\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c1ca3d-a68f-4a9d-a5c4-25df7385b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'F:/Project_Data/mabR_Project'\n",
    "mycobacteria_seq_dir = 'F:/Datasets/NCBI_Refseq_Mycobacteriaceae_Complete_Annot_20230511/data'\n",
    "actinomycetes_seq_dir = 'F:/Datasets/NCBI_Refseq_Actinomycetes_Complete_Annot_20230511/data'\n",
    "tb_species = 'AL123456.3' \n",
    "tb_annotation_dirname = 'GCA_000195955.2'\n",
    "num_cores = 16\n",
    "core_numbers = list(range(1, num_cores+1))\n",
    "muscle_exe = 'C:/Users/nicho/Muscle/muscle3.8.31_i86win32.exe'\n",
    "full_build = False\n",
    "min_upstream_region_length = 7 \n",
    "min_blast_pct_id = 40\n",
    "min_seq_in_alignment = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "503e82c4-1431-4d17-945f-788c5cc7bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_complement(seq_string):\n",
    "    complement_dict = {'A':'T','C':'G','G':'C','T':'A','N':'N','S':'A','R':'A','Y':'A','K':'A'}    # Note S\n",
    "    temp = []\n",
    "    for char in reversed(seq_string):\n",
    "        temp.append(complement_dict[char])\n",
    "    return ''.join(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee7b780-b0b1-4ada-aa73-94dc320fb8c4",
   "metadata": {},
   "source": [
    "#### Check files where no genomic file downloaded from NCBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a952cd25-6f52-41a8-9bc1-22233f79e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_empty_directories(num_subsets, subset_num, dir_list, seqdir):\n",
    "    temp = util.chunk_list(dir_list, num_subsets, subset_num)\n",
    "    non_empty_dirs = []\n",
    "    for dirname in temp:\n",
    "            if not(os.path.exists(seqdir + '/' + dirname + '/genomic.gbff')):\n",
    "                continue\n",
    "            else:\n",
    "                non_empty_dirs.append(dirname)\n",
    "    return non_empty_dirs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40439141-c290-401a-9644-c3653be333ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycobacteria_dirs = []\n",
    "actinomycetes_dirs = []\n",
    "sequence_dirs = util.list_dirs(mycobacteria_seq_dir)\n",
    "parallel_output = Parallel(n_jobs=-1)(delayed(non_empty_directories)(num_cores, core_number, sequence_dirs, mycobacteria_seq_dir) for core_number in core_numbers)\n",
    "for temp in parallel_output:\n",
    "    for x in temp:\n",
    "        mycobacteria_dirs.append(x) \n",
    "sequence_dirs = util.list_dirs(actinomycetes_seq_dir)\n",
    "parallel_output = Parallel(n_jobs=-1)(delayed(non_empty_directories)(num_cores, core_number, sequence_dirs, actinomycetes_seq_dir) for core_number in core_numbers)\n",
    "for temp in parallel_output:\n",
    "    for x in temp:\n",
    "        actinomycetes_dirs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f27503d-e5a5-41af-9415-4dbcd14444b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(project_dir + '/mycobacteria_dirs.pkl', 'wb') as f:\n",
    "    pickle.dump(mycobacteria_dirs, f) \n",
    "with open(project_dir + '/actinomycetes_dirs.pkl', 'wb') as f:\n",
    "    pickle.dump(actinomycetes_dirs, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9007b6-7093-49cf-ac0d-16e9f86f8b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mycobacteria_dirs),len(actinomycetes_dirs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198ce0ae-2b01-482b-83cb-93c720537916",
   "metadata": {},
   "source": [
    "#### Create files with all CDS for both mycobacteria and actinobacteria reference sets and create BLAST databases for TB CDS and both reference sets (to do reciprocal best hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6068fd3f-1e3d-4bd4-b1ac-ef4c7a190fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_protein_dataset(num_subsets, subset_num, dir_list, seqdir): \n",
    "    sequence_dirs = util.chunk_list(dir_list, num_subsets, subset_num)\n",
    "    all_cds = []\n",
    "    all_tb_cds = []\n",
    "    names = []\n",
    "    sequences = []\n",
    "    locations = []\n",
    "    for dirname in (sequence_dirs):\n",
    "        for genome_record in SeqIO.parse(seqdir + '/' + dirname + '/genomic.gbff', \"genbank\"):\n",
    "            accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "            names.append([accession_ver, genome_record.annotations['organism']])\n",
    "            full_sequence = str(genome_record.seq)\n",
    "            sequences.append([accession_ver, full_sequence])\n",
    "            for feature in genome_record.features:\n",
    "                a = feature.qualifiers\n",
    "                if feature.type == 'CDS' and a.get(\"translation\") != None and a.get(\"locus_tag\") != None:\n",
    "                    locus_tag = a.get(\"locus_tag\")[0]\n",
    "                    accession_locus = accession_ver + '@' + locus_tag\n",
    "                    translation = a.get(\"translation\")[0]\n",
    "                    (start, stop, strand) = (int(feature.location.start), int(feature.location.end), int(feature.location.strand))\n",
    "                    locations.append([accession_locus, (start, stop, strand)])\n",
    "                    all_cds.append([accession_locus, translation])\n",
    "                    if dirname == tb_annotation_dirname:\n",
    "                        all_tb_cds.append([accession_locus, translation])\n",
    "    return (all_cds, all_tb_cds, names, locations, sequences)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e2fbea0-6e4e-46ad-a53c-6475d7e960ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_upstream_sequence_dataset(num_subsets, subset_num, dir_list, seqdir): \n",
    "    sequence_dirs = util.chunk_list(dir_list, num_subsets, subset_num)\n",
    "    upstream_cds_regions = []\n",
    "    for dirname in (sequence_dirs):\n",
    "        all_features = []\n",
    "        cds_features = []\n",
    "        for genome_record in SeqIO.parse(seqdir + '/' + dirname + '/genomic.gbff', \"genbank\"):\n",
    "            accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "            full_sequence = str(genome_record.seq)\n",
    "            len_full_sequence = len(full_sequence)\n",
    "            for feature in genome_record.features:\n",
    "                if feature.type in ['gene', 'source']:\n",
    "                    continue\n",
    "                a = feature.qualifiers\n",
    "                feature_type = feature.type\n",
    "                if a.get(\"locus_tag\") != None:\n",
    "                    locus_tag = a.get(\"locus_tag\")[0]\n",
    "                    accession_locus = accession_ver + '@' + locus_tag\n",
    "                else:\n",
    "                    accession_locus  = ''\n",
    "                (start, stop, strand) = (int(feature.location.start), int(feature.location.end), int(feature.location.strand))\n",
    "                all_features.append([accession_locus, feature_type, start, stop, strand])\n",
    "            \n",
    "            features = cds_features\n",
    "            #features = all_features\n",
    "            # Positive strand upstream \n",
    "\n",
    "            features.sort(key = lambda x: x[2])\n",
    "            max_stop = 0\n",
    "            for (accession_locus, feature_type, start, stop, strand) in features:\n",
    "                if max_stop < start and feature_type == 'CDS' and strand == 1 and start - max_stop < 100000:    #Avoid joins where biopython interprets inconsistently \n",
    "                    upstream_cds_regions.append([accession_locus, max_stop, start, strand, full_sequence[max_stop: start+3]])\n",
    "                max_stop = max(max_stop, stop)\n",
    "            # Negative strand upstream\n",
    "            features.sort(key = lambda x: x[3], reverse = True)\n",
    "            min_start = len(full_sequence)-1\n",
    "            for (accession_locus, feature_type, start, stop, strand) in features:\n",
    "                if stop < min_start and feature_type == 'CDS' and strand == -1 and min_start - stop < 100000:\n",
    "                    upstream_cds_regions.append([accession_locus, stop, min_start, strand, reverse_complement(full_sequence[stop-3: min_start])])\n",
    "                min_start = min(min_start, start)\n",
    "    return (upstream_cds_regions)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbd55c9a-2985-4355-a57b-0c00fa653ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_downstream_sequence_dataset(num_subsets, subset_num, dir_list, seqdir): \n",
    "    sequence_dirs = util.chunk_list(dir_list, num_subsets, subset_num)\n",
    "    downstream_cds_regions = []\n",
    "    for dirname in (sequence_dirs):\n",
    "        all_features = []\n",
    "        cds_features = []\n",
    "        for genome_record in SeqIO.parse(seqdir + '/' + dirname + '/genomic.gbff', \"genbank\"):\n",
    "            accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "            full_sequence = str(genome_record.seq)\n",
    "            len_full_sequence = len(full_sequence)\n",
    "            for feature in genome_record.features:\n",
    "                if feature.type in ['gene', 'source']:\n",
    "                    continue\n",
    "                a = feature.qualifiers\n",
    "                feature_type = feature.type\n",
    "                if a.get(\"locus_tag\") != None:\n",
    "                    locus_tag = a.get(\"locus_tag\")[0]\n",
    "                    accession_locus = accession_ver + '@' + locus_tag\n",
    "                else:\n",
    "                    accession_locus  = ''\n",
    "                (start, stop, strand) = (int(feature.location.start), int(feature.location.end), int(feature.location.strand))\n",
    "                all_features.append([accession_locus, feature_type, start, stop, strand])\n",
    "                if feature_type == 'CDS':\n",
    "                    cds_features.append([accession_locus, feature_type, start, stop, strand])\n",
    "           \n",
    "            features = cds_features\n",
    "            #features = all_features\n",
    "            \n",
    "            #Megative strand downstream\n",
    "            features.sort(key = lambda x: x[2])\n",
    "            max_stop = 0\n",
    "            for (accession_locus, feature_type, start, stop, strand) in features:\n",
    "                if max_stop < start and feature_type == 'CDS' and strand == -1 and start - max_stop < 100000:    #Avoid joins where biopython interprets inconsistently \n",
    "                    downstream_cds_regions.append([accession_locus, max_stop, start, strand, reverse_complement(full_sequence[max_stop: start+3])])\n",
    "                max_stop = max(max_stop, stop)\n",
    "            # Positive strand downstream\n",
    "            features.sort(key = lambda x: x[3], reverse = True)\n",
    "            min_start = len(full_sequence)-1\n",
    "            for (accession_locus, feature_type, start, stop, strand) in features:\n",
    "                if stop < min_start and feature_type == 'CDS' and strand == 1 and min_start - stop < 100000:\n",
    "                    downstream_cds_regions.append([accession_locus, stop, min_start, strand, (full_sequence[stop-3: min_start])])\n",
    "                min_start = min(min_start, start)\n",
    "    return (downstream_cds_regions)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f0742-7686-4b24-808f-787faa247c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if full_build == True:\n",
    "    parallel_output = Parallel(n_jobs=-1)(delayed(generate_protein_dataset)(num_cores, core_number, mycobacteria_dirs, mycobacteria_seq_dir) for core_number in core_numbers)\n",
    "    names_dict_1 = {}\n",
    "    locations_dict_1 = {}\n",
    "    sequence_dict_1 = {}\n",
    "    all_cds_1 = []\n",
    "    all_tb_cds_1 = []\n",
    "    for x in parallel_output:\n",
    "        all_cds_1 += x[0]\n",
    "        all_tb_cds_1 += x[1]\n",
    "        for temp in x[2]:\n",
    "            names_dict_1[temp[0]] = temp[1]\n",
    "        for temp in x[3]:\n",
    "            locations_dict_1[temp[0]] = temp[1]\n",
    "        for temp in x[4]:\n",
    "            sequence_dict_1[temp[0]] = temp[1]\n",
    "    with open(project_dir + '/names_dict_1.pkl', 'wb') as f:\n",
    "            pickle.dump(names_dict_1, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75de3d4-28cf-4873-892c-608a027d57cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if full_build == True:\n",
    "    parallel_output = Parallel(n_jobs=-1)(delayed(generate_protein_dataset)(num_cores, core_number, actinomycetes_dirs, actinomycetes_seq_dir) for core_number in core_numbers)\n",
    "    names_dict_2 = {}\n",
    "    locations_dict_2 = {}\n",
    "    sequence_dict_2 = {}\n",
    "    all_cds_2 = []\n",
    "    all_tb_cds_2 = []\n",
    "    for x in parallel_output:\n",
    "        all_cds_2 += x[0]\n",
    "        all_tb_cds_2 += x[1]\n",
    "        for temp in x[2]:\n",
    "            names_dict_2[temp[0]] = temp[1]\n",
    "        for temp in x[3]:\n",
    "            locations_dict_2[temp[0]] = temp[1]\n",
    "        for temp in x[4]:\n",
    "            sequence_dict_2[temp[0]] = temp[1]\n",
    "    with open(project_dir + '/names_dict_2.pkl', 'wb') as f:\n",
    "            pickle.dump(names_dict_2, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81888d67-09e0-40e4-8508-c0f1ae994c7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cds_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\nicho\\AppData\\Local\\Temp/ipykernel_10248/2361186261.py\", line 23, in generate_upstream_sequence_dataset\nNameError: name 'cds_features' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10248/2711338894.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmycobacteria_upstream_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mactinomycetes_upstream_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mparallel_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_upstream_sequence_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcore_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmycobacteria_dirs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmycobacteria_seq_dir\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcore_number\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcore_numbers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparallel_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Bioinformatics\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Bioinformatics\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[1;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cds_features' is not defined"
     ]
    }
   ],
   "source": [
    "#if full_build == True:\n",
    "if 1==1:\n",
    "    mycobacteria_upstream_dict = {}\n",
    "    actinomycetes_upstream_dict = {}\n",
    "    parallel_output = Parallel(n_jobs=-1)(delayed(generate_upstream_sequence_dataset)(num_cores, core_number, mycobacteria_dirs, mycobacteria_seq_dir) for core_number in core_numbers)\n",
    "    for x in parallel_output:\n",
    "        for n in x:\n",
    "            mycobacteria_upstream_dict[n[0]] = [n[1], n[2], n[3], n[4]]\n",
    "    parallel_output = Parallel(n_jobs=-1)(delayed(generate_upstream_sequence_dataset)(num_cores, core_number, actinomycetes_dirs, actinomycetes_seq_dir) for core_number in core_numbers)\n",
    "    for x in parallel_output:\n",
    "        for n in x:\n",
    "            actinomycetes_upstream_dict[n[0]] = [n[1], n[2], n[3], n[4]]\n",
    "    with open(project_dir + '/mycobacteria_upstream_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(mycobacteria_upstream_dict, f) \n",
    "    with open(project_dir + '/actinomycetes_upstream_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(actinomycetes_upstream_dict, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48c89dc0-6b43-486c-a6c4-e87a39dc2212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f full_build == True:\n",
    "if 1==1:\n",
    "    mycobacteria_downstream_dict = {}\n",
    "    actinomycetes_downstream_dict = {}\n",
    "    parallel_output = Parallel(n_jobs=-1)(delayed(generate_downstream_sequence_dataset)(num_cores, core_number, mycobacteria_dirs, mycobacteria_seq_dir) for core_number in core_numbers)\n",
    "    for x in parallel_output:\n",
    "        for n in x:\n",
    "            mycobacteria_downstream_dict[n[0]] = [n[1], n[2], n[3], n[4]]\n",
    "    parallel_output = Parallel(n_jobs=-1)(delayed(generate_downstream_sequence_dataset)(num_cores, core_number, actinomycetes_dirs, actinomycetes_seq_dir) for core_number in core_numbers)\n",
    "    for x in parallel_output:\n",
    "        for n in x:\n",
    "            actinomycetes_downstream_dict[n[0]] = [n[1], n[2], n[3], n[4]]\n",
    "    with open(project_dir + '/mycobacteria_downstream_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(mycobacteria_downstream_dict, f) \n",
    "    with open(project_dir + '/actinomycetes_downstream_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(actinomycetes_downstream_dict, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e554633f-42d0-40c4-9600-a6f7c8ef17c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if full_build == True:\n",
    "    util.produce_fasta_file(all_cds_1, project_dir + '/mycobacteria_cds.fasta')\n",
    "    util.produce_fasta_file(all_tb_cds_1, project_dir + '/tb_cds.fasta')\n",
    "    util.produce_fasta_file(all_cds_2, project_dir + '/actinomycetes_cds.fasta')\n",
    "    blastfn.build_blast_db(project_dir, 'mycobacteria_cds.fasta', 'Mycobacteria', project_dir + '/BLAST/Mycobacteria')\n",
    "    blastfn.build_blast_db(project_dir, 'tb_cds.fasta', 'all_tb_cds', project_dir + '/BLAST/Tb')\n",
    "    blastfn.build_blast_db(project_dir, 'actinomycetes_cds.fasta', 'Actinomycetes', project_dir + '/BLAST/Actinomycetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64c685a-3fe4-44e0-a045-59504f7ce64c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if full_build == True:\n",
    "    blastfn.run_blastp(project_dir + '/BLAST/Mycobacteria', 'tb_cds.fasta', 'Mycobacteria', 'tb_mycobacteria_hits.csv', e_value = 1e-10)\n",
    "    blastfn.run_blastp(project_dir + '/BLAST/Tb', 'mycobacteria_cds.fasta', 'all_tb_cds', 'mycobacteria_tb_hits.csv', e_value = 1e-10)\n",
    "    a = blastfn.process_blast_output(project_dir + '/BLAST/Mycobacteria/tb_mycobacteria_hits.csv', names_dict_1, top_hit_only = False)\n",
    "    a = a.loc[a.groupby(['query_ref','target_species_name'])['bit_score'].idxmax()]     # Utility top hit method uses accession ver which can differ if multiple sets exist per species in fragmented annotations\n",
    "    b = blastfn.process_blast_output(project_dir + '/BLAST/Tb/mycobacteria_tb_hits.csv', names_dict_1, top_hit_only = False)\n",
    "    b = b.loc[b.groupby(['query_ref','target_species_name'])['bit_score'].idxmax()] \n",
    "    rbh =  blastfn.keep_reciprocal_best_hits(a, b)\n",
    "    rbh.to_csv(project_dir + '/tb_mycobacteria_reciprocal_best_hits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaf6f56-f9f1-4761-a909-bacf02ac47f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if full_build == True:\n",
    "    blastfn.run_blastp(project_dir + '/BLAST/Actinomycetes', 'tb_cds.fasta', 'Actinomycetes', 'tb_actinomycetes_hits.csv', e_value = 1e-10)\n",
    "    blastfn.run_blastp(project_dir + '/BLAST/Tb', 'actinomycetes_cds.fasta', 'all_tb_cds', 'actinomycetes_tb_hits.csv', e_value = 1e-10)\n",
    "    a = blastfn.process_blast_output(project_dir + '/BLAST/Actinomycetes/tb_actinomycetes_hits.csv', names_dict_2, top_hit_only = False)\n",
    "    a = a.loc[a.groupby(['query_ref','target_species_name'])['bit_score'].idxmax()]     # Utility top hit method uses accession ver which can differ if multiple sets exist per species in fragmented annotations\n",
    "    b = blastfn.process_blast_output(project_dir + '/BLAST/Tb/actinomycetes_tb_hits.csv', names_dict_2, top_hit_only = False)\n",
    "    b = b.loc[b.groupby(['query_ref','target_species_name'])['bit_score'].idxmax()] \n",
    "    rbh_2 =  blastfn.keep_reciprocal_best_hits(a, b)\n",
    "    rbh_2.to_csv(project_dir + '/tb_actinomycetes_reciprocal_best_hits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ab102-796e-4af7-a58b-3111e917ea21",
   "metadata": {},
   "source": [
    "#### Function to generate FASTA file containing intergenic regions in orthologous species and run Muscle / R-scape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7452ef50-1879-4ac8-8106-25c89e82a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(full_build == True):\n",
    "    with open(project_dir + '/names_dict_1.pkl', 'rb') as f:\n",
    "        names_dict_1 = pickle.load(f)\n",
    "    with open(project_dir + '/names_dict_2.pkl', 'rb') as f:\n",
    "        names_dict_2 = pickle.load(f)\n",
    "    with open(project_dir + '/mycobacteria_dirs.pkl', 'rb') as f:\n",
    "        mycobacteria_dirs = pickle.load(f) \n",
    "    with open(project_dir + '/actinomycetes_dirs.pkl', 'rb') as f:\n",
    "         actinomycetes_dirs = pickle.load(f)  \n",
    "    with open(project_dir + '/mycobacteria_upstream_dict.pkl', 'rb') as f:\n",
    "        mycobacteria_upstream_dict = pickle.load(f) \n",
    "    with open(project_dir + '/actinomycetes_upstream_dict.pkl', 'rb') as f:\n",
    "        actinomycetes_upstream_dict = pickle.load(f) \n",
    "    with open(project_dir + '/mycobacteria_downstream_dict.pkl', 'rb') as f:\n",
    "        mycobacteria_downstream_dict = pickle.load(f) \n",
    "    with open(project_dir + '/actinomycetes_downstream_dict.pkl', 'rb') as f:\n",
    "        actinomycetes_downstream_dict = pickle.load(f) \n",
    "    tb_mycobacteria_hits = blastfn.process_blast_output(project_dir + '/BLAST/Mycobacteria/tb_mycobacteria_hits.csv', names_dict_1, top_hit_only = False)\n",
    "    tb_mycobacteria_rbh = pd.read_csv(project_dir + '/tb_mycobacteria_reciprocal_best_hits.csv')\n",
    "    tb_actinomycetes_rbh = pd.read_csv(project_dir + '/tb_actinomycetes_reciprocal_best_hits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11c06384-3c27-4a95-ac4c-cfd218c8cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_regions(locus, comparison_type, alignment_type, output_dir): # 1 = mycobacteria, #2 = actinomycetes, 'U'= upstream 'D' = downstream\n",
    "    if comparison_type == 1:\n",
    "        comparison_df = tb_mycobacteria_rbh\n",
    "        name_dict = names_dict_1\n",
    "        prefix = 'mycobacteria'\n",
    "        if alignment_type == 'U':\n",
    "            comparison_dict = mycobacteria_upstream_dict\n",
    "        else:\n",
    "            comparison_dict = mycobacteria_downstream_dict\n",
    "    else:\n",
    "        comparison_df = tb_actinomycetes_rbh\n",
    "        name_dict = names_dict_2\n",
    "        prefix = 'actinomycetes'\n",
    "        if alignment_type == 'U':\n",
    "            comparison_dict = actinomycetes_upstream_dict\n",
    "        else:\n",
    "            comparison_dict = actinomycetes_downstream_dict\n",
    "    intergenic_regions = []\n",
    "    target_locus = tb_species + '@' + locus\n",
    "    hits = comparison_df[comparison_df['query_ref'] == target_locus]\n",
    "    hits = hits[hits['percent_identical_matches'] > min_blast_pct_id]\n",
    "    tb_hit = 0\n",
    "    for i, r in hits.iterrows():\n",
    "        target_ref = r['target_ref']\n",
    "        if target_ref in comparison_dict:\n",
    "            upstream_region = comparison_dict[target_ref][3]\n",
    "            if len(upstream_region) >= min_upstream_region_length + 3:   #Include start codon\n",
    "                if tb_species in target_ref:\n",
    "                    tb_hit = 1\n",
    "                intergenic_regions.append([name_dict[target_ref.split('@')[0]].replace(' ', '_'), upstream_region])\n",
    "    if len(intergenic_regions) >= min_seq_in_alignment and tb_hit == 1:    \n",
    "        results_dir = output_dir + '/' + locus\n",
    "        if not os.path.exists(results_dir):\n",
    "            os.makedirs(results_dir)\n",
    "        util.produce_fasta_file(intergenic_regions, results_dir +'/'+prefix+'_intergenic_regions.fasta')\n",
    "        cline = MuscleCommandline(muscle_exe, input= results_dir +'/'+prefix + '_intergenic_regions.fasta', out = results_dir + '/' + prefix + '_'+locus + '_alignment.fasta')\n",
    "        exception = 0\n",
    "        try:\n",
    "            stdout, stderr = cline()\n",
    "        except Exception as e:\n",
    "            exception == 1\n",
    "        if exception == 0 and comparison_type == 2:\n",
    "            blastfn.convert_fasta_to_stockholm(results_dir, prefix + '_'+locus + '_alignment.fasta', prefix + '_'+locus + '_alignment.sto')\n",
    "            blastfn.run_rscape(results_dir, prefix + '_'+locus + '_alignment.sto', 'rscape_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db8b457a-8470-41de-8b91-31532fe9e447",
   "metadata": {},
   "outputs": [],
   "source": [
    " for genome_record in SeqIO.parse(mycobacteria_seq_dir + '/' + tb_annotation_dirname + '/genomic.gbff', \"genbank\"):\n",
    "            accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "            full_sequence = str(genome_record.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b026b56-274f-4766-bd81-c2dab16bd6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2522230,\n",
       " 2522359,\n",
       " 1,\n",
       " 'GCCAGTTATCCCCAGCGGTGGCTGGTCAACGCGAGGCGCTCCTCGCATGCTCGGACGGTGCCTACCGACGCGCTAACAATTCTCGAGAAGGCCGGCGGGTTCGCCACCACCGCGCAATTGCTCACGGTCATG']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycobacteria_upstream_dict[tb_species + '@' + 'Rv2248']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed2f57fb-93de-43be-a30b-99f2c15c86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "regulation_type_dict = {}\n",
    "downreg_genes = pd.read_excel(project_dir + '/2022-10-02_data_NU_NAs_renamed.xlsx', sheet_name = 'significant genes downregulated')\n",
    "upreg_genes = pd.read_excel(project_dir + '/2022-10-02_data.xlsx', sheet_name = 'significant genes upregulated')\n",
    "gene_list = []\n",
    "for i, r in downreg_genes.iterrows():\n",
    "    gene_list.append(r['Locus'])\n",
    "    regulation_type_dict[r['Locus']] = 'Downregulated'\n",
    "for i, r in upreg_genes.iterrows():\n",
    "    gene_list.append(r['Locus'])\n",
    "    regulation_type_dict[r['Locus']] = 'Upregulated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e32d193-3969-40a2-bd39-0f72b0291f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "gene_list = ['Rv2248']\n",
    "for locus in gene_list:\n",
    "    align_regions(str(locus), 1, 'U', project_dir + '/Intergenic_Regions')\n",
    "    #align_regions(str(locus), 2, 'U', project_dir + '/Intergenic_Regions')\n",
    "    #align_regions(str(locus), 1, 'D', project_dir + '/Downstream_Intergenic_Regions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3556711a-e9b6-4fea-8d6a-6a739ed2b186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:02<00:00, 39.28it/s]\n"
     ]
    }
   ],
   "source": [
    "mave_len = 10\n",
    "id_re = []\n",
    "location_dir = project_dir + '/Downstream_Intergenic_Regions'\n",
    "seq_ids = util.list_dirs(location_dir)\n",
    "out_list = []\n",
    "consensus_dict = {}\n",
    "for id in tqdm(seq_ids):\n",
    "    if os.path.exists(location_dir + '/'+str(id)+ '/mycobacteria_'+str(id) + '_alignment.fasta'):\n",
    "        alignment = util.read_fasta_to_array(location_dir + '/' + str(id)+ '/mycobacteria_'+str(id) + '_alignment.fasta')\n",
    "        sequences_in_alignment = len(alignment[0])\n",
    "        alignment_length = len(alignment[1][0])\n",
    "        for j, name in enumerate(alignment[0]):\n",
    "            if 'H37Rv' in name:\n",
    "                tb_index = j\n",
    "                break\n",
    "        if sequences_in_alignment < min_seq_in_alignment:\n",
    "            continue\n",
    "        upstream_sequences = util.read_fasta_to_array(location_dir + '/' + str(id)+ '/mycobacteria_intergenic_regions.fasta')\n",
    "        for j, name in enumerate(upstream_sequences[0]):\n",
    "            if 'H37Rv' in name:\n",
    "                upstream_tb_index = j\n",
    "                break\n",
    "        pct_identity = []\n",
    "        consensus = []\n",
    "        for i in range(alignment_length):\n",
    "            temp = []\n",
    "            for j in range(sequences_in_alignment):\n",
    "                temp.append(alignment[1][j][i])\n",
    "            match_found = 0\n",
    "            mac_pct_id = 0\n",
    "            for letter in ['A','C','G','T']:\n",
    "                if temp.count(letter) / sequences_in_alignment >= 0.8:\n",
    "                    match_found = 1\n",
    "                    consensus.append(letter)\n",
    "                    break\n",
    "            if match_found == 0:\n",
    "                consensus.append('*')\n",
    "        consensus_dict[id] = consensus    \n",
    "        #print(consensus[410:])\n",
    "        re = (alignfn.relative_entropy(alignment[1]))\n",
    "        mave_re = []\n",
    "        for i in range(len(re[0])-mave_len):\n",
    "            temp = re[0][i:i+mave_len]\n",
    "            mave_re.append(sum(temp)/len(temp))\n",
    "        max_re = -999\n",
    "        max_re_pos = 0\n",
    "        if len(mave_re) == 0:\n",
    "            continue\n",
    "        for i in range(len(re[0])-mave_len):\n",
    "            if mave_re[i] > max_re:\n",
    "                max_re = mave_re[i]\n",
    "                max_re_pos = i\n",
    "        id_re.append([id, max_re, ''.join(consensus_dict[id][max_re_pos: max_re_pos + mave_len]), ''.join(consensus_dict[id]), len(consensus_dict[id]), len([x for x in re[0] if x > 1.9]), \n",
    "                      sequences_in_alignment, upstream_sequences[1][upstream_tb_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7aed19aa-916b-42c5-9bf8-233f84fe8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_entropy_df = pd.DataFrame(id_re, columns = ['Downstream CDS', 'Maximum_Moving_Ave_RE', 'Max_Region_Consensus_Sequence','Full_Consensus','Intergenic_Region_TB_Length','Num_positions_gt_90_ID', 'Num_Seq_in_alignement','TB_Upstream_Sequence'])\n",
    "rel_entropy_df.to_csv(project_dir + '/downstream_rel_entropy_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b06608-912f-4c18-a3ed-ee9698cda756",
   "metadata": {},
   "outputs": [],
   "source": [
    "covarying_pair_dict =  {}\n",
    "seq_ids = util.list_dirs(project_dir +'/Intergenic_Regions')\n",
    "out_list = []\n",
    "for id in seq_ids:\n",
    "    if os.path.exists(project_dir + '/Intergenic_Regions/' + str(id) + '/rscape_.cov'):\n",
    "        with open(project_dir + '/Intergenic_Regions/' + str(id) + '/rscape_.cov', 'r') as f:  \n",
    "            num_pairs = 0\n",
    "            e_values = []\n",
    "            for l in f:\n",
    "                if (not ('#' in l)):\n",
    "                    a = l.split()\n",
    "                    num_pairs +=1\n",
    "            covarying_pair_dict[id] = num_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046fa66-f923-4b9d-954f-2af5c01c78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_info = []\n",
    "for gene_name in gene_list:\n",
    "    intergenic_regions = []\n",
    "    locus = tb_species + '@'+ str(gene_name)\n",
    "    hits = tb_mycobacteria_rbh.query('query_ref == @locus and percent_identical_matches > @min_blast_pct_id')\n",
    "    num_hits_gt_threshold = len(hits)\n",
    "    if gene_name in covarying_pair_dict:\n",
    "        covarying_pairs = covarying_pair_dict[gene_name]\n",
    "    else:\n",
    "        covarying_pairs = 0\n",
    "    tb_hit = 0\n",
    "    for i, r in hits.iterrows():\n",
    "        target_ref = r['target_ref']\n",
    "        if target_ref in mycobacteria_upstream_dict:\n",
    "            upstream_region = mycobacteria_upstream_dict[target_ref][3][:-3]\n",
    "            if len(upstream_region) >= min_upstream_region_length:\n",
    "                if tb_species in target_ref:\n",
    "                    tb_hit = 1\n",
    "                intergenic_regions.append([names_dict_1[target_ref.split('@')[0]].replace(' ', '_'), upstream_region])\n",
    "    if locus in mycobacteria_upstream_dict:\n",
    "        hit_info.append([gene_name, regulation_type_dict[gene_name], num_hits_gt_threshold, len(mycobacteria_upstream_dict[locus][3][:-3]), tb_hit, len(intergenic_regions), covarying_pairs])\n",
    "    else: \n",
    "        hit_info.append([gene_name, regulation_type_dict[gene_name], num_hits_gt_threshold, 0, tb_hit, len(intergenic_regions), covarying_pairs])\n",
    "hit_info_df = pd.DataFrame(hit_info, columns = ['Downstream CDS', 'Regulation type','num_hits', 'tb_upstream_region_length', 'tb_hit', 'num_upstream_regions', 'num_covarying_pairs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81681d72-5bf4-4a5e-8b4c-2b2ba806dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_info_df = hit_info_df.merge(rel_entropy_df, on='Downstream CDS', how='left').fillna('')\n",
    "gene_info_df.to_csv(project_dir +'/significant_gene_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184eb6bd-79dc-4eb7-bc80-5e2aaf6adbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycobacteria_upstream_dict[tb_species + '@'+ 'Rv0752c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f4cae-0ba3-4694-a8c7-0428f6b9d5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
