{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f01790-2228-4b32-96fb-fa57771489a6",
   "metadata": {},
   "source": [
    "##### Files and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f62318d-edb6-46ec-9611-e406c714a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from Bio import Entrez, SeqIO, AlignIO, pairwise2, Align, Seq, motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from scipy.stats import binom\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "from Comparative_Analysis import Sequence_Analysis_Routines as sar\n",
    "from Comparative_Analysis import Utilities as util\n",
    "from Comparative_Analysis import Alignment as align\n",
    "from Comparative_Analysis import Blast_Functions as blastfn\n",
    "import random\n",
    "import copy\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "from Bio.Align.Applications import MuscleCommandline\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21dd4d91-b21d-4033-98c1-161fd933d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'D:/Project_Data/Project_8'\n",
    "datasets_dir = project_dir + '/Datasets'\n",
    "output_dir = project_dir + '/Output'\n",
    "seq_dir = 'D:/Actinobacteria_Ref_Rep_Lev_Complete'\n",
    "all_protein_blast_dir = 'D:/BLAST/actinobacteria_ref_rep_comp_prot'\n",
    "all_protein_blast_db_name = 'actinobacteria_ref_rep_comp_prot'\n",
    "ref_protein_blast_dir = 'D:/BLAST/actinobacteria_ref_rep_comp_prot_ref'\n",
    "ref_protein_blast_db_name = 'actinobacteria_ref_rep_comp_prot_ref'\n",
    "num_cores = 16\n",
    "core_numbers = list(range(1, num_cores+1))\n",
    "reference_species_filename = 'GCF_000195955.2_ASM19595v2_genomic.gbff'\n",
    "reference_species = 'NC_000962.3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5bc3bf7-6338-4020-a9d9-3b823ac8d5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681\n"
     ]
    }
   ],
   "source": [
    "species_list = util.list_files(seq_dir)\n",
    "species_list = [x for x in species_list if '.gbff' in x]    # Exclude other files generated in directory\n",
    "print(len(species_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc6ed8-e104-4d6f-a74d-06074d0c66c0",
   "metadata": {},
   "source": [
    "##### Produce file with all protein sequences in comparison species and reference species used for BLAST database building and searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e71d908-2783-494d-ae8a-0178b02fa349",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ed5ebac-8a96-45cb-bd38-e54b43f02055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_genome(num_subsets, subset_num, id_list):\n",
    "    translator = util.Translator()\n",
    "    ids = util.chunk_list(id_list, num_subsets, subset_num)\n",
    "    temp = []\n",
    "    for id in ids:\n",
    "        temp_1 = []\n",
    "        for genome_record in SeqIO.parse(seq_dir + '/' + id, \"genbank\"):\n",
    "            organism_name = genome_record.annotations['organism']\n",
    "            accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "            organism_accession = organism_name.replace(' ', '_') + '_' + accession_ver\n",
    "\n",
    "            if id == reference_species_filename:\n",
    "                output = []\n",
    "                features = []\n",
    "                genome_record = next(SeqIO.parse(seq_dir + '/' + id, \"genbank\"))\n",
    "                organism_name = genome_record.annotations['organism']\n",
    "                accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "                organism_accession = organism_name.replace(' ', '_') + '_' + accession_ver\n",
    "                full_sequence = str(genome_record.seq)\n",
    "                mycobrowser_df = pd.read_excel(datasets_dir+'/Mycobrowser_Release_4.xlsx')\n",
    "                for i, r in mycobrowser_df.iterrows():\n",
    "                    if r['Feature'] == 'CDS':\n",
    "                        locus_tag = r['Locus']\n",
    "                        accession_locus = accession_ver + '@' + locus_tag\n",
    "                        start = int(r['Start'])-1\n",
    "                        stop = int(r['Stop'])\n",
    "                        if r['Strand'] == '+':\n",
    "                            strand = 1\n",
    "                        else:\n",
    "                            strand = -1\n",
    "                        translation = translator.translate_sequence(full_sequence[start:stop],strand, 0)[:-1]    #Remove stop codon from translation       \n",
    "                        temp_1.append([organism_name, accession_ver, accession_locus, start, stop, strand, translation, locus_tag])     #Mycobrowser is 1-indexed\n",
    "            else:\n",
    "                for feature in genome_record.features:\n",
    "                    a = feature.qualifiers\n",
    "                    if feature.type == 'CDS':\n",
    "                        if a.get(\"locus_tag\")!= None and a.get(\"translation\")!= None:\n",
    "                            locus_tag = a.get(\"locus_tag\")[0]\n",
    "                            accession_locus = accession_ver + '@' + locus_tag\n",
    "                            translation = a.get(\"translation\")[0]\n",
    "                            temp_1.append([organism_name, accession_ver, accession_locus, int(feature.location.start), int(feature.location.end), int(feature.location.strand), translation, locus_tag])\n",
    "            temp.append(temp_1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04107e31-b056-4076-9790-3ab5afaed247",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dict = {}\n",
    "for id in tqdm(species_list):\n",
    "    for genome_record in SeqIO.parse(seq_dir + '/' + id, \"genbank\"):\n",
    "        organism_name = genome_record.annotations['organism']\n",
    "        accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "        if not(accession_ver in names_dict):\n",
    "            names_dict[accession_ver] = organism_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0604e132-36e4-4524-9ac6-ba171c9d5331",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_output = Parallel(n_jobs=-1)(delayed(parse_genome)(num_cores, core_number, species_list) for core_number in core_numbers)\n",
    "temp = [item for sublist in parallel_output for item in sublist]\n",
    "gene_records = [item for sublist in temp for item in sublist]\n",
    "reference_gene_records = [x for x in gene_records if x[1] == reference_species]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f54fa9f-e3ac-4120-8312-0a7f27fbaa1e",
   "metadata": {},
   "source": [
    "##### Produce and pickle dictionary of all genes and locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8de324b-fcbf-4d98-b369-39a6ca6410f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_records.sort(key=lambda x: (x[1],x[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41a5982a-132e-4a2a-8a9b-d4346dbfc55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_info_dict = {}\n",
    "for i, record in enumerate(gene_records):\n",
    "    if record[1] in gene_info_dict:\n",
    "        gene_info_dict[record[1]].append((record[7],record[3], record[4], (record[7], record[5]), (record[7], record[5])))\n",
    "    else:\n",
    "        gene_info_dict[record[1]] = [(record[7],record[3], record[4], (record[7], record[5]), (record[7], record[5]))]\n",
    "    if (i + 1) < len(gene_records):\n",
    "        next_feature = gene_records[i+1]\n",
    "        if next_feature[1] == record[1] and next_feature[3] > record[4]:\n",
    "            gene_info_dict[record[1]].append((record[7] + '_IG', record[4], next_feature[3], (record[7], record[5]), (next_feature[7], next_feature[5])))\n",
    "with open(output_dir + '/gene_info_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(gene_info_dict, f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e3871-0eb5-4692-9c34-a8dc818d837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### protein_records = []\n",
    "for record in gene_records:\n",
    "    protein_records.append([record[2], record[6]])\n",
    "util.produce_fasta_file(protein_records, seq_dir + '/all_proteins.faa')    \n",
    "util.produce_fasta_file(protein_records, ref_protein_blast_dir + '/all_proteins.faa') \n",
    "protein_records = []\n",
    "for record in reference_gene_records:\n",
    "    protein_records.append([record[2], record[6]])\n",
    "util.produce_fasta_file(protein_records, seq_dir + '/reference_proteins.faa')  \n",
    "util.produce_fasta_file(protein_records, all_protein_blast_dir + '/reference_proteins.faa')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d11a15-ee5f-4210-9d4b-4224ac1bdbf5",
   "metadata": {},
   "source": [
    "##### Produce FASTA containing all full sequences (used for HMMER/INFERNAL searches of intergenic regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4523b5-0f16-4ecb-a367-caa47adfca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_sequence_file(num_subsets, subset_num, id_list):\n",
    "    ids = util.chunk_list(id_list, num_subsets, subset_num)\n",
    "    reference_list = []\n",
    "    for species in ids:\n",
    "        for genome_record in SeqIO.parse(seq_dir + '/' + species, \"genbank\"):\n",
    "            feature_info = []\n",
    "            accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "            reference_list.append([accession_ver, str(genome_record.seq)])\n",
    "    return reference_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7866d-43e6-448d-8ae2-7140b418a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    parallel_output = Parallel(n_jobs=-1)(delayed(generate_full_sequence_file)(num_cores, core_number, species_list) for core_number in core_numbers)\n",
    "    temp = [item for sublist in parallel_output for item in sublist]\n",
    "    gene_records = [[item[0], item[1]] for item in temp]\n",
    "    util.produce_fasta_file(gene_records, seq_dir + '/full_sequences.faa') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8e8d9c-f6cb-4d61-85ea-7edde21c7e25",
   "metadata": {},
   "source": [
    "##### Build BLAST database from all protein sequences and run BLAST searches to and from reference set to all species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7ef4a3-ad5b-4ca1-bca2-4be8b76503d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "    blastfn.build_blast_db(seq_dir, 'all_proteins.faa', all_protein_blast_db_name, all_protein_blast_dir, 'prot')\n",
    "    blastfn.build_blast_db(seq_dir, 'reference_proteins.faa', ref_protein_blast_db_name, ref_protein_blast_dir, 'prot')\n",
    "    blastfn.run_blastp(all_protein_blast_dir, 'reference_proteins.faa',  all_protein_blast_db_name, 1e-10)\n",
    "    blastfn.run_blastp(ref_protein_blast_dir, 'all_proteins.faa',  ref_protein_blast_db_name, 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f43ca-932f-4721-b3f1-891966058f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_to_all_best_hits = blastfn.process_blast_output(all_protein_blast_dir+'/hits.csv', output_dir + '/Blast_Output/ref_to_all_best_hits.pkl', names_dict, True)\n",
    "all_to_ref_best_hits = blastfn.process_blast_output(ref_protein_blast_dir+'/hits.csv', output_dir + '/Blast_Output/all_to_ref_best_hits.pkl', names_dict, True)\n",
    "reciprocal_best_hits = blastfn.keep_reciprocal_best_hits(ref_to_all_best_hits, all_to_ref_best_hits, output_dir + '/Blast_Output/reciprocal_best_hits.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561c37b-5e24-4144-bf1c-72691a70e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "#if full_run == False:\n",
    "    with open(output_dir + '/Blast_Output/reciprocal_best_hits.pkl', 'rb') as f:\n",
    "        rbh_results = pickle.load(f)\n",
    "        rbh_results.to_csv(output_dir + '/Blast_Output/reciprocal_best_hits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fedfb3-db14-439a-8c9d-b3339488eda8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
