{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd555e82-b9bd-441f-97e1-2ea88e235609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez, SeqIO, AlignIO, pairwise2, Align, Seq, motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from Comparative_Analysis import Utilities as util\n",
    "from Comparative_Analysis import Sequence_Analysis_Routines as sar\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "from Comparative_Analysis import Alignment as align\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95848924-ea83-44a5-be33-2aa6957f1656",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'D:/Project_Data/Project_6'\n",
    "genome_datasets_dir = project_dir + '/Datasets/NCBI_Datasets'\n",
    "output_dir = project_dir + '/Output'\n",
    "sonic_paranoid_run_name = 'Run_Without_Outgroup'\n",
    "sonic_paranoid_output_loc = output_dir + '/Sonic_Paranoid_Output'\n",
    "ortholog_dir = sonic_paranoid_output_loc + '/runs/' + sonic_paranoid_run_name + '/ortholog_groups'\n",
    "literature_datasets_dir = project_dir + '/Datasets/Data_From_Publications'\n",
    "temp_fileloc = project_dir + '/Temp_Files'\n",
    "reference_species = 'GCF_000195955.2'\n",
    "outgroup_species = 'GCF_000696675.2'\n",
    "NCBIWWW.email = \"nicholas.underhill@sky.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8b9c0c1-8116-483a-9621-e2937e2da681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_fasta(sequence, name, file):\n",
    "    line_length = 60\n",
    "    lines = []\n",
    "    sequence_length = len(sequence)\n",
    "    number_of_lines = math.ceil(sequence_length / line_length)\n",
    "    lines.append(\">\" + name + \"\\n\")\n",
    "    for i in range(number_of_lines):\n",
    "            subsequence = sequence[i*line_length:(i+1)*line_length]\n",
    "            lines.append(subsequence + \"\\n\")\n",
    "    a = ''.join(lines)\n",
    "    with open(file,'w', newline='') as outfile:\n",
    "        outfile.write(''.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9441be0-b139-451a-91b0-c3cdd6bcdf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "codon_dict = {}\n",
    "with open('D:/Project_Data/Project_3/Datasets/Reference_Tables/Standard_Code.txt') as f:\n",
    "    for l in f:\n",
    "        codon_dict[str(l[1:4])] = l[5]\n",
    "        \n",
    "def translate_sequence(input_seq, strand, rf):\n",
    "    output_seq = ''\n",
    "    if strand == 1:\n",
    "        seq = input_seq[rf:]\n",
    "    else:\n",
    "        seq = align.reverse_complement(input_seq)[rf:]\n",
    "    for i in range(0,len(seq)-2,3):\n",
    "        if seq[i:(i+3)] in codon_dict:\n",
    "            output_seq += codon_dict[seq[i:(i+3)]]\n",
    "        else:\n",
    "            output_seq += 'X'\n",
    "    return output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a37ed122-d1e7-4210-9da9-8d2c127471c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = [x for x in util.list_dirs(genome_datasets_dir) if not (x in [reference_species, outgroup_species])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47fbd019-5554-4df0-9cba-395f2d4a8349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42feeebe27e149b5b598bd85fc671e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for id in tqdm(query_list + [reference_species]):\n",
    "    genome_record = next(SeqIO.parse(genome_datasets_dir + '/'+id + '/genomic.gbff', \"genbank\"))\n",
    "    organism_name = genome_record.annotations['organism']\n",
    "    full_sequence = genome_record.seq\n",
    "    write_fasta(str(full_sequence), id, temp_fileloc + '/'+id+'.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f807055c-f8de-413c-a78c-e0d08db6055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==0:\n",
    "    for query_id in tqdm(query_list):\n",
    "        subprocess.run('wsl cd ~; cd mummer4/mummer-4.0.0rc1; promer -p promer '+util.wslname(temp_fileloc + '/'+ reference_species +'.fasta ')+ util.wslname(temp_fileloc + '/'+  query_id +'.fasta ') , shell=True)\n",
    "        temp = subprocess.run('wsl cd ~; cd mummer4/mummer-4.0.0rc1; show-coords -r -k -c -l -L 30 -I 50 -T promer.delta' , shell=True, capture_output=True).stdout.decode('utf-8')\n",
    "        column_names =[ 'S1', 'E1', 'S2', 'E2', 'LEN 1', 'LEN 2', '% IDY', '% SIM', '% STP', 'LEN R', 'LEN Q', 'COV R', 'COV Q', 'FRM_1', 'FRM_2', 'TAGS_1', 'TAGS_2']\n",
    "        temp_df = pd.read_table(StringIO(temp), skiprows=4, index_col=False, header=None, names=column_names)\n",
    "        temp_df.to_csv(project_dir + '/mummer_coords_'+query_id+'_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f85b16-5d93-43a3-816d-96bc670165d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dfs = []\n",
    "for query_id in (query_list):\n",
    "    query_dfs.append(pd.read_csv(project_dir + '/mummer_coords_'+query_id+'_.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ef898d5-7b59-4dfa-9fbc-aaa11edbd064",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_species_len = len(next(SeqIO.parse(genome_datasets_dir + '/'+reference_species + '/genomic.gbff', \"genbank\")).seq)\n",
    "reference_protein_dict = {}\n",
    "genome_record = next(SeqIO.parse(genome_datasets_dir + '/'+reference_species + '/genomic.gbff', \"genbank\"))\n",
    "for feature in genome_record.features:\n",
    "        a = feature.qualifiers\n",
    "        if feature.type == 'CDS':\n",
    "            reference_protein_dict[a.get(\"protein_id\")[0]]= a.get(\"locus_tag\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94e2c65b-a55d-4464-b5fb-010d1acf98cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beff02ec72f04424ad805cce6d78d4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conservation_counts = np.zeros(reference_species_len)\n",
    "for df in tqdm(query_dfs):\n",
    "    for i, r in df.iterrows():\n",
    "        if r.FRM_1 > 0:\n",
    "            start = r.S1\n",
    "            end = r.E1\n",
    "        else:\n",
    "            start = r.E1\n",
    "            end = r.S1\n",
    "        for pos in range(start-1, end):\n",
    "            conservation_counts[pos]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "968ad4a8-d8a4-40f8-8915-3a0a2732e263",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_cds_boundaries = []\n",
    "mycobrowser_df = pd.read_excel(literature_datasets_dir+'/Mycobrowser_Release_4.xlsx')\n",
    "temp = mycobrowser_df[mycobrowser_df['Feature'] == 'CDS'][['Locus','Start','Stop','Strand']]\n",
    "actual_cds_boundaries = []\n",
    "for i, r in temp.iterrows():\n",
    "    if r['Strand'] == '+':\n",
    "        strand = 1\n",
    "    else:\n",
    "        strand = -1\n",
    "    actual_cds_boundaries.append((r['Locus'],r['Start']-1, r['Stop'], strand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b1600e0-eb25-4e0a-adc3-51063d9a2157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75075/75075 [00:03<00:00, 23240.01it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 82.90it/s]\n"
     ]
    }
   ],
   "source": [
    "orthologs = sar.Ortholog_Grouping(ortholog_dir)\n",
    "all_copy_seq_data = sar.Ortholog_Sequence_Dataset(orthologs, genome_datasets_dir, [x for x in util.list_dirs(genome_datasets_dir)], 50, reference_species, single_copy = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "265135f3-5877-4b40-935a-9c2a31949568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_blast(id_list, num_subsets, subset_num):\n",
    "    ids = util.chunk_list(id_list, num_subsets, subset_num)\n",
    "    E_VALUE_THRESH = 0.04\n",
    "    tb_seq = str(next(SeqIO.parse(genome_datasets_dir + '/'+reference_species + '/genomic.gbff', \"genbank\")).seq)\n",
    "    for i in (range(len(ids))):\n",
    "        blast_results_list = []\n",
    "        locus_tag = ids[i][0]\n",
    "        start = ids[i][1]\n",
    "        end = ids[i][2]\n",
    "        strand = ids[i][3]\n",
    "        temp=translate_sequence(tb_seq[start:end],strand,0)\n",
    "        result_handle = NCBIWWW.qblast(\"blastp\", \"nr\", temp[:-1], entrez_query= \"all [filter] NOT(txid77643[ORGN]) AND txid85007[ORGN]\")\n",
    "        blast_record = NCBIXML.read(result_handle)\n",
    "        for alignment in blast_record.alignments:\n",
    "            for hsp in alignment.hsps:\n",
    "                if hsp.expect < E_VALUE_THRESH:\n",
    "                     blast_results_list.append([locus_tag, start, end, strand, alignment.title, alignment.accession, alignment.length, hsp.expect, hsp.identities, hsp.query_start, hsp.query_end, hsp.sbjct_start, hsp.sbjct_end, hsp.strand, hsp.score])\n",
    "        blast_results_TB_genes_df = pd.DataFrame(blast_results_list, columns = [['locus_tag','locus_start','locus_end','locus_strand','title', 'accession', 'length', 'e_value', 'identities', 'query_start', 'query_end', 'subject_start','subject_end','subject_strand', 'score']])\n",
    "        blast_results_TB_genes_df.to_csv(project_dir + '/'+ids[i][0]+'_blast_results_TB_genes_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1778fa0e-eb4a-4839-91a8-76fc9d047eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d4121f0da74bbf8b5fe07156eff0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Error message from NCBI: Entrez Query: all [filter] NOT(txid77643[ORGN]) AND txid85007[ORGN] is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\nicho\\AppData\\Local\\Temp/ipykernel_15856/1422809397.py\", line 12, in run_blast\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\Bio\\Blast\\NCBIWWW.py\", line 208, in qblast\n    rid, rtoe = _parse_qblast_ref_page(handle)\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\Bio\\Blast\\NCBIWWW.py\", line 318, in _parse_qblast_ref_page\n    raise ValueError(\"Error message from NCBI: %s\" % msg)\nValueError: Error message from NCBI: Entrez Query: all [filter] NOT(txid77643[ORGN]) AND txid85007[ORGN] is not supported\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15856/1341741100.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_cores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcore_numbers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_cores\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_blast\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_cds_boundaries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_cores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcore_number\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcore_number\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore_numbers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Bioinformatics\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Bioinformatics\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[1;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error message from NCBI: Entrez Query: all [filter] NOT(txid77643[ORGN]) AND txid85007[ORGN] is not supported"
     ]
    }
   ],
   "source": [
    "num_cores = 16\n",
    "core_numbers = list(range(1, num_cores+1))\n",
    "par = Parallel(n_jobs=-1)(delayed(run_blast)(actual_cds_boundaries, num_cores, core_number) for core_number in tqdm(core_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d95c968-73d9-456c-a506-0fe4bb18860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp[temp.locus_tag == 'Rv3121']\n",
    "group_id = temp_df.iloc[0]['group_id']\n",
    "temp[temp.group_id == group_id]\n",
    "\n",
    "temp = all_copy_seq_data.sequence_data\n",
    "for i in actual_cds_boundaries:\n",
    "    temp_df = temp[temp.locus_tag == i[0]]\n",
    "    if len(temp_df) > 0:\n",
    "        group_id = temp_df.iloc[0]['group_id']\n",
    "        num_orthologs = len(temp[temp.group_id == group_id]) -1\n",
    "    else:\n",
    "        num_orthologs = 0\n",
    "    print(i[0], i[1], i[2], statistics.mean(conservation_counts[i[1]:i[2]]), num_orthologs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2bd52-c388-4ad4-8bac-7cf93e4cf4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.Series(conservation_counts)\n",
    "a=(d.rolling(10000).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620672b3-3528-48e0-80db-1b52c8c69961",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [i for i,v in enumerate(a) if v < 0.5]\n",
    "z =[v for i, v in enumerate(temp) if i > 1 and v - temp[i-1] > 1]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e0fbc9-0a6f-4b71-ab42-c29dce810d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a[200:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a86ea5-5f75-47cd-93f9-bb18b25c5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(conservation_counts[1650000: 1713090])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ae482-fc09-4e03-a72d-9e3a5e33e7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24502e42-d268-4d84-ae2e-a35961e201a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf70969-cb19-45b8-a1f7-5710b38015c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4f9c5f3-be71-477a-85e8-bca799956e6d",
   "metadata": {},
   "source": [
    "##### Read alignments output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe06472-4bcc-4f68-add1-f09f42c4616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = subprocess.run('wsl cd ~; cd mummer4/mummer-4.0.0rc1; show-aligns promer.delta '+id_list[0]+' '+ id_list[1] , shell=True, capture_output=True).stdout.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d8359-4291-41d9-a63f-79acdb567117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alignments_from_ids():\n",
    "    alignments = subprocess.run('wsl cd ~; cd mummer4/mummer-4.0.0rc1; show-aligns promer.delta '+id_list[0]+' '+ id_list[1] , shell=True, capture_output=True).stdout.decode('utf-8')\n",
    "    # Note that no sorting is done by default for the output of `show-aligns`, so we _may_ assume\n",
    "    # that the order of the matches is the same as their order of appearance in the deltafile\n",
    "\n",
    "    # \"Beginning delimiter\" of every alignment in the `show-aligns` output\n",
    "    begin_alignment_regex = '-- BEGIN alignment \\[ (?P<ref_direction>[+\\-])1 (?P<ref_start>[0-9]+) - (?P<ref_end>[0-9]+) \\|' + \\\n",
    "    ' (?P<query_direction>[+\\-])1 (?P<query_start>[0-9]+) - (?P<query_end>[0-9]+) \\]\\n\\n'\n",
    "    # \"End delimiter\" of every alignment in the `show-aligns` output\n",
    "    end_alignment_regex = '\\n\\n--\\s+END alignment \\[ [+\\-]1 [0-9]+ - [0-9]+ \\| [+\\-]1 [0-9]+ - [0-9]+ \\]'\n",
    "\n",
    "    # Goal is to capture everything between the begin alignment strings and the end alignment strings\n",
    "    parse_regex = '(?s)'+begin_alignment_regex+'(?P<alignment_string>.*?)'+end_alignment_regex\n",
    "    # FYI:    have to use (?s) at beginning to ensure '.' will also match new lines\n",
    "    # See:    https://stackoverflow.com/questions/42302482/python-find-a-string-between-two-strings-repeatedly#comment116031644_42302556\n",
    "    parsed_alignments = [match.groupdict() for match in re.finditer(parse_regex, alignments)]   \n",
    "\n",
    "    parsed_alignments = pd.DataFrame(parsed_alignments)\n",
    "\n",
    "    return parsed_alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b852b3-8a31-462d-ac71-ed6d57705bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_alignments_from_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba1bbc2-f3ff-4f5d-917b-bad883d27d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n"
     ]
    }
   ],
   "source": [
    "ct = 0\n",
    "with open('D:/protein.faa', 'r') as f:\n",
    "    for l in f:\n",
    "        if l[0] == '>':\n",
    "            ct+=1\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5351e7-530e-44dc-ab15-04313c13193e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
