{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86772f7a-4290-484b-9e7c-83bf0b69b281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\ete3-3.1.2-py3.7.egg\\ete3\\evol\\parser\\codemlparser.py:221: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\ete3-3.1.2-py3.7.egg\\ete3\\evol\\parser\\codemlparser.py:221: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fft import fft, fftfreq\n",
    "from Bio import Entrez, SeqIO, AlignIO, pairwise2, Align, Seq, motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from scipy.stats import binom\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from Comparative_Analysis import Utilities as util\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from Comparative_Analysis import Blast_Functions as blastfn\n",
    "import time\n",
    "import os\n",
    "import ete3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1988a242-f558-4643-b3a9-27272fa7bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'D:/Project_Data/Project_9'\n",
    "cryptic_input_path = \"F:/Datasets/CRYPTIC_DATA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e4a41b9-51a1-44ba-bee1-86fb6dd6855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dir = 'D:/Project_Data/Project_8/Datasets/Actinobacteria_Ref_Rep_Lev_Complete'\n",
    "tb_species = 'NC_000962.3' \n",
    "tb_genome_filename = 'GCF_000195955.2_ASM19595v2_genomic.gbff'\n",
    "for record in SeqIO.parse(seq_dir + '/' + tb_genome_filename, \"genbank\"):\n",
    "           full_sequence = str(record.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923afa4e-9242-411a-b4b6-047ccff856af",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc4714d-da75-43d2-b95d-670814d3cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    variant_df = pd.read_csv(cryptic_input_path + \"VARIANTS.csv\") \n",
    "    with open(project_dir + '/variant_df.pkl', 'wb') as f:\n",
    "        pickle.dump(variant_df[['UNIQUEID', 'VARIANT', 'MUTATION_TYPE', 'IS_NULL', 'IS_HET', 'IS_FILTER_PASS', 'IS_SNP', 'REF', 'ALT', 'GENOME_INDEX']], f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c1db5f4-decb-4b01-8de1-d19cf23eaac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    variant_dict = {}\n",
    "    for i, r in variant_df.iterrows():\n",
    "         if r['IS_NULL'] == False and r['IS_FILTER_PASS'] == True and r['IS_HET'] == False and r['IS_SNP'] == True :\n",
    "            if r['UNIQUEID'] in variant_dict:\n",
    "                temp = (variant_dict[r['UNIQUEID']])\n",
    "                variant_dict[r['UNIQUEID']].append(r['VARIANT'])\n",
    "            else:\n",
    "                variant_dict[r['UNIQUEID']] = [r['VARIANT']]\n",
    "    with open(project_dir + '/cryptic_variant_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(variant_dict, f) \n",
    "else:\n",
    "    with open(project_dir + '/cryptic_variant_dict.pkl', 'rb') as f:\n",
    "        variant_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92cdce30-8d0e-4f5d-952d-018557c988e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    with open(project_dir + '/variant_df.pkl', 'rb') as f:\n",
    "        variant_df = pickle.load(f) \n",
    "    position_dict = {}\n",
    "    for i, r in variant_df.iterrows():\n",
    "         if r['IS_NULL'] == False and r['IS_FILTER_PASS'] == True and r['IS_HET'] == False and r['IS_SNP'] == True :\n",
    "            if r['GENOME_INDEX'] in position_dict:\n",
    "                position_dict[r['GENOME_INDEX']].append((r['UNIQUEID'], r['ALT']))\n",
    "            else:\n",
    "                position_dict[r['GENOME_INDEX']] = [r['REF'], (r['UNIQUEID'], r['ALT'])]\n",
    "    with open(project_dir + '/cryptic_position_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(position_dict, f) \n",
    "else:\n",
    "    with open(project_dir + '/cryptic_position_dict.pkl', 'rb') as f:\n",
    "        position_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de1b60a5-3ebc-4094-9020-6c2500cfff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dict = {}\n",
    "for i, (k, v) in enumerate(variant_dict.items()):\n",
    "    id_dict[k] = i\n",
    "fast_position_dict = {}\n",
    "for i, (k, v) in enumerate(position_dict.items()):\n",
    "    temp = set([id_dict[x[0]] for x in v[1:]])\n",
    "    if len(temp) >= 50:     # Exclude small SNPs\n",
    "        fast_position_dict[k] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85db383d-032d-4d8c-bf96-f6fc0915f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tree(species_to_split, position):\n",
    "    temp = fast_position_dict[position].intersection(species_to_split)\n",
    "    temp_2 = species_to_split - temp\n",
    "    if len(temp_2) > 1 and len(temp) > 1:\n",
    "        return ([(position, temp, len(temp)), (position, temp_2, len(temp_2))])\n",
    "    else:\n",
    "        return([(-1, species_to_split, len(species_to_split))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83bcd536-db90-4e91-b296-15599eab0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_split_position(species_to_split_list):\n",
    "    best_split_num = 1e20\n",
    "    best_position = 0\n",
    "\n",
    "    for k, v in fast_position_dict.items():\n",
    "        mutation_count = 0\n",
    "        for species_to_split in species_to_split_list:\n",
    "            num_species_to_split = len(species_to_split)\n",
    "            optimal_split = int(num_species_to_split/2)\n",
    "            mutation_count += abs(len(v.intersection(species_to_split)) - optimal_split)\n",
    "       \n",
    "        if abs(mutation_count) < abs(best_split_num):\n",
    "            best_position = k\n",
    "            best_split_num = abs(mutation_count)\n",
    "          \n",
    "    return(best_position, best_split_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8802c47a-ab72-4f05-bcd2-26a6701c8c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(836658, 38166), (836658, 39414)]\n",
      "1 4.15625 1327\n",
      "2 5.015625 7045\n",
      "3 7.15625 16920\n",
      "4 10.75 18956\n",
      "5 15.09375 19515\n",
      "6 22.640625 21145\n",
      "7 31.890625 21594\n",
      "8 44.984375 23025\n",
      "9 64.21875 24206\n",
      "10 84.953125 25675\n",
      "11 110.125 26218\n"
     ]
    }
   ],
   "source": [
    "all_species = [[-1,set(x for x in range(len(id_dict))),99,True]]\n",
    "pos = optimal_split_position([x[1] for x in all_species])[0]\n",
    "split_results = [split_tree(all_species[0][1], pos)]\n",
    "print( [(x[0], x[2]) for x in split_results[0]] )\n",
    "for i in range(1,12):\n",
    "    start = time.process_time()\n",
    "    split_results.append([])\n",
    "    posn = optimal_split_position([x[1] for x in split_results[i-1]])\n",
    "    pos= posn[0]\n",
    "    split_score = posn[1]\n",
    "    successful_splits = 0\n",
    "    for x in split_results[i-1]:\n",
    "        temp = split_tree(x[1], pos) \n",
    "        if len(temp) == 1:\n",
    "            split_results[i].append(temp[0])\n",
    "        else:\n",
    "            successful_splits +=1\n",
    "            split_results[i].append(temp[0])\n",
    "            split_results[i].append(temp[1])\n",
    "    print(i, time.process_time() - start, split_score)\n",
    "    if successful_splits == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7b4cd57d-ec97-4cd8-a443-b48a16127802",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for res in split_results:\n",
    "    for info in res:\n",
    "        temp.append(info[0])\n",
    "snps = set(temp)\n",
    "snps.remove(-1)\n",
    "len(snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "17ff3188-cb38-4070-abbc-50609a68cc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76952/76952 [00:00<00:00, 742682.32it/s]\n",
      "100%|██████████| 2295/2295 [00:00<00:00, 756755.32it/s]\n"
     ]
    }
   ],
   "source": [
    "sequence_dict = {}\n",
    "sequence_dict_2 = {}\n",
    "for i in snps: \n",
    "    if i in fast_position_dict:\n",
    "        for (name, alt) in position_dict[i][1:]:\n",
    "            name2 = 'seq_'+ str(id_dict[name])\n",
    "            if name2 in sequence_dict:\n",
    "                sequence_dict[name2].append((i, alt.upper()))\n",
    "            else:\n",
    "                sequence_dict[name2] = [(i, alt.upper())]\n",
    "\n",
    "temp = []\n",
    "for key, val in sequence_dict.items():\n",
    "    if val not in temp:\n",
    "        temp.append(val)\n",
    "        sequence_dict_2[key] = val           \n",
    "                \n",
    "sequences = []\n",
    "for k, v in sequence_dict.items():\n",
    "    sequence = []\n",
    "    for i in snps: \n",
    "        sequence.append(full_sequence[i-1])\n",
    "        for (pos, alt) in v:\n",
    "            if pos == i:\n",
    "                sequence[-1:] = alt\n",
    "    sequences.append([k, ''.join(sequence)])\n",
    "    \n",
    "util.produce_fasta_file(sequences, project_dir + '/' + 'tb_variants.faa')\n",
    "\n",
    "sequences = []\n",
    "for k, v in sequence_dict_2.items():\n",
    "    sequence = []\n",
    "    for i in snps: \n",
    "        sequence.append(full_sequence[i-1])\n",
    "        for (pos, alt) in v:\n",
    "            if pos == i:\n",
    "                sequence[-1:] = alt\n",
    "    sequences.append([k, ''.join(sequence)])\n",
    "util.produce_fasta_file(sequences, project_dir + '/' + 'distinct_tb_variants.faa')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "18e8d174-3c39-4bbb-94f4-f25f018319bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_tree = ete3.Tree(project_dir + '/' + 'distinct_tb_variants.faa.treefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e5c48609-83b4-4070-a28a-c459419fa3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_dict = {}\n",
    "\n",
    "for i in range(6000,7000): \n",
    "    if i in fast_position_dict:\n",
    "        for (name, alt) in position_dict[i][1:]:\n",
    "            name2 = 'seq_'+ str(id_dict[name])\n",
    "            if name2 in sequence_dict:\n",
    "                sequence_dict[name2].append((i, alt.upper()))\n",
    "            else:\n",
    "                sequence_dict[name2] = [(i, alt.upper())]\n",
    "\n",
    "sequence_to_score_dict = {}\n",
    "for k, v in sequence_dict.items():\n",
    "    if k in sequence_dict_2:\n",
    "        sequence = []\n",
    "        for i in range(6000,7000): \n",
    "            sequence.append(full_sequence[i-1])\n",
    "            for (pos, alt) in v:\n",
    "                if pos == i:\n",
    "                    sequence[-1:] = alt\n",
    "        sequence_to_score_dict[k] = [{i} for i in ''.join(sequence)]  \n",
    "\n",
    "for k, v in sequence_dict_2.items():\n",
    "    if not(k in sequence_to_score_dict):\n",
    "        sequence_to_score_dict[k] = [{i} for i in full_sequence[5999:6999]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ffcefd8e-2fb0-4214-bfdf-b9d5a0545a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitch_1(list_1, list_2):\n",
    "    res =[]\n",
    "    for i, j in zip(list_1, list_2):\n",
    "        a = i.intersection(j)\n",
    "        if len(a) == 0:\n",
    "            a = i.union(j)\n",
    "        res.append(a)\n",
    "    return res\n",
    "\n",
    "def fitch_2(parent_list, child_list):\n",
    "    res = []\n",
    "    mutations = []\n",
    "    for i, j in zip(parent_list, child_list):\n",
    "        mutation = 0\n",
    "        a = i.intersection(j)\n",
    "        if len(a) == 0:\n",
    "            a = set(list(j)[0])\n",
    "            mutation = 1\n",
    "        res.append(a)\n",
    "        if mutation == 1:\n",
    "            mutations.append(1)\n",
    "        else:\n",
    "            mutations.append(0)\n",
    "    return (res, mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "255245fd-16b1-4913-aaf3-57b1c6b02d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in master_tree.traverse(\"postorder\"):\n",
    "    if node.is_leaf():\n",
    "        node.add_features(seq = sequence_to_score_dict[node.name])\n",
    "    else:\n",
    "        children = node.children\n",
    "        node.add_features(seq = fitch_1(children[0].seq, children[1].seq))\n",
    "for k, v in sequence_to_score_dict.items():              \n",
    "    seq_length = len(v)\n",
    "    break\n",
    "\n",
    "mutation_counts = [0 for i in range(seq_length)]\n",
    "for node in master_tree.traverse(\"preorder\"):\n",
    "    if node.is_leaf():\n",
    "        continue\n",
    "    if node.is_root():\n",
    "        node.seq = [{list(x)[0]} for x in node.seq]\n",
    "    children = node.children\n",
    "    mutations = []\n",
    "    for child in children:\n",
    "        (temp_1, temp_2) = fitch_2(node.seq ,child.seq)\n",
    "        child.seq = temp_1\n",
    "        mutations.append(temp_2)\n",
    "    temp = []\n",
    "    for h, i, j in zip(mutation_counts, mutations[0], mutations[1]):\n",
    "        temp.append(h+max(i, j))\n",
    "    mutation_counts = temp        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f94efc2d-a461-4d64-9d4a-18c7ff2b9762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 13,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 125,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 37,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 33,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 22,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 46,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutation_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecbc6f7-3edb-41a1-8339-996b4f6ab6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "blastfn.run_rscape(project_dir, 'Rvnt30.sto', 'rscape_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5c2e2-62c6-4a66-af98-549faca23681",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "start = 0\n",
    "best = 0\n",
    "for i in range(1,4000000):\n",
    "    if not (i in position_dict):\n",
    "        tot+=1\n",
    "        if start == 0:\n",
    "            start = i\n",
    "    else:\n",
    "        if tot > best:\n",
    "            best = tot\n",
    "            print(\"new best\", best, start, i-1)\n",
    "        start = 0\n",
    "        tot = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71beaedc-0e91-4295-8563-e7b1b777e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(a), len(b), len(a.symmetric_difference(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424696fe-df61-40da-a6c6-9d630689938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a.intersection(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8853e9fd-203c-4b01-a60e-6d6b2af56c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.zeros((len(variant_dict), 1))\n",
    "for i, (k, v) in enumerate(variant_dict.items()):\n",
    "    if i == 2:\n",
    "        a = set(v)\n",
    "    b = set(v)\n",
    "    distances[i, 0] = len(a.symmetric_difference(b))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbff43e2-1ec9-48c8-976c-b61c1a071199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b2b90-fff4-4020-9eb2-d860c3e5eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(project_dir + '/variant_df.pkl', 'rb') as f:\n",
    "    variant_df = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99244d80-a486-482c-896e-3cda66e62601",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507660db-095b-4efb-b985-c5c67596edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in variant_df.iterrows():\n",
    "    print(r)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ddf791-0afd-4566-bd95-6d722bbe53fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in variant_df.iterrows():\n",
    "    if '1416523g>x' == r['VARIANT']:\n",
    "        print(r)\n",
    "        if not(math.isnan(r['MUTATION_TYPE'])):\n",
    "            print(\"Hello\")\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5827cf3b-fb0a-40f5-a355-a030a7be60cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_formula(max_bin_counts, tot_bin_counts, in_frame = False):\n",
    "    successes = 0\n",
    "    if in_frame == False:\n",
    "        for i in range(10000):\n",
    "            a = np.random.default_rng().multinomial(tot_bin_counts, np.array([1/3, 1/3, 1/3]), size=None)\n",
    "            if max(a) >= max_bin_counts:\n",
    "                successes +=1\n",
    "    else:\n",
    "        for i in range(10000):\n",
    "            a = np.random.default_rng().multinomial(tot_bin_counts, np.array([1/3, 1/3, 1/3]), size=None)\n",
    "            if a[0] >= max_bin_counts:\n",
    "                successes +=1\n",
    "    return successes / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5039c6-3aa8-48cb-9790-5320e4da3887",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_boundaries = []\n",
    "for feature in genome_record.features:\n",
    "\n",
    "        if feature.type == 'CDS':\n",
    "            a = feature.qualifiers  \n",
    "            cds_boundaries.append((a.get(\"locus_tag\")[0], int(feature.location.start), int(feature.location.end)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa605aae-67ab-4128-a6d4-af06c5d05155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_bin_probability(start, end, strand, in_frame = False):\n",
    "    mutations = []\n",
    "    for i in range(start,end):\n",
    "        for letter in ['a','c','g','t']:\n",
    "            if (i+1, 'SNP', letter) in variant_count_dict:        #Variant count dictionary positions are one indexed\n",
    "                mutations.append(i)\n",
    "    bin_counts =[0,0,0]\n",
    "    for m in mutations:\n",
    "        if strand == 1:\n",
    "            bin_counts[(m-(start))%3] +=1\n",
    "        else:\n",
    "            bin_counts[((end-1)-m)%3] +=1\n",
    "    #return (((1-binom.cdf(max(bin_counts),sum(bin_counts),1/3))*3)\n",
    "    if in_frame == False:\n",
    "        return (bin_formula(max(bin_counts), sum(bin_counts), in_frame), sum(bin_counts), bin_counts)  \n",
    "    else:\n",
    "        return (bin_formula(bin_counts[2], sum(bin_counts), in_frame), sum(bin_counts), bin_counts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270613b5-f7fd-46fa-8de3-bcf64f1eef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_changes(start, end, strand):\n",
    "    important_mutations = 0\n",
    "    all_mutations = 0\n",
    "    if strand == 1:\n",
    "        for letter in ['a','c','g','t']:\n",
    "            if (start + 2, 'SNP', letter) in variant_count_dict:    #one indexed dictionary\n",
    "                important_mutations+=(variant_count_dict[(start + 2, 'SNP', letter)])\n",
    "            if (start + 3, 'SNP', letter) in variant_count_dict:\n",
    "                important_mutations+=(variant_count_dict[(start + 3, 'SNP', letter)]) \n",
    "    else:\n",
    "        for letter in ['a','c','g','t']:\n",
    "            if (end - 1, 'SNP', letter) in variant_count_dict:\n",
    "                important_mutations+=(variant_count_dict[(end-1, 'SNP', letter)])\n",
    "            if (end - 2, 'SNP', letter) in variant_count_dict:\n",
    "                important_mutations+=(variant_count_dict[(end-2, 'SNP', letter)]) \n",
    "    for i in range(start, end):\n",
    "        for letter in ['a','c','g','t']:\n",
    "            if (i+1, 'SNP', letter) in variant_count_dict:        #Variant count dictionary positions are one indexed\n",
    "                all_mutations+=variant_count_dict[(i+1, 'SNP', letter)]\n",
    "    return (important_mutations, all_mutations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a90ec-4502-4910-9863-ba9de588a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cds_probs(num_subsets, subset_num, boundaries):\n",
    "    cds_boundaries = util.chunk_list(boundaries, num_subsets, subset_num)\n",
    "    probs = []\n",
    "    lens = []\n",
    "    no_mutations = []\n",
    "    for (loc_name,x,y) in cds_boundaries:\n",
    "        (temp, num_mutations) = mutation_bin_probability(x, y)\n",
    "        if num_mutations > 0:\n",
    "            probs.append(temp)\n",
    "            lens.append(y-x)\n",
    "        else:\n",
    "            no_mutations.append(loc_name)\n",
    "    return (probs, lens, no_mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a256bdb-a08b-4e68-87f3-f75cce24b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_output = Parallel(n_jobs=-1)(delayed(generate_cds_probs)(num_cores, core_number, cds_boundaries) for core_number in core_numbers)\n",
    "temp = [item for sublist in parallel_output for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6403d4c-82cf-474c-bb56-cbc7d751d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 =[x[0] for x in parallel_output]\n",
    "t2 =[x[1] for x in parallel_output]\n",
    "temp1 = [item for sublist in t1 for item in sublist]\n",
    "temp2 = [item for sublist in t2 for item in sublist]\n",
    "sns.scatterplot(y=temp1, x=temp2)\n",
    "\n",
    "#sns.ecdfplot(temp1, ax = ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3a7ba2-bb84-409f-94e3-4c3b4999545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(temp))\n",
    "sns.histplot(probs, bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596166f-0577-46a0-892a-0a34ff3196ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.ecdfplot(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5ee19-6c34-46e8-b742-9607ec1fd0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(no_mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88de272-a67f-443b-b347-7aaa2c67112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_prob_regions = []\n",
    "non_cds_probs = []\n",
    "non_cds_no_mutations = []\n",
    "for i, (loc_name, x,y) in enumerate(tqdm(cds_boundaries)):\n",
    "    if i < len(cds_boundaries) - 1:\n",
    "        temp = cds_boundaries[i+1][1]\n",
    "        if temp - y > 100:\n",
    "            (temp2, num_mutations) = mutation_bin_probability(y, temp)\n",
    "            if num_mutations > 0:\n",
    "                non_cds_probs.append(temp2)\n",
    "                if temp2 < 0.01:\n",
    "                    low_prob_regions.append(loc_name)\n",
    "            else:\n",
    "                non_cds_no_mutations.append(loc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfeae66-c87a-4720-9666-5442cad415ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_orf(seq_start, seq_stop, in_frame, output_all_orfs = False):\n",
    "    orfs_found = []\n",
    "    max_len = 0\n",
    "    orf_length = 0\n",
    "    start_pos = -999\n",
    "    end_pos = -999\n",
    "    for frame in ['Forward', 'Reverse']:\n",
    "        if frame == 'Forward':\n",
    "            temp = (full_sequence[seq_start: seq_stop])\n",
    "        else:\n",
    "            temp = align.reverse_complement(full_sequence[seq_start: seq_stop])\n",
    "        seq_len = len(temp)\n",
    "        for i in range(seq_len - 2):\n",
    "            test_codon = temp[i: i+3] \n",
    "            if test_codon in ['ATG','GTG','TTG']:  #Missed out CTG as doesn't seem to be used very much at all\n",
    "                for j in range(i + 3, seq_len - 2, 3):\n",
    "                    test_codon_2 = temp[j: j+3] \n",
    "                    if test_codon_2 in ['TAG','TGA','TAA']:\n",
    "                        orf_length = j - i\n",
    "                        break\n",
    "                if orf_length > 0:\n",
    "                    if frame == 'Forward':\n",
    "                        orf_start =  seq_start + i\n",
    "                        orf_end = seq_start + j+3\n",
    "                        orf_strand = 1\n",
    "                    else:\n",
    "                        orf_start =  seq_start + seq_len-(j+3)\n",
    "                        orf_end = seq_start + seq_len-i\n",
    "                        orf_strand = -1\n",
    "                    orfs_found.append((orf_start, orf_end, orf_strand, orf_length, mutation_bin_probability(orf_start, orf_end, orf_strand, in_frame=True)))\n",
    "                   \n",
    "                if orf_length > max_len:\n",
    "                    max_len = orf_length\n",
    "                    start_pos = orf_start\n",
    "                    end_pos = orf_end\n",
    "                    strand = orf_strand \n",
    "               \n",
    "    if output_all_orfs == True:\n",
    "        sorted_orfs = sorted(orfs_found, key=lambda x: x[3], reverse=True)\n",
    "        return sorted_orfs\n",
    "    elif start_pos == -999:\n",
    "        return(0,0,0,(0,0,[0,0,0]))\n",
    "    else: \n",
    "        return(start_pos, end_pos, strand, mutation_bin_probability(start_pos, end_pos, strand, in_frame=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44da6b2d-865c-491f-b943-5ed392c6ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cds_boundaries[200:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a854a31d-d52f-4098-80da-135194c03043",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_orf(577338,578426, in_frame=True, output_all_orfs = True)    #(11500,13000)    (2272700,2275000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30864d-5586-4ce3-8730-c724969b4418",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_boundaries = []\n",
    "for feature in genome_record.features:\n",
    "    if feature.type == 'CDS':\n",
    "            a = feature.qualifiers  \n",
    "            cds_boundaries.append((a.get(\"locus_tag\")[0], int(feature.location.start), int(feature.location.end)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2be064-6633-46a4-8b1c-2426464e5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list = []\n",
    "for i, (loc_name, x,y) in enumerate((cds_boundaries)):\n",
    "    if i < len(cds_boundaries) - 1:\n",
    "        temp = cds_boundaries[i+1][1]\n",
    "        if temp - y > 100:\n",
    "            res = max_orf(y, temp, in_frame=True, genbank_format = True)\n",
    "            if res[3][0] < 0.05 and res[3][1] > 0 and res[1] - res[0] > 100:\n",
    "                print(loc_name, res)\n",
    "                out_list.append([loc_name, res[0], res[1], res[2], res[3][0]])\n",
    "df=pd.DataFrame(out_list,columns=['locus','start','end','strand','p_value'])\n",
    "df.to_csv(cryptic_output_path + '/significant_degenerate_patterns_intergenic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de03a2-1d07-46b3-be8b-ad5892007103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(out_list,columns=['locus','start','end','strand','p_value'])\n",
    "df.to_csv(cryptic_output_path + '/significant_degenerate_patterns_intergenic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6941e7-bcd4-411e-b4d3-6755ba2299f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(align.reverse_complement(full_sequence[578027:578192]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdca572a-0a4b-4f77-9181-1d9308b560db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((full_sequence[578027:578192]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b832d-fd6c-4e70-9ecd-4dc4556e54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = 16\n",
    "core_numbers = list(range(1, num_cores+1))\n",
    "tb_species = 'GCF_000195955.2'\n",
    "outgroup_species = 'GCF_000696675.2'\n",
    "non_cds_offset = 50\n",
    "genome_ids_with_outgroup = util.list_dirs(genome_datasets_dir)\n",
    "genome_ids = util.list_dirs(genome_datasets_dir)\n",
    "genome_ids.remove(outgroup_species)\n",
    "non_target_genome_ids = util.list_dirs(genome_datasets_dir)\n",
    "non_target_genome_ids.remove(outgroup_species)\n",
    "non_target_genome_ids.remove(tb_species)\n",
    "num_ids = len(genome_ids)\n",
    "num_ids_with_outgroup = len(genome_ids_with_outgroup)\n",
    "orthologs = sar.Ortholog_Grouping(ortholog_dir)\n",
    "outgroup_orthologs = sar.Ortholog_Grouping(outgroup_ortholog_dir)\n",
    "seq_data = sar.Ortholog_Sequence_Dataset(orthologs, genome_datasets_dir, genome_ids, non_cds_offset, tb_species) \n",
    "outgroup_seq_data = sar.Ortholog_Sequence_Dataset(outgroup_orthologs, genome_datasets_dir, genome_ids_with_outgroup, non_cds_offset, tb_species) \n",
    "all_copy_seq_data = sar.Ortholog_Sequence_Dataset(orthologs, genome_datasets_dir, genome_ids, non_cds_offset, tb_species, single_copy = False) \n",
    "#print(outgroup_seq_data.species_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62c1aa2-c41b-4f53-aa55-e435181b4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(non_cds_probs))\n",
    "sns.histplot(non_cds_probs, bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400ae69f-70b9-40b4-9b08-93cda0b9840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.ecdfplot(non_cds_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fb7475-02be-4190-94cc-b2a7c40dc31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = all_copy_seq_data.sequence_data\n",
    "for locus_id in no_mutations:\n",
    "    print(locus_id)\n",
    "    if len(temp[temp['locus_tag'] == locus_id]) > 0:\n",
    "        group_id = temp[temp['locus_tag'] == locus_id].iloc[0]['group_id']\n",
    "        temp[temp['group_id'] == group_id]\n",
    "    else:\n",
    "        print (\"No record of \"+ locus_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee346295-8cd8-4587-8a1e-5571960a30b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(low_prob_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07997aa4-1fc4-4180-b578-8700eab12a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85326626-6110-4589-a5fa-42f4101e51a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryptic_variant_count_dict = {}\n",
    "for i in range(len(full_sequence)):\n",
    "    if i+1 in variant_count_dict:\n",
    "        cryptic_variant_count_dict[i] = variant_count_dict[i+1]\n",
    "    else:\n",
    "        cryptic_variant_count_dict[i] = 0\n",
    "with open(literature_datasets_dir + '/' + 'cryptic_variant_count_dictionary.pkl','wb') as f:\n",
    "    pickle.dump(cryptic_variant_count_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e17cbd-b70f-400b-935e-9ee7b24096c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4099696, 4099098, -1):\n",
    "    if i in nick_dict:\n",
    "        print(i, nick_dict[i])\n",
    "    else:\n",
    "        print(i, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9802a2-8237-46cf-92a2-5c4e76c10f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(variant_count_dict[4099403])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632dd758-5e44-4e2b-a8fd-ddd1ef037440",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_key = 0\n",
    "for key, value in variant_count_dict.items():\n",
    "    if key > max_key:\n",
    "        max_key = key\n",
    "print(max_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ecd87-1d9f-40f3-a1f6-b205bbc540a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nick_dict = []\n",
    "for i in range(max_key + 1):\n",
    "    if i in variant_count_dict:\n",
    "        nick_dict.append(variant_count_dict[i])\n",
    "    else:\n",
    "        nick_dict.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff1dc7-b0e0-46c9-8c8c-6464b7ccfa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 4099375\n",
    "end = 4099521\n",
    "x_ax = list(range(start,end))\n",
    "y_ax = nick_dict[start:end]\n",
    "y_alt_ax = nick_dict[start:end]\n",
    "for i, val in enumerate(y_ax):\n",
    "    if val > 0:\n",
    "        y_alt_ax[i] = val\n",
    "        y_ax[i] = 1\n",
    "        \n",
    "plt.plot(x_ax, y_alt_ax)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x_ax, y_ax)\n",
    "plt.show()\n",
    "\n",
    "# Number of samples in normalized_tone\n",
    "N = len(x_ax)\n",
    "\n",
    "yf = fft(y_ax)\n",
    "xf = fftfreq(N, 1)\n",
    "\n",
    "plt.plot(xf[1:], np.abs(yf)[1:])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5606a9-60e9-45f1-ae5b-893fd327ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "chunksize = 0.5 * (10 ** 7) \n",
    "chunknum = 0\n",
    "with pd.read_csv(cryptic_input_path + \"VARIANTS.csv\", chunksize=chunksize) as reader:\n",
    "    for chunk in reader:\n",
    "        chunknum += 1\n",
    "        print(chunknum)\n",
    "        for i, r in chunk.iterrows():\n",
    "            if r['GENOME_INDEX'] in range(start,end):\n",
    "                temp.append([r['UNIQUEID'], r['GENOME_INDEX'], r['REF'],r['ALT'],r['MUTATION_TYPE']])\n",
    "df = pd.DataFrame(temp, columns = ['UNIQUEID', 'GENOME_INDEX','REF','ALT','MUTATION_TYPE'])\n",
    "df.to_csv(cryptic_output_path + '/' + 'upstream_3660.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa7aff-e987-4f32-a2e6-4a3122a96cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b9d3a2-7556-4def-a2e5-d5909e7036f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nick= df[['GENOME_INDEX', 'REF','ALT']]\n",
    "a = nick.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae5fba-f082-49b5-9dec-47c5a6bbbfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sequence[4099380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae706eb8-c029-4fa0-ba3b-5b2d8c78d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['GENOME_INDEX', 'REF', 'ALT']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c09aa4-7953-4ac1-bab7-4bdd011afed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(cryptic_output_path + '/' + 'nick.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974b3fa7-d55d-489d-ad66-e3c545c3bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sequence[4099376:4099400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95798500-311b-4be4-bd5e-d47e3a750150",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_count_dict[4099406]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189f52f-b74a-4e39-ba22-ca909690461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_orf2(seq_start, seq_stop, in_frame):\n",
    "    max_len = 0\n",
    "    orf_length = 0\n",
    "    start_pos = -999\n",
    "    end_pos = -999\n",
    "    for frame in ['Forward', 'Reverse']:\n",
    "        if frame == 'Forward':\n",
    "            temp = (full_sequence[seq_start: seq_stop])\n",
    "        else:\n",
    "            temp = align.reverse_complement(full_sequence[seq_start: seq_stop])\n",
    "        seq_len = len(temp)\n",
    "        for i in range(seq_len - 2):\n",
    "            test_codon = temp[i: i+3] \n",
    "            if test_codon in ['ATG','GTG','TTG']:  #Missed out CTG as doesn't seem to be used very much at all\n",
    "                for j in range(i + 3, seq_len - 2, 3):\n",
    "                    test_codon_2 = temp[j: j+3] \n",
    "                    if test_codon_2 in ['TAG','TGA','TAA']:\n",
    "                        orf_length = j - i\n",
    "                        break\n",
    "                if orf_length > max_len:\n",
    "                    max_len = orf_length\n",
    "                    if frame == 'Forward':\n",
    "                        start_pos = i\n",
    "                        end_pos = j+3\n",
    "                        strand = 1\n",
    "                    else:\n",
    "                        start_pos = seq_len-(j+3)\n",
    "                        end_pos = seq_len-i\n",
    "                        strand = -1\n",
    "    #print(seq_start+start_pos, seq_start+end_pos, strand)\n",
    "    #if strand == 1:\n",
    "    #    print(full_sequence[seq_start+start_pos:seq_start+start_pos+3], full_sequence[seq_start+end_pos-3: seq_start+end_pos])\n",
    "    #else:\n",
    "    #    print(align.reverse_complement(full_sequence[seq_start+end_pos-3: seq_start+end_pos]), align.reverse_complement(full_sequence[seq_start+start_pos:seq_start+start_pos+3]))\n",
    "    \n",
    "    if start_pos == -999:\n",
    "        return(0,0,0,(0,0,[0,0,0]))\n",
    "    else:\n",
    "        return(seq_start+start_pos, seq_start+end_pos, strand, mutation_bin_probability(seq_start+start_pos, seq_start+end_pos, strand, in_frame=True), big_changes(seq_start+start_pos, seq_start+end_pos, strand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751be336-ee2a-435d-9e1c-5160ef1e3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 0\n",
    "cds_boundaries = [[0, 0], [4411530, 4411530]]\n",
    "while num_iterations <= 10:\n",
    "    temp_boundaries = []\n",
    "    for i, (x,y) in enumerate((cds_boundaries)):\n",
    "        if i < len(cds_boundaries) - 1:\n",
    "            temp = cds_boundaries[i+1][0]\n",
    "            if temp - y > 100:\n",
    "                res = max_orf(y, temp, in_frame=True, genbank_format = False)\n",
    "                #if res[3][0] < 0.005 and res[3][1] > 0 and res[1] - res[0] > 100:\n",
    "                if res[0] == res[1]:\n",
    "                    pass\n",
    "                else:\n",
    "                    #print(res)\n",
    "                    temp_boundaries.append([res[0], res[1]])\n",
    "    cds_boundaries = sorted(cds_boundaries + temp_boundaries, key=lambda x: x[0])\n",
    "    print(\"iteration \" + str(num_iterations))\n",
    "    print (cds_boundaries)\n",
    "    num_iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c788f20-c7ae-4229-bb9a-3638e7a738c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cds_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b04e189-b43c-4f04-a18b-272c4bc4d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2**10-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc61905-f92d-4cb8-be6c-16a0e5cb41e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[1,1],[3,4]]+[[1,5],[3,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6eb58c-9d64-47a3-87ae-f394098bc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "vsmall = 0\n",
    "small = 0\n",
    "for k, v in fast_position_dict.items():\n",
    "    tot +=1\n",
    "    temp = len(v)\n",
    "    if temp < 4:\n",
    "        vsmall+=1\n",
    "    if temp < 50:\n",
    "        small +=1\n",
    "print(tot, vsmall, small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6645f4fa-2984-475d-9b12-8bfcdbb02f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 7]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([0,2,1],[2,0,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "63e211d2-863c-4e32-b469-e6469f9c86b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "counts = []\n",
    "for h,i, j in zip([1,1,1],[0,2,1],[2,0,7]):\n",
    "    counts.append(h+max(i, j))\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1deca8b-494c-44a4-bfb0-7d36d65201db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
