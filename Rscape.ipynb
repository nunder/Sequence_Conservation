{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d24f991-5e62-4643-a8c3-d08ddaacc4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "from Comparative_Analysis import Utilities as util\n",
    "from Bio import AlignIO, SeqIO\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import re\n",
    "from Comparative_Analysis import Sequence_Analysis_Routines as sar\n",
    "from Comparative_Analysis import Alignment as align\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e8479c-a9a6-4794-808d-26cae6cb4a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_dir = 'D:/Project_Data/Project_7'\n",
    "dataset_loc = project_dir + '/NCBI_Dataset_Actinobacteria'\n",
    "r_scape_output_loc = project_dir + '/R_Scape_Results_Test'\n",
    "merged_file_loc = dataset_loc + '/merged_file.txt'\n",
    "literature_datasets_dir = project_dir + '/Data_From_Publications'\n",
    "wsl_merged_file_loc = util.wslname(merged_file_loc)\n",
    "reference_species = 'GCF_000195955.2_ASM19595v2'\n",
    "reference_species_folder = 'GCF_000195955.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b7d97e-a16c-4da2-b4e0-de8e4be16410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "    with open(merged_file_loc, 'w') as outfile:\n",
    "        for dir in util.list_dirs(dataset_loc):\n",
    "            directory = dataset_loc + '/' + dir\n",
    "            for file in util.list_files(directory):\n",
    "                if file.endswith(\"genomic.fna\"):\n",
    "                    with open(directory + '/' + file, encoding=\"utf-8\", errors='ignore') as infile:\n",
    "                        outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c86df15-31c8-4de7-9949-59347fa9598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "features = []\n",
    "genome_record = next(SeqIO.parse(dataset_loc + '/'+reference_species_folder +'/' + reference_species + '_genomic.fna', \"fasta\"))\n",
    "full_sequence = str(genome_record.seq)\n",
    "mycobrowser_df = pd.read_excel(literature_datasets_dir+'/Mycobrowser_Release_4.xlsx')\n",
    "for i, r in mycobrowser_df.iterrows():\n",
    "    #if r['Feature'] == 'CDS':\n",
    "    if 1 == 1:\n",
    "        if r['Strand'] == '+':\n",
    "            strand = 1\n",
    "        else:\n",
    "            strand = -1\n",
    "        features.append([r['Locus'],r['Start']-1, r['Stop'], strand])\n",
    "features.sort(key=lambda x: x[1])\n",
    "feature_info = []\n",
    "for i, feature in enumerate(features):\n",
    "    if feature[1] < feature[2]:  \n",
    "        if (i + 1)< len(features) and feature[2] < features[i+1][1]:\n",
    "            utr_coords = (feature[2], features[i+1][1])\n",
    "            utr_sequence = full_sequence[feature[2]: features[i+1][1]]\n",
    "            utr_length = len(utr_sequence)\n",
    "        else:\n",
    "            utr_coords = (0,0)\n",
    "            utr_sequence = ''\n",
    "            utr_length = 0\n",
    "        feature_info.append([feature[0], utr_coords[0], utr_coords[1], utr_sequence, utr_length])\n",
    "intergenic_df = pd.DataFrame(feature_info, columns = ['Locus', 'Start' , 'End', 'Sequence', 'Length'])\n",
    "intergenic_df.to_csv(project_dir + '/intergenic_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d908bb9-b1ff-4d1c-b469-2ecde30d7a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "intergenic_df = pd.read_csv(project_dir + '/intergenic_df.csv')\n",
    "alignment_ids = []\n",
    "for i, r in intergenic_df.iterrows():\n",
    "    alignment_ids.append(r['Locus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcfe16be-59ee-4134-8d29-e0cdf23801ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_ids = [alignment_ids[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af353a03-8ac6-41c8-af7e-04e8a1399e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_ids = ['Rv0052']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b20de15-9852-4d3c-ae74-846d87b496ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_hit_per_species(analysis_dir, search_num):\n",
    "    best_hit_dict = {}\n",
    "    with open(analysis_dir + '/search_hits_'+str(search_num)+'.txt','r') as infile:\n",
    "        for l in infile:\n",
    "            if l[0] =='#':\n",
    "                pass\n",
    "            else:\n",
    "                space_delims = l.split()\n",
    "                seq_id = space_delims[0]\n",
    "                seq_from = space_delims[7]\n",
    "                seq_to = space_delims[8]\n",
    "                e_value = float(space_delims[15])\n",
    "                if e_value < 0.001:\n",
    "                    if seq_id in best_hit_dict:\n",
    "                        if e_value < best_hit_dict[seq_id][2]:\n",
    "                            best_hit_dict[seq_id] = (seq_from, seq_to, e_value)\n",
    "                    else:\n",
    "                        best_hit_dict[seq_id] = (seq_from, seq_to, e_value)\n",
    "    inclusion_sections = []\n",
    "    for k, v in best_hit_dict.items():\n",
    "        inclusion_sections.append(k+'/'+v[0]+'-'+v[1])\n",
    "    inclusion_sections = inclusion_sections + ['//', '# STOCKHOLM', 'Infernal']\n",
    "    with open(analysis_dir + '/search_'+str(search_num)+'.sto', 'r') as infile:\n",
    "        with open(analysis_dir + '/search_bh_'+str(search_num)+'.sto', 'w') as outfile:\n",
    "            for l in infile:\n",
    "                if len(l) < 2:\n",
    "                    outfile.write(l)\n",
    "                else:\n",
    "                    for sect in inclusion_sections:\n",
    "                        if (sect in l) or (len(l) < 2):\n",
    "                            outfile.write(l)\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7f7224a-27d2-4d7f-a3e5-0f4530e4da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_utr(utr_s, utr_e, searchline):\n",
    "    result = re.search('NC_000962.3/(\\S*)\\s', searchline)\n",
    "    if not(result == None):\n",
    "        start = int(result.group(1).split('-')[0])\n",
    "        end = int(result.group(1).split('-')[1])\n",
    "        if ((start < utr_e) and (end > utr_s)) or  ((end < utr_e) and (start > utr_s)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def utr_in_file(filename, utr_s, utr_e):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            for l in f:\n",
    "                if match_utr(utr_s, utr_e, l) == True:\n",
    "                    return True\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f59d963b-a265-4e93-ad0d-60a420bc2c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712657af52fc431283d19e2a05f9cd8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "for alignment_id in tqdm(alignment_ids):\n",
    "    temp_df = intergenic_df[intergenic_df.Locus == alignment_id]\n",
    "    utr_seq = str(temp_df.iloc[0]['Sequence'])\n",
    "    utr_start = int(temp_df.iloc[0]['Start'])\n",
    "    utr_end = int(temp_df.iloc[0]['End'])\n",
    "    utr_length = int(temp_df.iloc[0]['Length'])\n",
    "    analysis_directory = r_scape_output_loc + '/' + alignment_id\n",
    "    wsl_analysis_directory = util.wslname(analysis_directory)\n",
    "    if len(utr_seq) > 150:\n",
    "        if not os.path.exists(analysis_directory):\n",
    "            os.makedirs(analysis_directory)\n",
    "        util.produce_fasta_file([[alignment_id, utr_seq]], analysis_directory + '/utr_'+ alignment_id + '.fasta')\n",
    "        subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; nhmmer -A align_1.sto --incE 1e-20 '+  'utr_'+ alignment_id + '.fasta '+wsl_merged_file_loc, shell=True)\n",
    "    \n",
    "        # Initial run with HMM\n",
    "\n",
    "        subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; ~/infernal-1.1.4/src/cmbuild --noss -F cm_1.cm align_1.sto'  , shell=True)\n",
    "        subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; ~/infernal-1.1.4/src/cmsearch  --tblout search_hits_1.txt -A search_1.sto cm_1.cm ' + wsl_merged_file_loc  , shell=True) \n",
    "        if utr_in_file(analysis_directory + '/search_1.sto', utr_start, utr_end) == False:\n",
    "            continue\n",
    "        best_hit_per_species(analysis_directory, 1)\n",
    "        subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; ~/rscape_v2.0.0.g/bin/R-scape --cacofold --outname rscape_1 search_bh_1.sto'  , shell=True)\n",
    "      \n",
    "        # Subsequent runs with Cacofold CM\n",
    "\n",
    "        for iter_num in range(2, 4):\n",
    "            subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; ~/infernal-1.1.4/src/cmbuild -F cm_'+str(iter_num)+'.cm rscape_'+str(iter_num - 1) +'.cacofold.R2R.sto'  , shell=True)\n",
    "            subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; ~/infernal-1.1.4/src/cmcalibrate cm_'+str(iter_num)+'.cm', shell= True)\n",
    "            subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; ~/infernal-1.1.4/src/cmsearch --tblout search_hits_'+str(iter_num)+'.txt -A search_'+str(iter_num)+'.sto cm_'+str(iter_num)+'.cm ' + wsl_merged_file_loc  , shell=True)  \n",
    "            if utr_in_file(analysis_directory + '/search_'+str(iter_num)+'.sto', utr_start, utr_end) == False:\n",
    "                continue\n",
    "            best_hit_per_species(analysis_directory, iter_num)\n",
    "            subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; ~/rscape_v2.0.0.g/bin/R-scape --cacofold --outname rscape_'+str(iter_num) +' search_bh_'+str(iter_num)+'.sto'  , shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd2e82d-32f9-4653-937c-41e558aba07d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
