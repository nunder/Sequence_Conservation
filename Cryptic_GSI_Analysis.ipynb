{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e30ed4-8a0e-4a6f-96eb-dfe116dfb2de",
   "metadata": {},
   "source": [
    "#### Directories etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9c6377-5080-4c22-94db-feabe17cc47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\ete3-3.1.2-py3.7.egg\\ete3\\evol\\parser\\codemlparser.py:221: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\ete3-3.1.2-py3.7.egg\\ete3\\evol\\parser\\codemlparser.py:221: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fft import fft, fftfreq\n",
    "from Bio import Entrez, SeqIO, AlignIO, pairwise2, Align, Seq, motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from scipy.stats import binom\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from Comparative_Analysis import Utilities as util\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from Comparative_Analysis import Blast_Functions as blastfn\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from Comparative_Analysis import ORF_Functions as orffn\n",
    "from random import sample\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import ete3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1988a242-f558-4643-b3a9-27272fa7bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'F:/Project_Data/Project_11'\n",
    "seq_dir = 'F:/Datasets/Actinobacteria_Ref_Rep_Lev_Complete'\n",
    "dictionary_dir = 'F:/Datasets/CRYPTIC_DATA/Cryptic_Dictionaries'\n",
    "mutation_count_dir = 'F:/Datasets/CRYPTIC_DATA/Cryptic_Mutation_Counts'\n",
    "mutation_count_dir = 'F:/Datasets/CRYPTIC_DATA/Cryptic_Mutation_Counts'\n",
    "tb_species = 'NC_000962.3' \n",
    "tb_genome_filename = 'GCF_000195955.2_ASM19595v2_genomic.gbff'\n",
    "mycobrowser_dir = 'F:/Datasets/Data_From_Publications'\n",
    "num_cores = 16\n",
    "core_numbers = list(range(1, num_cores+1))\n",
    "cryptic_input_path = 'F:/Datasets/CRYPTIC_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3235e1e1-a7fa-474b-8a88-72232e020b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in SeqIO.parse(seq_dir + '/' + tb_genome_filename, \"genbank\"):\n",
    "    full_sequence = str(record.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b88b412-d21e-4178-aef9-84e81e3c0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ee7e9e-6a66-485f-badf-22c81560e77f",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ebdfd2-85cc-4bc6-86c5-9e3c6c9cf3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_sequences(position_list, variant_dict, position_dict):\n",
    "    base_sequence = []\n",
    "    for i in position_list:\n",
    "        base_sequence.append(full_sequence[i-1])     # Cryptic are 1 based \n",
    "    output_sequence_dict ={}\n",
    "    for k, v in variant_dict.items():\n",
    "        output_sequence_dict[k] = copy.deepcopy(base_sequence)\n",
    "    for i, pos in enumerate(position_list):\n",
    "        if pos in position_dict:\n",
    "            variant_info = position_dict[pos][1:]  # Miss out initlal \"ref\" record\n",
    "            for (name, alt) in variant_info:\n",
    "                output_sequence_dict[name][i] = alt.upper()\n",
    "    output_sequences = []\n",
    "    for k, v in output_sequence_dict.items():\n",
    "        output_sequences.append(['seq_'+str(k), ''.join(v)])\n",
    "    return output_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd2694-16c3-4f59-b516-08d2b64a3082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_sequences_to_score(position_list, variant_dict, position_dict, distinct_sequence_names):\n",
    "    base_sequence = []\n",
    "    for i in position_list:\n",
    "        base_sequence.append({full_sequence[i-1]})     # Cryptic are 1 based \n",
    "    output_sequence_dict ={}\n",
    "    for k, v in variant_dict.items():\n",
    "        if k in distinct_sequence_names:\n",
    "            output_sequence_dict[k] = copy.deepcopy(base_sequence)\n",
    "    for i, pos in enumerate(position_list):\n",
    "        if pos in position_dict:\n",
    "            variant_info = position_dict[pos][1:]  # Miss out initlal \"ref\" record\n",
    "            for (name, alt) in variant_info:\n",
    "                if name in output_sequence_dict:\n",
    "                    output_sequence_dict[name][i] = {alt.upper()}\n",
    "    temp_dict = {}\n",
    "    for k, v in output_sequence_dict.items():\n",
    "        temp_dict['seq_'+str(k)] = v\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9acb43-19f3-45e0-8214-f9481910cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitch_1(list_1, list_2):\n",
    "    res =[]\n",
    "    for i, j in zip(list_1, list_2):\n",
    "        a = i.intersection(j)\n",
    "        if len(a) == 0:\n",
    "            a = i.union(j)\n",
    "        res.append(a)\n",
    "    return res\n",
    "\n",
    "def fitch_2(parent_list, child_list):\n",
    "    res = []\n",
    "    mutations = []\n",
    "    for i, j in zip(parent_list, child_list):\n",
    "        mutation = 0\n",
    "        a = i.intersection(j)\n",
    "        if len(a) == 0:\n",
    "            a = set(list(j)[0])\n",
    "            mutation = 1\n",
    "        res.append(a)\n",
    "        if mutation == 1:\n",
    "            mutations.append(1)\n",
    "        else:\n",
    "            mutations.append(0)\n",
    "    return (res, mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb8d3e-ef11-4e1a-bf89-cacff5ff6f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mutation_counts(filename, core_number):    \n",
    "    seq_length = 100\n",
    "    a = filename.split('_')\n",
    "    start = a[-3]\n",
    "    stop = a[-2]\n",
    "    with open(filename, 'rb') as f:\n",
    "        sequence_to_score_dict = pickle.load(f)\n",
    "    master_tree2= ete3.Tree(project_dir + '/' + 'my_tree.nwk')\n",
    "    for node in master_tree2.traverse(\"postorder\"):\n",
    "        if node.is_leaf():\n",
    "            node.add_features(seq = sequence_to_score_dict[node.name][core_number * seq_length: (core_number+1) * seq_length])\n",
    "        else:\n",
    "            children = node.children\n",
    "            node.add_features(seq = fitch_1(children[0].seq, children[1].seq))\n",
    "    #for k, v in sequence_to_score_dict.items():              \n",
    "        #seq_length = len(v)\n",
    "        #break\n",
    "    \n",
    "    mutation_counts = [0 for i in range(seq_length)]\n",
    "    for node in master_tree2.traverse(\"preorder\"):\n",
    "        if node.is_leaf():\n",
    "            continue\n",
    "        if node.is_root():\n",
    "            node.seq = [{list(x)[0]} for x in node.seq]\n",
    "        children = node.children\n",
    "        mutations = []\n",
    "        child_sequences = []\n",
    "        for child in children:\n",
    "            (temp_1, temp_2) = fitch_2(node.seq ,child.seq)\n",
    "            child_sequences.append(temp_1)\n",
    "            child.seq = temp_1\n",
    "            mutations.append(temp_2)\n",
    "        temp = []\n",
    "        for n, (h, i, j) in enumerate(zip(mutation_counts, mutations[0], mutations[1])):\n",
    "            if i + j == 0:\n",
    "                temp.append(h+0)\n",
    "            elif i + j == 1:\n",
    "                temp.append(h+1)\n",
    "            else:\n",
    "                if child_sequences[0][i] == child_sequences[1][i]:\n",
    "                    temp.append(h+1)\n",
    "                else:\n",
    "                    temp.append(h+2)\n",
    "            \n",
    "        mutation_counts = temp     \n",
    "    return (start, stop, mutation_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc25129-08e0-4ce1-9b17-a64f477c50d8",
   "metadata": {},
   "source": [
    "#### Create variant dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fcbb04-2c85-4719-b420-2651cf1e2cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    variant_df = pd.read_csv(cryptic_input_path + \"/VARIANTS.csv\") \n",
    "    with open(project_dir + '/variant_df.pkl', 'wb') as f:\n",
    "        pickle.dump(variant_df[['UNIQUEID', 'VARIANT', 'MUTATION_TYPE', 'IS_NULL', 'IS_HET', 'IS_FILTER_PASS', 'IS_SNP', 'REF', 'ALT', 'GENOME_INDEX']], f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe61cc-adfe-4aa1-97d1-ba7ef7ac00ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if full_run == True:\n",
    "if 1==1:\n",
    "    position_dict = {}\n",
    "    variant_dict = {}\n",
    "    id_dict = {}\n",
    "    with open(project_dir + '/variant_df.pkl', 'rb') as f:\n",
    "        variant_df = pickle.load(f) \n",
    "        unique_ids = variant_df.UNIQUEID.unique()\n",
    "        for i, unique_id in enumerate(unique_ids):\n",
    "            id_dict[unique_id] = i\n",
    "        for i, r in variant_df.iterrows():\n",
    "            if r['IS_NULL'] == False and r['IS_FILTER_PASS'] == True and r['IS_HET'] == False and r['IS_SNP'] == True :\n",
    "            #if r['IS_SNP'] == True:    \n",
    "                if id_dict[r['UNIQUEID']] in variant_dict:\n",
    "                    variant_dict[id_dict[r['UNIQUEID']]].append((r['GENOME_INDEX'], r['ALT']))\n",
    "                else:\n",
    "                    variant_dict[id_dict[r['UNIQUEID']]] = [(r['GENOME_INDEX'], r['ALT'])]\n",
    "\n",
    "                if r['GENOME_INDEX'] in position_dict:\n",
    "                    position_dict[r['GENOME_INDEX']].append((id_dict[r['UNIQUEID']], r['ALT']))\n",
    "                else:\n",
    "                    position_dict[r['GENOME_INDEX']] = [r['REF'], (id_dict[r['UNIQUEID']], r['ALT'])]    # If first entry also include reference value for info\n",
    "\n",
    "    with open(project_dir + '/id_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(id_dict, f)\n",
    "    with open(project_dir + '/variant_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(variant_dict, f) \n",
    "    with open(project_dir + '/position_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(position_dict, f) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9da2b4-26ab-4150-90e6-99fc3b388cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == False:\n",
    "    with open(project_dir + '/id_dict.pkl', 'rb') as f:\n",
    "        id_dict = pickle.load(f)  \n",
    "    with open(project_dir + '/variant_dict.pkl', 'rb') as f:\n",
    "        variant_dict = pickle.load(f)  \n",
    "    with open(project_dir + '/position_dict.pkl', 'rb') as f:\n",
    "        position_dict = pickle.load(f)  \n",
    "    with open(project_dir + '/variant_df.pkl', 'rb') as f:\n",
    "        variant_df = pickle.load(f)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0cf8791-dcf4-46e4-b801-ba5ec9a1b6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicho\\AppData\\Local\\Temp/ipykernel_29472/86580013.py:3: DtypeWarning: Columns (1,3,13,14,15,27,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  genomes_df = pd.read_csv(cryptic_input_path + '/GENOMES.csv')\n"
     ]
    }
   ],
   "source": [
    "with open(project_dir + '/variant_df.pkl', 'rb') as f:\n",
    "        variant_df = pickle.load(f)      \n",
    "genomes_df = pd.read_csv(cryptic_input_path + '/GENOMES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "573b5b9b-4030-4424-b18f-92e854f9b4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site.05.subj.LR-2285.lab.FN-00492-18.iso.1 95.0 95\n",
      "site.04.subj.03671.lab.JJH10007.iso.1 54.0 54\n",
      "site.13.subj.070208197.lab.070208197.iso.1 45.0 45\n",
      "site.13.subj.070207152.lab.070207152.iso.1 38.0 38\n",
      "site.13.subj.070208207.lab.070208207.iso.1 41.0 41\n",
      "site.13.subj.080200043.lab.080200043.iso.1 37.0 37\n",
      "site.03.subj.GB-91540144.lab.IML-01052.iso.1 45.0 45\n",
      "site.03.subj.GB-91540133.lab.IML-01053.iso.1 45.0 45\n",
      "site.03.subj.GB-91540141.lab.IML-01056.iso.1 44.0 44\n",
      "site.03.subj.GB-91540140.lab.IML-01055.iso.1 45.0 45\n",
      "site.03.subj.GB-91540138.lab.IML-01054.iso.1 44.0 44\n",
      "site.06.subj.MHL_0208-14.lab.06MIL0327.iso.1 40.0 40\n",
      "site.10.subj.YA00038861.lab.YA00038861.iso.1 47.0 47\n",
      "site.10.subj.YA00099963.lab.YA00099963.iso.1 39.0 39\n"
     ]
    }
   ],
   "source": [
    "temp = genomes_df#[genomes_df['UNIQUEID'] == 'site.02.subj.0005.lab.2014222011.iso.1']\n",
    "temp2 = temp[temp['SNP_DISTANCE_TO_H37rV'] <100]\n",
    "len(temp2)\n",
    "for i, r in temp2.iterrows():\n",
    "    print(r['UNIQUEID'], r['SNP_DISTANCE_TO_H37rV'] , len(variant_dict[id_dict[r['UNIQUEID']]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68506edf-9ceb-4ac3-9826-083a30c37a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(variant_dict[id_dict['site.05.subj.LR-2285.lab.FN-00492-18.iso.1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c2f29b4-7e4f-464a-9bc9-7ee6d90d4357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97961825"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cd = pd.merge(variant_df, , how='outer', on = 'GENOME_INDEX')\n",
    "for i, r in df_cd.iterrows():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f586affb-c8b7-41c1-8438-e7c393c81f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpi_genomes_df = genomes_df[genomes_df['BELONGS_GPI']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f96c2f0-bc5b-40ac-82df-d8f6a6e3f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpi_variants_df = pd.merge(variant_df, gpi_genomes_df, how='inner', on = 'UNIQUEID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a61faf0b-f20c-42cd-bac1-e416af45128f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIQUEID</th>\n",
       "      <th>VARIANT</th>\n",
       "      <th>MUTATION_TYPE</th>\n",
       "      <th>IS_NULL</th>\n",
       "      <th>IS_HET</th>\n",
       "      <th>IS_FILTER_PASS</th>\n",
       "      <th>IS_SNP</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>GENOME_INDEX</th>\n",
       "      <th>...</th>\n",
       "      <th>IMAGE_MD5SUM</th>\n",
       "      <th>FTP_PATH</th>\n",
       "      <th>FTP_FILENAME_VCF</th>\n",
       "      <th>TREE_PATH</th>\n",
       "      <th>TREE_FILENAME_VCF</th>\n",
       "      <th>FASTQ_MD5SUMS</th>\n",
       "      <th>SEQTREAT_SAMPLE</th>\n",
       "      <th>MYKROBE_LINEAGE_NAME_1</th>\n",
       "      <th>MYKROBE_LINEAGE_NAME_2</th>\n",
       "      <th>ENA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>site.02.subj.0958.lab.22A197.iso.1</td>\n",
       "      <td>1849c&gt;a</td>\n",
       "      <td>SNP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1849</td>\n",
       "      <td>...</td>\n",
       "      <td>{'02-0958-22A197-1-14': 'a587bac9ad2a0ebd36274...</td>\n",
       "      <td>/well/bag/jeffk/release_staging/</td>\n",
       "      <td>00/01/41/00/14100/site.02.iso.1.subject.0958.l...</td>\n",
       "      <td>dat/CRyPTIC2/V2/02/0958/22A197/1/regenotyped/</td>\n",
       "      <td>site.02.subj.0958.lab.22A197.iso.1.v0.8.3.rege...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Lineage 2</td>\n",
       "      <td>lineage2.2.1</td>\n",
       "      <td>ERS5301054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>site.02.subj.0958.lab.22A197.iso.1</td>\n",
       "      <td>1977a&gt;g</td>\n",
       "      <td>SNP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "      <td>1977</td>\n",
       "      <td>...</td>\n",
       "      <td>{'02-0958-22A197-1-14': 'a587bac9ad2a0ebd36274...</td>\n",
       "      <td>/well/bag/jeffk/release_staging/</td>\n",
       "      <td>00/01/41/00/14100/site.02.iso.1.subject.0958.l...</td>\n",
       "      <td>dat/CRyPTIC2/V2/02/0958/22A197/1/regenotyped/</td>\n",
       "      <td>site.02.subj.0958.lab.22A197.iso.1.v0.8.3.rege...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Lineage 2</td>\n",
       "      <td>lineage2.2.1</td>\n",
       "      <td>ERS5301054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>site.02.subj.0958.lab.22A197.iso.1</td>\n",
       "      <td>4013t&gt;c</td>\n",
       "      <td>SNP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>t</td>\n",
       "      <td>c</td>\n",
       "      <td>4013</td>\n",
       "      <td>...</td>\n",
       "      <td>{'02-0958-22A197-1-14': 'a587bac9ad2a0ebd36274...</td>\n",
       "      <td>/well/bag/jeffk/release_staging/</td>\n",
       "      <td>00/01/41/00/14100/site.02.iso.1.subject.0958.l...</td>\n",
       "      <td>dat/CRyPTIC2/V2/02/0958/22A197/1/regenotyped/</td>\n",
       "      <td>site.02.subj.0958.lab.22A197.iso.1.v0.8.3.rege...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Lineage 2</td>\n",
       "      <td>lineage2.2.1</td>\n",
       "      <td>ERS5301054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>site.02.subj.0958.lab.22A197.iso.1</td>\n",
       "      <td>7362g&gt;c</td>\n",
       "      <td>SNP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>7362</td>\n",
       "      <td>...</td>\n",
       "      <td>{'02-0958-22A197-1-14': 'a587bac9ad2a0ebd36274...</td>\n",
       "      <td>/well/bag/jeffk/release_staging/</td>\n",
       "      <td>00/01/41/00/14100/site.02.iso.1.subject.0958.l...</td>\n",
       "      <td>dat/CRyPTIC2/V2/02/0958/22A197/1/regenotyped/</td>\n",
       "      <td>site.02.subj.0958.lab.22A197.iso.1.v0.8.3.rege...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Lineage 2</td>\n",
       "      <td>lineage2.2.1</td>\n",
       "      <td>ERS5301054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>site.02.subj.0958.lab.22A197.iso.1</td>\n",
       "      <td>7585g&gt;c</td>\n",
       "      <td>SNP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>7585</td>\n",
       "      <td>...</td>\n",
       "      <td>{'02-0958-22A197-1-14': 'a587bac9ad2a0ebd36274...</td>\n",
       "      <td>/well/bag/jeffk/release_staging/</td>\n",
       "      <td>00/01/41/00/14100/site.02.iso.1.subject.0958.l...</td>\n",
       "      <td>dat/CRyPTIC2/V2/02/0958/22A197/1/regenotyped/</td>\n",
       "      <td>site.02.subj.0958.lab.22A197.iso.1.v0.8.3.rege...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Lineage 2</td>\n",
       "      <td>lineage2.2.1</td>\n",
       "      <td>ERS5301054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18159372</th>\n",
       "      <td>site.10.subj.YA00166043.lab.YA00166043.iso.1</td>\n",
       "      <td>4338587_indel</td>\n",
       "      <td>INDEL</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>agctccgagctctagt</td>\n",
       "      <td>agctccgagtctagt</td>\n",
       "      <td>4338587</td>\n",
       "      <td>...</td>\n",
       "      <td>{'10-YA00166043-YA00166043-1-14': 'e151041dd9b...</td>\n",
       "      <td>/well/bag/jeffk/release_staging/</td>\n",
       "      <td>00/02/95/61/29561/site.10.iso.1.subject.YA0016...</td>\n",
       "      <td>dat/CRyPTIC2/V2/10/YA00166043/YA00166043/1/reg...</td>\n",
       "      <td>site.10.subj.YA00166043.lab.YA00166043.iso.1.v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Lineage 2</td>\n",
       "      <td>lineage2.2.1</td>\n",
       "      <td>NO_ENA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18159373</th>\n",
       "      <td>site.10.subj.YA00166043.lab.YA00166043.iso.1</td>\n",
       "      <td>4379044_indel</td>\n",
       "      <td>INDEL</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>cg</td>\n",
       "      <td>c</td>\n",
       "      <td>4379044</td>\n",
       "      <td>...</td>\n",
       "      <td>{'10-YA00166043-YA00166043-1-14': 'e151041dd9b...</td>\n",
       "      <td>/well/bag/jeffk/release_staging/</td>\n",
       "      <td>00/02/95/61/29561/site.10.iso.1.subject.YA0016...</td>\n",
       "      <td>dat/CRyPTIC2/V2/10/YA00166043/YA00166043/1/reg...</td>\n",
       "      <td>site.10.subj.YA00166043.lab.YA00166043.iso.1.v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Lineage 2</td>\n",
       "      <td>lineage2.2.1</td>\n",
       "      <td>NO_ENA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18159374</th>\n",
       "      <td>site.10.subj.YA00166043.lab.YA00166043.iso.1</td>\n",
       "      <td>4383144_indel</td>\n",
       "      <td>INDEL</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>c</td>\n",
       "      <td>ccgggg</td>\n",
       "      <td>4383144</td>\n",
       "      <td>...</td>\n",
       "      <td>{'10-YA00166043-YA00166043-1-14': 'e151041dd9b...</td>\n",
       "      <td>/well/bag/jeffk/release_staging/</td>\n",
       "      <td>00/02/95/61/29561/site.10.iso.1.subject.YA0016...</td>\n",
       "      <td>dat/CRyPTIC2/V2/10/YA00166043/YA00166043/1/reg...</td>\n",
       "      <td>site.10.subj.YA00166043.lab.YA00166043.iso.1.v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Lineage 2</td>\n",
       "      <td>lineage2.2.1</td>\n",
       "      <td>NO_ENA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18159375</th>\n",
       "      <td>site.10.subj.YA00166043.lab.YA00166043.iso.1</td>\n",
       "      <td>4400660_indel</td>\n",
       "      <td>INDEL</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>ac</td>\n",
       "      <td>a</td>\n",
       "      <td>4400660</td>\n",
       "      <td>...</td>\n",
       "      <td>{'10-YA00166043-YA00166043-1-14': 'e151041dd9b...</td>\n",
       "      <td>/well/bag/jeffk/release_staging/</td>\n",
       "      <td>00/02/95/61/29561/site.10.iso.1.subject.YA0016...</td>\n",
       "      <td>dat/CRyPTIC2/V2/10/YA00166043/YA00166043/1/reg...</td>\n",
       "      <td>site.10.subj.YA00166043.lab.YA00166043.iso.1.v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Lineage 2</td>\n",
       "      <td>lineage2.2.1</td>\n",
       "      <td>NO_ENA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18159376</th>\n",
       "      <td>site.10.subj.YA00166043.lab.YA00166043.iso.1</td>\n",
       "      <td>4409797_indel</td>\n",
       "      <td>INDEL</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>c</td>\n",
       "      <td>cgccatccgctgacgatccttgccgtatttcttttgcaaggccttg...</td>\n",
       "      <td>4409797</td>\n",
       "      <td>...</td>\n",
       "      <td>{'10-YA00166043-YA00166043-1-14': 'e151041dd9b...</td>\n",
       "      <td>/well/bag/jeffk/release_staging/</td>\n",
       "      <td>00/02/95/61/29561/site.10.iso.1.subject.YA0016...</td>\n",
       "      <td>dat/CRyPTIC2/V2/10/YA00166043/YA00166043/1/reg...</td>\n",
       "      <td>site.10.subj.YA00166043.lab.YA00166043.iso.1.v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Lineage 2</td>\n",
       "      <td>lineage2.2.1</td>\n",
       "      <td>NO_ENA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18159377 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              UNIQUEID        VARIANT  \\\n",
       "0                   site.02.subj.0958.lab.22A197.iso.1        1849c>a   \n",
       "1                   site.02.subj.0958.lab.22A197.iso.1        1977a>g   \n",
       "2                   site.02.subj.0958.lab.22A197.iso.1        4013t>c   \n",
       "3                   site.02.subj.0958.lab.22A197.iso.1        7362g>c   \n",
       "4                   site.02.subj.0958.lab.22A197.iso.1        7585g>c   \n",
       "...                                                ...            ...   \n",
       "18159372  site.10.subj.YA00166043.lab.YA00166043.iso.1  4338587_indel   \n",
       "18159373  site.10.subj.YA00166043.lab.YA00166043.iso.1  4379044_indel   \n",
       "18159374  site.10.subj.YA00166043.lab.YA00166043.iso.1  4383144_indel   \n",
       "18159375  site.10.subj.YA00166043.lab.YA00166043.iso.1  4400660_indel   \n",
       "18159376  site.10.subj.YA00166043.lab.YA00166043.iso.1  4409797_indel   \n",
       "\n",
       "         MUTATION_TYPE  IS_NULL  IS_HET  IS_FILTER_PASS  IS_SNP  \\\n",
       "0                  SNP    False   False            True    True   \n",
       "1                  SNP    False   False            True    True   \n",
       "2                  SNP    False   False            True    True   \n",
       "3                  SNP    False   False            True    True   \n",
       "4                  SNP    False   False            True    True   \n",
       "...                ...      ...     ...             ...     ...   \n",
       "18159372         INDEL    False   False            True   False   \n",
       "18159373         INDEL    False   False            True   False   \n",
       "18159374         INDEL    False   False            True   False   \n",
       "18159375         INDEL    False   False            True   False   \n",
       "18159376         INDEL    False   False            True   False   \n",
       "\n",
       "                       REF                                                ALT  \\\n",
       "0                        c                                                  a   \n",
       "1                        a                                                  g   \n",
       "2                        t                                                  c   \n",
       "3                        g                                                  c   \n",
       "4                        g                                                  c   \n",
       "...                    ...                                                ...   \n",
       "18159372  agctccgagctctagt                                    agctccgagtctagt   \n",
       "18159373                cg                                                  c   \n",
       "18159374                 c                                             ccgggg   \n",
       "18159375                ac                                                  a   \n",
       "18159376                 c  cgccatccgctgacgatccttgccgtatttcttttgcaaggccttg...   \n",
       "\n",
       "          GENOME_INDEX  ...  \\\n",
       "0                 1849  ...   \n",
       "1                 1977  ...   \n",
       "2                 4013  ...   \n",
       "3                 7362  ...   \n",
       "4                 7585  ...   \n",
       "...                ...  ...   \n",
       "18159372       4338587  ...   \n",
       "18159373       4379044  ...   \n",
       "18159374       4383144  ...   \n",
       "18159375       4400660  ...   \n",
       "18159376       4409797  ...   \n",
       "\n",
       "                                               IMAGE_MD5SUM  \\\n",
       "0         {'02-0958-22A197-1-14': 'a587bac9ad2a0ebd36274...   \n",
       "1         {'02-0958-22A197-1-14': 'a587bac9ad2a0ebd36274...   \n",
       "2         {'02-0958-22A197-1-14': 'a587bac9ad2a0ebd36274...   \n",
       "3         {'02-0958-22A197-1-14': 'a587bac9ad2a0ebd36274...   \n",
       "4         {'02-0958-22A197-1-14': 'a587bac9ad2a0ebd36274...   \n",
       "...                                                     ...   \n",
       "18159372  {'10-YA00166043-YA00166043-1-14': 'e151041dd9b...   \n",
       "18159373  {'10-YA00166043-YA00166043-1-14': 'e151041dd9b...   \n",
       "18159374  {'10-YA00166043-YA00166043-1-14': 'e151041dd9b...   \n",
       "18159375  {'10-YA00166043-YA00166043-1-14': 'e151041dd9b...   \n",
       "18159376  {'10-YA00166043-YA00166043-1-14': 'e151041dd9b...   \n",
       "\n",
       "                                  FTP_PATH  \\\n",
       "0         /well/bag/jeffk/release_staging/   \n",
       "1         /well/bag/jeffk/release_staging/   \n",
       "2         /well/bag/jeffk/release_staging/   \n",
       "3         /well/bag/jeffk/release_staging/   \n",
       "4         /well/bag/jeffk/release_staging/   \n",
       "...                                    ...   \n",
       "18159372  /well/bag/jeffk/release_staging/   \n",
       "18159373  /well/bag/jeffk/release_staging/   \n",
       "18159374  /well/bag/jeffk/release_staging/   \n",
       "18159375  /well/bag/jeffk/release_staging/   \n",
       "18159376  /well/bag/jeffk/release_staging/   \n",
       "\n",
       "                                           FTP_FILENAME_VCF  \\\n",
       "0         00/01/41/00/14100/site.02.iso.1.subject.0958.l...   \n",
       "1         00/01/41/00/14100/site.02.iso.1.subject.0958.l...   \n",
       "2         00/01/41/00/14100/site.02.iso.1.subject.0958.l...   \n",
       "3         00/01/41/00/14100/site.02.iso.1.subject.0958.l...   \n",
       "4         00/01/41/00/14100/site.02.iso.1.subject.0958.l...   \n",
       "...                                                     ...   \n",
       "18159372  00/02/95/61/29561/site.10.iso.1.subject.YA0016...   \n",
       "18159373  00/02/95/61/29561/site.10.iso.1.subject.YA0016...   \n",
       "18159374  00/02/95/61/29561/site.10.iso.1.subject.YA0016...   \n",
       "18159375  00/02/95/61/29561/site.10.iso.1.subject.YA0016...   \n",
       "18159376  00/02/95/61/29561/site.10.iso.1.subject.YA0016...   \n",
       "\n",
       "                                                  TREE_PATH  \\\n",
       "0             dat/CRyPTIC2/V2/02/0958/22A197/1/regenotyped/   \n",
       "1             dat/CRyPTIC2/V2/02/0958/22A197/1/regenotyped/   \n",
       "2             dat/CRyPTIC2/V2/02/0958/22A197/1/regenotyped/   \n",
       "3             dat/CRyPTIC2/V2/02/0958/22A197/1/regenotyped/   \n",
       "4             dat/CRyPTIC2/V2/02/0958/22A197/1/regenotyped/   \n",
       "...                                                     ...   \n",
       "18159372  dat/CRyPTIC2/V2/10/YA00166043/YA00166043/1/reg...   \n",
       "18159373  dat/CRyPTIC2/V2/10/YA00166043/YA00166043/1/reg...   \n",
       "18159374  dat/CRyPTIC2/V2/10/YA00166043/YA00166043/1/reg...   \n",
       "18159375  dat/CRyPTIC2/V2/10/YA00166043/YA00166043/1/reg...   \n",
       "18159376  dat/CRyPTIC2/V2/10/YA00166043/YA00166043/1/reg...   \n",
       "\n",
       "                                          TREE_FILENAME_VCF  FASTQ_MD5SUMS  \\\n",
       "0         site.02.subj.0958.lab.22A197.iso.1.v0.8.3.rege...            NaN   \n",
       "1         site.02.subj.0958.lab.22A197.iso.1.v0.8.3.rege...            NaN   \n",
       "2         site.02.subj.0958.lab.22A197.iso.1.v0.8.3.rege...            NaN   \n",
       "3         site.02.subj.0958.lab.22A197.iso.1.v0.8.3.rege...            NaN   \n",
       "4         site.02.subj.0958.lab.22A197.iso.1.v0.8.3.rege...            NaN   \n",
       "...                                                     ...            ...   \n",
       "18159372  site.10.subj.YA00166043.lab.YA00166043.iso.1.v...            NaN   \n",
       "18159373  site.10.subj.YA00166043.lab.YA00166043.iso.1.v...            NaN   \n",
       "18159374  site.10.subj.YA00166043.lab.YA00166043.iso.1.v...            NaN   \n",
       "18159375  site.10.subj.YA00166043.lab.YA00166043.iso.1.v...            NaN   \n",
       "18159376  site.10.subj.YA00166043.lab.YA00166043.iso.1.v...            NaN   \n",
       "\n",
       "          SEQTREAT_SAMPLE  MYKROBE_LINEAGE_NAME_1 MYKROBE_LINEAGE_NAME_2  \\\n",
       "0                   False               Lineage 2           lineage2.2.1   \n",
       "1                   False               Lineage 2           lineage2.2.1   \n",
       "2                   False               Lineage 2           lineage2.2.1   \n",
       "3                   False               Lineage 2           lineage2.2.1   \n",
       "4                   False               Lineage 2           lineage2.2.1   \n",
       "...                   ...                     ...                    ...   \n",
       "18159372            False               Lineage 2           lineage2.2.1   \n",
       "18159373            False               Lineage 2           lineage2.2.1   \n",
       "18159374            False               Lineage 2           lineage2.2.1   \n",
       "18159375            False               Lineage 2           lineage2.2.1   \n",
       "18159376            False               Lineage 2           lineage2.2.1   \n",
       "\n",
       "                 ENA  \n",
       "0         ERS5301054  \n",
       "1         ERS5301054  \n",
       "2         ERS5301054  \n",
       "3         ERS5301054  \n",
       "4         ERS5301054  \n",
       "...              ...  \n",
       "18159372      NO_ENA  \n",
       "18159373      NO_ENA  \n",
       "18159374      NO_ENA  \n",
       "18159375      NO_ENA  \n",
       "18159376      NO_ENA  \n",
       "\n",
       "[18159377 rows x 46 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpi_variants_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "939fa77c-73ba-49d6-9e3b-22caaf0598ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1849 c C\n",
      "1 1977 a A\n",
      "2 4013 t T\n",
      "3 7362 g G\n",
      "4 7585 g G\n",
      "5 9304 g G\n",
      "6 11312 g G\n",
      "7 11820 c C\n",
      "8 11879 t A\n",
      "9 14785 t T\n",
      "10 14861 g G\n",
      "11 15117 c C\n"
     ]
    }
   ],
   "source": [
    "for i, r in gpi_variants_df.iterrows():\n",
    "    print(i, r['GENOME_INDEX'], r['REF'], full_sequence[ r['GENOME_INDEX'] -1])\n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b31446d6-a808-4ba7-a84a-70aeec5032fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7119\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(cryptic_labels)):\n",
    "    if cryptic_labels[k] == 'site.05.subj.LR-2285.lab.FN-00492-18.iso.1':\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ed8be5f-153f-4844-863a-e156da74bc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15228"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(genomes_df[genomes_df['BELONGS_GPI']==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09c75730-c3a6-4126-89ef-fe8c3b8db565",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = variant_df[variant_df['UNIQUEID'] == 'site.00.subj.LE10KTB_23.lab.7627572.iso.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96fcf3c3-37fd-4765-9852-48b64e9ff6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_csv(project_dir + '/nick2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3781ec-2ff2-41dc-b21d-055b4b2cf8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = variant_df[variant_df['UNIQUEID'] == 'site.02.subj.0005.lab.2014222011.iso.1']\n",
    "df_2 = variant_df[variant_df['UNIQUEID'] == 'site.02.subj.0007.lab.2014222016.iso.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95245c0e-6727-4a7a-a335-51906da06a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd = pd.merge(df_1, df_2, how='outer', on = 'GENOME_INDEX')\n",
    "for i, r in df_cd.iterrows():\n",
    "    df_cd.at[i,'refseq'] = full_sequence[r['GENOME_INDEX']-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b3304-b51f-4a47-a1f8-7e53621fcdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = 0\n",
    "for i, r in df_cd.iterrows():\n",
    "    if (not(r['VARIANT_x'] == r['VARIANT_y'])):\n",
    "        distance +=1\n",
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8cddaa-98c5-408a-a527-50d78b37f351",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd.to_csv(project_dir  +'/nick.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acf169b-5ab4-4722-b5eb-81c4b7868302",
   "metadata": {},
   "outputs": [],
   "source": [
    "nick = df_cd.query('ALT_x == ALT_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da44ae-00fb-497e-a881-5cbe0129ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd4ae592-aff2-4ecb-9611-d658c5abb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryptic_labels = np.load(cryptic_input_path + '/GPI_SNP_DISTANCES_LABELS.npy')\n",
    "cryptic_distances=np.load(cryptic_input_path + '/GPI_SNP_DISTANCES_VALUES.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0414b7-d357-42a7-9ca0-e7875342f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cryptic_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0ec8fdc-65dc-47b7-b523-21e79e930183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distances(snp_pos_dict_1, snp_pos_dict_2):\n",
    "    distance_dict = {}\n",
    "    for k1, v1 in snp_pos_dict_1.items():\n",
    "        for k2, v2 in snp_pos_dict_2.items():\n",
    "            sd = v1.symmetric_difference(v2)\n",
    "            temp = {x[:-1] for x in sd}   # Only count variants with different nt in SNP as one mutation\n",
    "            #temp = sd\n",
    "            d = len(temp)\n",
    "            distance_dict[(k1, k2)] = d\n",
    "            distance_dict[(k2, k1)] = d\n",
    "    return(distance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0160212e-2424-4c09-b241-2c021821ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nick_distances(id_1, id_2):\n",
    "    samp_1 = cryptic_labels[id_1]\n",
    "    samp_2 = cryptic_labels[id_2]\n",
    "    id_1 = id_dict[samp_1]\n",
    "    id_2 = id_dict[samp_2]\n",
    "    snp_pos_dict = {}\n",
    "    snp_1 = set([str(pos) + snp for (pos, snp) in variant_dict[id_1]]) \n",
    "    snp_2 = set([str(pos) + snp for (pos, snp) in variant_dict[id_2]]) \n",
    "    snp_pos_dict[samp_1] = snp_1\n",
    "    snp_pos_dict[samp_2] = snp_2\n",
    "    a = generate_distances(snp_pos_dict, snp_pos_dict)\n",
    "    return a[(samp_1, samp_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6384922-d3d1-48ea-a6a8-378d6ee88984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7119 6689 27 543\n",
      "624.0\n",
      "7119 6956 20 539\n",
      "608.0\n",
      "7119 6978 28 548\n",
      "611.0\n",
      "7119 7106 19 557\n",
      "642.0\n",
      "7119 7324 27 561\n",
      "642.0\n",
      "7119 7401 22 558\n",
      "623.0\n",
      "7119 7408 21 538\n",
      "609.0\n",
      "7119 7722 9 552\n",
      "645.0\n",
      "7119 7858 16 535\n",
      "600.0\n",
      "7119 7889 9 551\n",
      "642.0\n",
      "7119 7908 14 534\n",
      "599.0\n",
      "7119 7910 18 533\n",
      "616.0\n",
      "7119 7915 4 528\n",
      "615.0\n",
      "7119 7948 3 532\n",
      "605.0\n",
      "7119 7965 18 551\n",
      "636.0\n",
      "7119 7979 16 550\n",
      "631.0\n",
      "7119 7988 23 553\n",
      "634.0\n",
      "7119 8033 18 550\n",
      "635.0\n",
      "7119 8160 15 552\n",
      "635.0\n",
      "7119 8236 24 556\n",
      "639.0\n",
      "7119 8318 5 548\n",
      "637.0\n",
      "7119 8321 6 554\n",
      "645.0\n",
      "7119 8325 27 561\n",
      "644.0\n",
      "7119 8333 9 554\n",
      "647.0\n",
      "7119 8350 16 531\n",
      "608.0\n",
      "7119 8394 23 557\n",
      "640.0\n",
      "7119 8415 21 556\n",
      "639.0\n",
      "7119 8440 15 537\n",
      "600.0\n",
      "7119 8942 20 553\n",
      "638.0\n"
     ]
    }
   ],
   "source": [
    "i = 7119\n",
    "for j in range(len(cryptic_labels)):\n",
    "    if j < 20:\n",
    "        continue\n",
    "    if i==j:\n",
    "        continue\n",
    "    \n",
    "    if abs(cryptic_distances[i,j]- nick_distances(i,j))>400:\n",
    "        temp = genomes_df[genomes_df['UNIQUEID'] == cryptic_labels[j]]\n",
    "        print (i, j, cryptic_distances[i,j], nick_distances(i,j))\n",
    "        for j, r in temp.iterrows():\n",
    "            print(r['SNP_DISTANCE_TO_H37rV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb37f318-6a33-44bc-9bec-ec45ec44a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_pos_dict = {}\n",
    "snp_1 = set([str(pos) + snp for (pos, snp) in variant_dict[id_dict[samp_1]]]) \n",
    "snp_2 = set([str(pos) + snp for (pos, snp) in variant_dict[id_dict[samp_2]]]) \n",
    "snp_pos_dict[samp_1] = snp_1\n",
    "snp_pos_dict[samp_2] = snp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5d3ba-29e4-48da-a43a-c6a32e95ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distances(snp_pos_dict_1, snp_pos_dict_2):\n",
    "    distance_dict = {}\n",
    "    for k1, v1 in snp_pos_dict_1.items():\n",
    "        for k2, v2 in snp_pos_dict_2.items():\n",
    "            sd = v1.symmetric_difference(v2)\n",
    "            #temp = {x[:-1] for x in sd}   # Only count variants with different nt in SNP as one mutation\n",
    "            temp = sd\n",
    "            d = len(temp)\n",
    "            distance_dict[(k1, k2)] = d\n",
    "            distance_dict[(k2, k1)] = d\n",
    "    return(distance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb9eaf6-2fea-4682-9417-9967d5880504",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_distances(snp_pos_dict, snp_pos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f53e455-16ce-4597-875e-34d059ec3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dict = {}\n",
    "for comparators in tqdm(pairwise_list):\n",
    "    parallel_output = Parallel(n_jobs=-1)(delayed(generate_distances)(snp_pos_dict[pos1], snp_pos_dict[pos2]) for (pos1, pos2) in comparators)\n",
    "    for output_dict in parallel_output:\n",
    "        for (k, v) in output_dict.items():\n",
    "            master_dict[k] = v\n",
    "with open(project_dir + '/master_distance_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(master_dict, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a76331e-942d-4ee7-8391-9f44fa51ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for k, v in master_dict.items():\n",
    "    ids.append(k[0])\n",
    "ids = list(set(ids))\n",
    "with open(project_dir+'/tb_seq_distances.phy', 'w') as f:\n",
    "    f.write('%d\\n' % len(ids))\n",
    "    for idref in ids:\n",
    "        f.write('seq_'+str(idref))\n",
    "        for opref in ids:\n",
    "            f.write('\\t%s' % str(abs(master_dict[idref, opref])))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38020a2d-eb43-4999-a94a-d887fcbba4a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Produce and save mutations per position (first produce files containing blocks of 10,000 nt values for all sequences in tree - will take about 36 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ab585-aaff-4ef5-8f31-46e766323fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variant_positions = []\n",
    "for k, v in variant_dict.items():\n",
    "    if k in distinct_sequence_names:\n",
    "        for (pos, snp) in v:\n",
    "            variant_positions.append(pos-1)     #Cryptic is 1 indexed\n",
    "sorted_variant_position_list = list(set(variant_positions))\n",
    "sorted_variant_position_list.sort()\n",
    "pos_id_dict = dict(zip(sorted_variant_position_list, range(len(set(variant_positions)))))\n",
    "id_pos_dict = dict(zip(range(len(set(variant_positions))), sorted_variant_position_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffa22c4-4035-4951-9272-4fe8b1219382",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tb_variants_sequence_length = len(pos_id_dict)\n",
    "chunk_size = 1000\n",
    "num_chunks = math.ceil(tb_variants_sequence_length/chunk_size)\n",
    "chunk_variant_dict = defaultdict(lambda: defaultdict(list))\n",
    "for k, v in variant_dict.items():\n",
    "    if k in distinct_sequence_names:\n",
    "        for (pos, snp) in v:\n",
    "            chunk = int(pos_id_dict[pos-1]/chunk_size)\n",
    "            position_in_chunk = pos_id_dict[pos-1] % chunk_size\n",
    "            chunk_variant_dict[chunk][k].append((position_in_chunk,snp.upper()))\n",
    "print(\"Built dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4903bc-3222-4018-a92e-cf0f1effc52f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_tb_variant_sequence = ''.join([full_sequence[pos] for pos in sorted_variant_position_list])\n",
    "if full_run == True:\n",
    "    for chunk in tqdm(range(num_chunks)):\n",
    "            start_pos = chunk * chunk_size\n",
    "            end_pos = min(tb_variants_sequence_length, start_pos + chunk_size)\n",
    "            variant_sequence_dict = {}\n",
    "            seq_chunk = [{x} for x in full_tb_variant_sequence[start_pos:end_pos]]\n",
    "            for seq_id in distinct_sequence_names:\n",
    "                temp = copy.copy(seq_chunk)\n",
    "                if seq_id in chunk_variant_dict[chunk]:\n",
    "                    for (pos, snp) in chunk_variant_dict[chunk][seq_id]:\n",
    "                        temp[pos] = {snp}\n",
    "                variant_sequence_dict['seq_'+str(seq_id)] = temp\n",
    "            with open(dictionary_dir + '/variant_dictionary_'+str(start_pos)+'_'+str(end_pos)+'_' + '.pkl', 'wb') as f:\n",
    "                   pickle.dump(variant_sequence_dict, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7730ef-05b3-46e6-b3ab-a58bdd82c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_list = util.list_files(dictionary_dir)\n",
    "filename_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7750a2-60f6-41fd-acb6-307438824c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if full_run==True:   #mutation_count_dir\n",
    "if 1==1:\n",
    "    res = []\n",
    "    filename_list = util.list_files(dictionary_dir)\n",
    "    for filename in tqdm([filename_list[0]]):\n",
    "        temp_2 = filename.split('_')\n",
    "        start_pos = int(temp_2[2])\n",
    "        end_pos = int(temp_2[3])\n",
    "        parallel_output = Parallel(n_jobs=-1)(delayed(generate_mutation_counts)(dictionary_dir+'/' + filename, core_number) for core_number in range(10))\n",
    "        temp = []\n",
    "        for x in parallel_output:\n",
    "            temp+=x[2]\n",
    "        res.append((int(parallel_output[0][0]), int(parallel_output[0][1]), temp))\n",
    "        with open(test_dir + '/mutation_counts_'+str(start_pos)+'_'+str(end_pos)+'_' + '.pkl', 'wb') as f:\n",
    "                   pickle.dump((int(parallel_output[0][0]), int(parallel_output[0][1]), temp), f) \n",
    "    with open(test_dir + '/all_mutation_counts.pkl', 'wb') as f:\n",
    "        pickle.dump(res, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789a34c-e491-4d71-851d-ac8230f2f004",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    non_zero_mutation_counts = []\n",
    "    for x in res:\n",
    "        non_zero_mutation_counts += x[2]\n",
    "    zero_and_non_zero_mutation_counts = []\n",
    "    for i in range(len(full_sequence)):\n",
    "        if i in pos_id_dict:\n",
    "            zero_and_non_zero_mutation_counts.append(non_zero_mutation_counts[pos_id_dict[i]])\n",
    "        else:\n",
    "            zero_and_non_zero_mutation_counts.append(0)\n",
    "with open(mutation_count_dir + '/zero_and_non_zero_mutation_counts.pkl', 'wb') as f:\n",
    "        pickle.dump(zero_and_non_zero_mutation_counts, f)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958cf361-756d-4c83-a9d4-d7df50a81587",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == False:\n",
    "    with open(mutation_count_dir + '/zero_and_non_zero_mutation_counts.pkl', 'rb') as f:\n",
    "        zero_and_non_zero_mutation_counts = pickle.load(f)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5186cf5-e207-4c3f-bc83-a8bf5b4f28b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240d70ef-14d8-4bf2-a360-0e611506a410",
   "metadata": {},
   "source": [
    "#### Calculate probabilites for annotated (and reannotated PGAP) CDS regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b3bf0-ecda-4573-8e66-7fcde8acd18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_boundaries = []\n",
    "for genome_record in SeqIO.parse(seq_dir + '/' + tb_genome_filename, \"genbank\"):\n",
    "    for feature in genome_record.features:\n",
    "        if feature.type == 'CDS':\n",
    "            a = feature.qualifiers  \n",
    "            if a.get(\"pseudo\") == None:\n",
    "                pseudo = False\n",
    "            else:\n",
    "                pseudo = True\n",
    "            cds_boundaries.append((a.get(\"locus_tag\")[0], pseudo, a.get(\"product\")[0], int(feature.location.start), int(feature.location.end), int(feature.location.strand)))   \n",
    "reannotated_cds_boundaries = []\n",
    "for genome_record in SeqIO.parse(project_dir + '/annot.gbk', \"genbank\"):\n",
    "    for feature in genome_record.features:\n",
    "        if feature.type == 'CDS':\n",
    "            a = feature.qualifiers  \n",
    "            if a.get(\"pseudo\") == None:\n",
    "                pseudo = False\n",
    "            else:\n",
    "                pseudo = True\n",
    "            reannotated_cds_boundaries.append((a.get(\"locus_tag\")[0], pseudo, a.get(\"product\")[0], int(feature.location.start), int(feature.location.end), int(feature.location.strand)))   \n",
    "cds_boundaries.sort(key = lambda x: x[3])\n",
    "reannotated_cds_boundaries.sort(key = lambda x: x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e647b-16e4-4c53-8c59-787dacbd80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_df = pd.read_csv(project_dir+'/mutation_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad47ede-8f39-4d1e-8a59-48ed5618e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_and_non_zero_mutation_counts = []\n",
    "for i, r in mutation_df.iterrows():\n",
    "    zero_and_non_zero_mutation_counts.append(r['Num_Mutations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f72d73-f975-4510-9896-aad8e3c4b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp =[]\n",
    "for (locus, pseudo, product, start, stop, strand) in cds_boundaries:\n",
    "    if pseudo == False:\n",
    "        if strand == 1:\n",
    "            #temp.append(mutation_bin_probability(old_mutation_count_list[start:stop]))\n",
    "            temp.append(mutation_bin_probability(zero_and_non_zero_mutation_counts[start:stop]))\n",
    "        else:\n",
    "            #temp.append(mutation_bin_probability(reversed(old_mutation_count_list[start:stop])))\n",
    "            temp.append(mutation_bin_probability(reversed(zero_and_non_zero_mutation_counts[start:stop])))\n",
    "scores = []\n",
    "for x in temp:\n",
    "    if x == 2:\n",
    "        scores.append(x)\n",
    "    else:\n",
    "        scores.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b9d7e-f827-4b4d-921e-f63b44f50ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(scores, bins =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7fa87-aa03-4ef1-971f-22b814e71b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot([x for x in zero_and_non_zero_mutation_counts if x < 200], bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e249c42-675d-48f0-a706-68cdd70250a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, i in enumerate(zero_and_non_zero_mutation_counts):\n",
    "    if i > 10000:\n",
    "        print(n, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f6321f-5a4e-481b-80dd-b73ec38fbd18",
   "metadata": {},
   "source": [
    "#### Identify potential ORFS (min length 200) in inter-CDS regions of standard annotation and output to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3b790-e301-4599-a155-74a0e7ae05ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORFFinder = orffn.ORF_Finder()\n",
    "trans = util.Translator()\n",
    "min_intergenic_length = 100\n",
    "details =  []\n",
    "results =[]\n",
    "for i, (locus, pseudo, product, start, stop, strand) in enumerate(cds_boundaries):\n",
    "    if i < len(cds_boundaries) - 1:\n",
    "        if cds_boundaries[i+1][3] > stop + min_intergenic_length:\n",
    "            a =ORFFinder.max_orf(stop-40, cds_boundaries[i+1][3]+40, 1e-20, output_all_orfs = False, min_orf_length = 200)\n",
    "            if not(a==(0,0,0)):\n",
    "                ov = 0\n",
    "                info = ('','','','','','','')\n",
    "                for i, (loc, pse, pro, sta, sto, stra) in enumerate(reannotated_cds_boundaries):\n",
    "                    if a[1] > sta and a[0] < sto:\n",
    "                        ov = (min(a[1], sto) - max(a[0], sta)) / (sto - sta)\n",
    "                        if ov > 0.3:\n",
    "                            info =  (loc, pse, pro, sta, sto, stra, ov)\n",
    "                        \n",
    "                ov = 0\n",
    "                myco_info = ('','','','','')\n",
    "                for i, (loc, sta, sto, stra) in enumerate(mycobrowser_features):\n",
    "                    if a[1] > sta and a[0] < sto:\n",
    "                        ov = (min(a[1], sto) - max(a[0], sta)) / (sto - sta)\n",
    "                        if ov > 0.3:\n",
    "                            myco_info =  (loc, sta, sto, stra, ov)\n",
    "                        \n",
    "                sequ = trans.translate_sequence(full_sequence[a[0]:a[1]], a[2], 0)\n",
    "                details.append([a, sequ])\n",
    "                results.append([a[0],a[1],a[2],a[3],info[0],info[1],info[2],info[3],info[4],info[5],info[6],myco_info[0],myco_info[1],myco_info[2],myco_info[3],myco_info[4]])\n",
    "results_df = pd.DataFrame(results, columns = ['start_pos','end_pos','strand','score','PGAP_ref','PGAP_pseudogene','PGAP_product', 'PGAP_start', 'PGAP_end','PGAP_strand', 'PGAP_overlap', 'Mycob_ref','Mycob_start', 'Mycob_end','Mycob_strand', 'Mycob_overlap'])\n",
    "results_df.to_csv(project_dir + '/cds_candidates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1542c9b-7d8d-4bcc-8104-edf07608f227",
   "metadata": {},
   "source": [
    "#### Calculate probabilities for regions in Smith et al 2021 and plot histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8a8a4-503a-43e1-86a7-48a9cdb0155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('F:/Datasets/Data_From_Publications/Smith_2021.xlsx')\n",
    "df1 = pd.read_excel(xls, 'Table S3', header=3)\n",
    "co_ords = []\n",
    "for i, r in df1.iterrows():\n",
    "    if r['Classification'] == 'Novel':\n",
    "        if r['Strand'] == '+':\n",
    "            co_ords.append([int(r['Start Coordinate']-1), int(r['Stop Coordinate']), 1])\n",
    "        else:\n",
    "            co_ords.append([int(r['Stop Coordinate'] - 1), int(r['Start Coordinate']),-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58096b14-401d-45d2-bf2f-4a45c6b02730",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "probs = []\n",
    "for x in co_ords:\n",
    "    if x[2] == 1:\n",
    "        a = (mutation_bin_probability(mutation_count_list[x[0]:x[1]]))\n",
    "    else:\n",
    "        a = (mutation_bin_probability(reversed(mutation_count_list[x[0]:x[1]])))\n",
    "    if a == 2:\n",
    "        probs.append(2)\n",
    "    else:\n",
    "        probs.append(a[1])\n",
    "    print(x, abs(x[1]-x[0]), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c42903-2248-4181-aa6a-99cb62c354ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(probs, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198ce0ae-2b01-482b-83cb-93c720537916",
   "metadata": {},
   "source": [
    "#### Find all (maximal nested) ORFs and filter out ORFS on opposite strand which would have same non-synonymous positions with larger ORF on other strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea12a609-41c4-402f-a220-c09b6cc10fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ORFFinder = orffn.ORF_Finder(full_sequence)\n",
    "a = ORFFinder.max_orf(0, 4411532, output_orfs = 'Nested', min_orf_length = 50)\n",
    "a.sort(key = lambda x: x[3], reverse = True)\n",
    "orf_list = [a[0]]\n",
    "for x in tqdm(a[1:]):\n",
    "    matched = 0\n",
    "    for v in orf_list:\n",
    "        if v[0]<=x[0] and v[1]>=x[1]:\n",
    "            if x[2] == v[2]:\n",
    "                if (v[0] - x[0])%3 == 0:\n",
    "                    matched = 1\n",
    "                    break\n",
    "            else:\n",
    "                if (v[0] - x[0])%3 == 1:\n",
    "                    matched = 1\n",
    "                    break\n",
    "    if matched == 0:\n",
    "        orf_list.append(x)\n",
    "orf_list.sort(key = lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eaa87f-ac8c-4fa4-9b70-241cfda7bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for (start, stop, strand, length) in orf_list:\n",
    "    if strand == 1:\n",
    "        temp.append(mutation_bin_probability(zero_and_non_zero_mutation_counts[start:stop]))\n",
    "    else:\n",
    "        temp.append(mutation_bin_probability(reversed(zero_and_non_zero_mutation_counts[start:stop])))\n",
    "scores = []\n",
    "for x in temp:\n",
    "    if x == 2:\n",
    "        scores.append(x)\n",
    "    else:\n",
    "        scores.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c310ef26-e928-4ee5-8f96-8f379b56eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(scores, bins =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd8435-6f3a-4389-baf3-46f4f7d741b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = []\n",
    "for x in orf_list:\n",
    "    prob.append(x[4])\n",
    "sns.histplot(prob, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2769ef-9358-406c-a22a-e88be6b93338",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_features = []\n",
    "for genome_record in SeqIO.parse(project_dir + '/annot.gbk', \"genbank\"):\n",
    "    for feature in genome_record.features:\n",
    "        if feature.type != 'source':\n",
    "            annotated_features.append((int(feature.location.start), int(feature.location.end), int(feature.location.strand)))   \n",
    "for genome_record in SeqIO.parse(seq_dir + '/' + tb_genome_filename, \"genbank\"):\n",
    "    for feature in genome_record.features:\n",
    "        if feature.type != 'source':\n",
    "            annotated_features.append((int(feature.location.start), int(feature.location.end), int(feature.location.strand)))   \n",
    "annotated_features.sort(key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd77402-5afe-4b13-9f1e-1a14e569d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_overlapping_orfs = []\n",
    "for i, orf in enumerate(orf_list):\n",
    "    max_ov = 0\n",
    "    for (sta, sto, stra) in annotated_features:\n",
    "        if orf[0] < sto and orf[1] > sta:\n",
    "            ov = (min(orf[1], sto) - max(orf[0], sta)) / (orf[1] - orf[0])\n",
    "            max_ov = max(ov, max_ov)\n",
    "    if max_ov < 0.1:\n",
    "        non_overlapping_orfs.append(orf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2683970-7a45-419b-875a-0ca44f8b7a66",
   "metadata": {},
   "source": [
    "#### Produce FASTA file with CDS candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8564e695-944e-448f-b6e1-4936f0ae0f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_overlapping_orfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214885e2-505b-42a5-a423-dd784b69cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = util.Translator()\n",
    "temp = []\n",
    "for x in non_overlapping_orfs:\n",
    "    if x[4] < 1e-5 or x[4]==2:\n",
    "        if x[2] == 1:\n",
    "            prot = trans.translate_sequence(full_sequence[x[0]:x[1]], 1, 0)\n",
    "        else:\n",
    "            prot = trans.translate_sequence(util.reverse_complement(full_sequence[x[0]:x[1]]), 1, 0)\n",
    "        name = 'Start_'+str(x[0])+'_Stop_'+str(x[1])+'_Strand_'+str(x[2])\n",
    "        temp.append([name, prot[:-1]])\n",
    "util.produce_fasta_file(temp, project_dir + '/' + 'tb_orf_candidates.faa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dbfb10-9277-4b21-9446-8fee25d4271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "blastfn.run_tblastn('F:/Datasets/BLAST/actinobacteria_ref_genomes', 'tb_orf_candidates.faa', 'blastdb_sourceseq_actinobacteria', e_value = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3b5056-e487-4742-8f14-b64008c781ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = []\n",
    "for x in orf_list:\n",
    "    prob.append(x[4])\n",
    "sns.histplot(prob, bins =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93696eef-27de-4070-b4d8-3a47e7319a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [x for x in orf_list if x[4] <1e-3]\n",
    "len(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0289a929-0d29-4246-a700-44840af34050",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Legacy code (might be useful - this is when tree was defined based on \"optimal splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffb9d2-7d32-4666-8b4f-f74a2f4a441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tree(species_to_split, position):\n",
    "    temp =  set([x[0] for x in reduced_position_dict[position][1:]]).intersection(species_to_split)\n",
    "    temp_2 = species_to_split - temp\n",
    "    if len(temp_2) > 1 and len(temp) > 1:\n",
    "        return ([(position, temp, len(temp)), (position, temp_2, len(temp_2))])\n",
    "    else:\n",
    "        return([(-1, species_to_split, len(species_to_split))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb7982-32e0-4eb1-afab-04b940de7ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_split_position(species_to_split_list):\n",
    "    best_split_num = 1e20\n",
    "    best_position = 0\n",
    "    splits_achieved_dict = {}\n",
    "    for k, v in reduced_position_dict.items():\n",
    "        mutation_count = 0\n",
    "        worst_count = 0\n",
    "        for species_to_split in species_to_split_list:\n",
    "            num_species_to_split = len(species_to_split)\n",
    "            optimal_split = int(num_species_to_split/2)\n",
    "            mutation_count += abs(len(set([x[0] for x in v[1:]]).intersection(species_to_split)) - optimal_split)\n",
    "            worst_count += optimal_split \n",
    "        splits_achieved_dict[k] = mutation_count\n",
    "        if abs(mutation_count) < abs(best_split_num):\n",
    "            best_position = k\n",
    "            best_split_num = abs(mutation_count)\n",
    "    return((best_position, best_split_num), (worst_count, splits_achieved_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79dd452-3ecc-4b58-9fa0-1f8950d400fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "snps_to_use = []\n",
    "reduced_position_dict =  {}\n",
    "for k, v in position_dict.items():\n",
    "    if len(v) >=100:\n",
    "        reduced_position_dict[k] = v\n",
    "print(len(position_dict), len(reduced_position_dict))\n",
    "\n",
    "\n",
    "all_species = [[-1,set(x for x in range(len(id_dict))),99,True]]\n",
    "pos = optimal_split_position([x[1] for x in all_species])[0][0]\n",
    "snps_to_use.append(pos)\n",
    "split_results = [split_tree(all_species[0][1], pos)]\n",
    "print( [(x[0], x[2]) for x in split_results[0]] )\n",
    "for i in range(1,50):\n",
    "    if i ==10:\n",
    "        break\n",
    "    start = time.process_time()\n",
    "    split_results.append([])\n",
    "    optimal_split_output = optimal_split_position([x[1] for x in split_results[i-1]])  \n",
    "    splits_achieved_dict = optimal_split_output[1][1]\n",
    "    optimal_split_score = optimal_split_output[1][0]\n",
    "    posn = optimal_split_output[0]\n",
    "    score_list = []\n",
    "    for k, v in splits_achieved_dict.items():\n",
    "        score_list.append(v)\n",
    "    score_list.sort()\n",
    "    score_p50 = score_list[int(len(score_list)/2)]\n",
    "    for k, v in splits_achieved_dict.items():\n",
    "        if v >= score_p50:#optimal_split_score - 1000:\n",
    "            reduced_position_dict.pop(k)\n",
    "    print(len(reduced_position_dict))\n",
    "    pos= posn[0]\n",
    "    snps_to_use.append(pos)\n",
    "    split_score = posn[1]\n",
    "    successful_splits = 0\n",
    "    for x in split_results[i-1]:\n",
    "        temp = split_tree(x[1], pos) \n",
    "        if len(temp) == 1:\n",
    "            split_results[i].append(temp[0])\n",
    "        else:\n",
    "            successful_splits +=1\n",
    "            split_results[i].append(temp[0])\n",
    "            split_results[i].append(temp[1])\n",
    "    print(max([x[2] for x in split_results[i]]))\n",
    "    print (time.process_time() - start)\n",
    "    print([(x[0], x[2]) for x in split_results[i]])\n",
    "    if successful_splits == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a422156-b290-454c-b856-aca6e7fb5bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimal_split_score)\n",
    "splits_achieved_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aef85b7-feb1-4670-8967-021f0a358395",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c4d9a-7759-4989-a706-0b2a0c868c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(x[0],x[2]) for x in split_results[2] if x[2] > 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b74d58-14a0-443a-96ab-8aa78a0fe0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for res in split_results:\n",
    "    for info in res:\n",
    "        temp.append(info[0])\n",
    "snps = set(temp)\n",
    "snps.remove(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf9a4de-bd5b-40b8-a247-9a907ed4c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mutation_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25046046-2644-4c23-aaa4-8176fb887d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mutation_count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9431024b-eb44-45a3-b7b5-4e5b2a38a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(mutation_count_list, bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f331c-d6de-40d1-9cb5-8362c832e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [x[1] for x in split_results[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc3f00-fb7d-4304-a5e1-0d94b4559401",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684a584-361d-42d3-9cf4-45cbed3e5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_ids = []\n",
    "variants = []\n",
    "for k, v in tqdm(variant_dict.items()):\n",
    "    if set(v) in variants:\n",
    "        continue\n",
    "    else:\n",
    "        variants.append(set(v))\n",
    "        distinct_ids.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca14ce1-f2b9-4a70-91b0-8e3f0d2f637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(variant_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88834d4c-38af-4314-b4ea-9f99491bb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(distinct_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618ef69d-d9a6-4cfd-aa4b-d9248c9aafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pow(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db1ff2b-c3e3-4011-b49b-fbdb29bd9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(position_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f2c251-666a-428b-94bd-ba7bb5f5ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq_length = 100\n",
    "\n",
    "with open(project_dir +'/test.faa', 'rb') as f:\n",
    "    sequence_to_score_dict = {}\n",
    "    sequence_to_score_dict['seq1'] = [{x} for x in 'AAATTTT']\n",
    "    sequence_to_score_dict['seq2'] = [{x} for x in 'AAACTTT']\n",
    "    sequence_to_score_dict['seq3'] = [{x} for x in 'AAAGTTT']\n",
    "    sequence_to_score_dict['seq4'] = [{x} for x in 'AAAATTT']\n",
    "master_tree2= ete3.Tree(project_dir + '/' + 'testtree.nwk')\n",
    "for node in master_tree2.traverse(\"postorder\"):\n",
    "    if node.is_leaf():\n",
    "        node.add_features(seq = sequence_to_score_dict[node.name])\n",
    "    else:\n",
    "        children = node.children\n",
    "        node.add_features(seq = fitch_1(children[0].seq, children[1].seq))\n",
    "\n",
    "#for k, v in sequence_to_score_dict.items():              \n",
    "    #seq_length = len(v)\n",
    "    #break\n",
    "mutation_counts = [0 for i in range(seq_length)]\n",
    "for node in master_tree2.traverse(\"preorder\"):\n",
    "    if node.is_leaf():\n",
    "        continue\n",
    "    if node.is_root():\n",
    "        node.seq = [{list(x)[0]} for x in node.seq]\n",
    "    children = node.children\n",
    "    mutations = []\n",
    "    child_sequences = []\n",
    "    for child in children:\n",
    "        (temp_1, temp_2) = fitch_2(node.seq ,child.seq)\n",
    "        child_sequences.append(temp_1)\n",
    "        child.seq = temp_1\n",
    "        mutations.append(temp_2)\n",
    "   \n",
    "    temp = []\n",
    "    for n, (h, i, j) in enumerate(zip(mutation_counts, mutations[0], mutations[1])):\n",
    "        if i + j == 0:\n",
    "            temp.append(h)\n",
    "        elif i + j == 1:\n",
    "            temp.append(h+1)\n",
    "        else:\n",
    "            if child_sequences[0][i] == child_sequences[1][i]:\n",
    "                temp.append(h+1)\n",
    "            else:\n",
    "                temp.append(h+2)\n",
    "    mutation_counts = temp     \n",
    "print(mutation_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a476b-f081-4a48-8ee6-b6a7303fa3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7870105a-c5ba-45a9-8d63-3d735ac3b817",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "for i in range(10000):\n",
    "    for j in range(10000):\n",
    "        dict[(i,j)] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d95928-2bc1-42b3-86f9-06690358d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sequence[11874]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e1a48-9e58-4739-984d-4398c6d93e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "    position_dict = {}\n",
    "    variant_dict = {}\n",
    "    id_dict = {}\n",
    "    with open(project_dir + '/variant_df.pkl', 'rb') as f:\n",
    "        variant_df = pickle.load(f) \n",
    "        for i, r in tqdm(variant_df.iterrows()):\n",
    "            if r['GENOME_INDEX'] in [25, 11875]:\n",
    "                print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25068b8-0b87-488e-9d99-b3491dd6d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(r['GENOME_INDEX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35279fcc-dbdc-484d-8379-1de03846805e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
