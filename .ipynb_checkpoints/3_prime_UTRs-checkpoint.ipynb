{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5181b7-3b50-4aca-84d8-e6ad809c14fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "898a25bb-a79e-4516-9f4d-7315c4699f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from Bio import Entrez, SeqIO, AlignIO, pairwise2, Align, Seq, motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from scipy.stats import binom\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "from Comparative_Analysis import Sequence_Analysis_Routines as sar\n",
    "from Comparative_Analysis import Utilities as util\n",
    "from Comparative_Analysis import Alignment as align\n",
    "import random\n",
    "import copy\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "from Bio.Align.Applications import MuscleCommandline\n",
    "import re\n",
    "muscle_exe = 'C:/Users/nicho/Muscle/muscle3.8.31_i86win32.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a0b5574-5195-4364-a0c6-0f649d3f8d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'D:/Project_Data/Project_7'\n",
    "literature_datasets_dir = project_dir + '/Data_From_Publications'\n",
    "output_dir = project_dir + '/Output'\n",
    "refseq_dir = project_dir + '/NCBI_Dataset_Mycobacteria'\n",
    "num_cores = 8\n",
    "core_numbers = list(range(1, num_cores+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0450d244-1510-48ff-b251-40510173eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = util.list_dirs(refseq_dir)\n",
    "reference_species = 'GCF_000195955.2'\n",
    "outgroup_species = 'GCF_000696675.2'\n",
    "#species_list = species_list[4:6]    #For testing\n",
    "species_list_excl_ref = [x for x in species_list if x!= reference_species]\n",
    "num_species = len(species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21eaf76c-ebec-4227-9ee2-0ee10c857a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_genome_record = next(SeqIO.parse(refseq_dir + '/'+reference_species+'/genomic.gbff', \"genbank\"))\n",
    "reference_sequence_length = len(str(ref_genome_record.seq))\n",
    "translator = util.Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f307521b-c70e-44d1-a4c3-0a993e290497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.32it/s]\n"
     ]
    }
   ],
   "source": [
    "reference_list = [[reference_species, str(ref_genome_record.seq)]]\n",
    "util.produce_fasta_file(reference_list, 'D:/H37Rv.faa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8665e30-5cdc-4d28-9bb4-569344f3e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_blast_output(infile_loc, outfile_loc, top_hit_only = False):\n",
    "    blast_results = pd.read_csv(infile_loc, header = None)\n",
    "    blast_results.columns = ['query_ref', 'target_ref', 'query_length', 'subject_length', 'percent_identical_matches','alignment_length', 'number_mismatches', 'number_of_gap_openings', 'query_start_alignment', 'query_end_alignment', 'target_start_alignment', 'target_end_alignment', 'e_value', 'bit_score']\n",
    "    for i, r in blast_results.iterrows():\n",
    "        blast_results.at[i, 'query_species'] = '_'.join(r.query_ref.split('_')[0:2])\n",
    "        blast_results.at[i, 'target_species'] = '_'.join(r.target_ref.split('_')[0:2])\n",
    "    blast_results['query_species_name'] = blast_results['query_species'].map(names_dict)\n",
    "    blast_results['target_species_name'] = blast_results['target_species'].map(names_dict)\n",
    "    if top_hit_only == True:\n",
    "        blast_results = blast_results.loc[blast_results.groupby(['query_ref','target_species'])['bit_score'].idxmax()]\n",
    "    blast_results['species_count'] = blast_results.groupby('query_ref')['query_ref'].transform('size')\n",
    "    with open(outfile_loc, 'wb') as f:\n",
    "        pickle.dump(blast_results, f)\n",
    "    return blast_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8c8ad6-b9be-4076-a34e-083317a6391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_reciprocal_best_hits(query_df, reverse_query_df, outfile_loc):\n",
    "    temp_1_dict = {}\n",
    "    temp_2_dict = {}\n",
    "    for i, r in query_df.iterrows():\n",
    "        temp_1_dict[r['query_ref']] = r['target_ref']\n",
    "    for i, r in reverse_query_df.iterrows():\n",
    "        temp_2_dict[r['query_ref']] = r['target_ref']\n",
    "    for i, r in query_df.iterrows():\n",
    "        if temp_1_dict[r['query_ref']] in temp_2_dict and temp_2_dict[temp_1_dict[r['query_ref']]] == r['query_ref']:\n",
    "            query_df.at[i, 'reciprocal_best_hit'] = 'Y'\n",
    "        else:\n",
    "            query_df.at[i, 'reciprocal_best_hit'] = 'N'\n",
    "    output = query_df[query_df.reciprocal_best_hit == 'Y'] \n",
    "    with open(outfile_loc, 'wb') as f:\n",
    "        pickle.dump(output, f)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2616d0d9-b446-472c-a198-5ced3637aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_myco_info(num_subsets, subset_num, species_master_list):\n",
    "    output = []\n",
    "    species_list = util.chunk_list(species_master_list, num_subsets, subset_num)\n",
    "    for species in species_list:\n",
    "        features = []\n",
    "        genome_record = next(SeqIO.parse(refseq_dir + '/'+species+'/genomic.gbff', \"genbank\"))\n",
    "        full_sequence = str(genome_record.seq)\n",
    "        if full_sequence.count('A') + full_sequence.count('C') + full_sequence.count('G') + full_sequence.count('T') < len(full_sequence):\n",
    "            continue\n",
    "        organism = genome_record.annotations['organism']\n",
    "        \n",
    "        #  Read feature information\n",
    "        if species == reference_species:\n",
    "            mycobrowser_df = pd.read_excel(literature_datasets_dir+'/Mycobrowser_Release_4.xlsx')\n",
    "            for i, r in mycobrowser_df.iterrows():\n",
    "                if r['Feature'] == 'CDS':\n",
    "                    if r['Strand'] == '+':\n",
    "                        strand = 1\n",
    "                    else:\n",
    "                        strand = -1\n",
    "                    features.append([r['Locus'],r['Start']-1, r['Stop'], strand])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            for feature in genome_record.features:\n",
    "                    a = feature.qualifiers\n",
    "                    if feature.type == 'CDS' and a.get(\"locus_tag\")!= None and int(feature.location.end) - int(feature.location.start) < 100000:  #  Exclude strange Biopython parsing where starts with complement join and looks like a CDS is full length of genome!   \n",
    "                        locus_tag = a.get(\"locus_tag\")[0]\n",
    "                        features.append([locus_tag, int(feature.location.start), int(feature.location.end), int(feature.location.strand)])\n",
    "        \n",
    "        features.sort(key=lambda x: x[1])\n",
    "        \n",
    "        feature_info = []\n",
    "        for i, feature in enumerate(features):\n",
    "            if feature[1] < feature[2]:  \n",
    "                if feature[3] == 1:\n",
    "                    cds_nt_sequence = full_sequence[feature[1]:feature[2]]\n",
    "                else:\n",
    "                    cds_nt_sequence = util.reverse_complement(full_sequence[feature[1]:feature[2]])\n",
    "                cds_aa_sequence = translator.translate_sequence(full_sequence[feature[1]:feature[2]],feature[3], 0)                                                                                           \n",
    "                if (i + 1)< len(features) and feature[3] == 1 and feature[2] < features[i+1][1]:\n",
    "                    utr_coords = (feature[2], features[i+1][1])\n",
    "                    utr_sequence = full_sequence[feature[2]: features[i+1][1]]\n",
    "                elif (i > 0) and feature[3] == -1 and features[i-1][2] < feature[1]:\n",
    "                    utr_coords = (features[i-1][2], feature[1])\n",
    "                    utr_sequence = util.reverse_complement(full_sequence[features[i-1][2]: feature[1]])\n",
    "                else:\n",
    "                    utr_coords = (0,0)\n",
    "                    utr_sequence = ''\n",
    "                if i > 0 and feature[3] == 1 and features[i-1][2] < feature[1]:\n",
    "                    utr_5_coords = (features[i-1][2], feature[1])\n",
    "                    utr_5_sequence = full_sequence[features[i-1][2]: feature[1]]\n",
    "                elif (i + 1) < len(features) and feature[3] == -1 and features[i+1][1] > feature[2]:\n",
    "                    utr_5_coords = (feature[2], features[i+1][1])\n",
    "                    utr_5_sequence = util.reverse_complement(full_sequence[feature[2]: features[i+1][1]])\n",
    "                else:\n",
    "                    utr_5_coords = (0,0)\n",
    "                    utr_5_sequence = ''\n",
    "                \n",
    "                \n",
    "                feature_info.append([species, feature[0], cds_aa_sequence, utr_sequence, feature, cds_nt_sequence, utr_coords, utr_5_coords, utr_5_sequence])\n",
    "\n",
    "        output.append((species, organism, feature_info))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d5262c-20f8-496f-a241-2d60c488e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    myco_info_dict = {}\n",
    "    protein_info_dict = {}\n",
    "    names_dict = {}\n",
    "    parallel_output = Parallel(n_jobs=-1)(delayed(generate_myco_info)(num_cores, core_number, species_list) for core_number in core_numbers)\n",
    "    for core_output in parallel_output:\n",
    "        for results in core_output:\n",
    "            myco_info_dict[results[0]] = (results[1], results[2])\n",
    "            for feature in results[2]:\n",
    "                protein_info_dict[feature[0] + '_' + feature[1]] = feature\n",
    "            names_dict[results[0]] = results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b1f9b-8303-4beb-adb2-0b4a0941fd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    comparison_protein_list = []\n",
    "    reference_nt_list = []\n",
    "    reference_protein_list = []\n",
    "    reference_utr_list = []\n",
    "    comparison_utr_list = []\n",
    "    comparison_nt_list = []\n",
    "    for species in species_list:\n",
    "        for feature_info in myco_info_dict[species][1]:\n",
    "            comparison_protein_list.append([feature_info[0]+'_'+feature_info[1],feature_info[2][:-1]])\n",
    "            comparison_nt_list.append([feature_info[0]+'_'+feature_info[1],feature_info[5]])\n",
    "            if len(feature_info[3]) > 8:\n",
    "                comparison_utr_list.append([feature_info[0]+'_'+feature_info[1],feature_info[3]])  \n",
    "    for feature_info in myco_info_dict[reference_species][1]:\n",
    "            reference_protein_list.append([feature_info[0]+'_'+feature_info[1],feature_info[2][:-1]])\n",
    "            reference_nt_list.append([feature_info[0]+'_'+feature_info[1],feature_info[5]])\n",
    "            if len(feature_info[3]) > 8:\n",
    "                reference_utr_list.append([feature_info[0]+'_'+feature_info[1],feature_info[3]])\n",
    "    util.produce_fasta_file(comparison_protein_list, 'D:/BLAST/comp_prot/comparison_proteins.faa')\n",
    "    util.produce_fasta_file(reference_protein_list, 'D:/BLAST/ref_prot/reference_proteins.faa')\n",
    "    util.produce_fasta_file(reference_nt_list, 'D:/BLAST/ref_nt/reference_nt.faa')\n",
    "    util.produce_fasta_file(comparison_nt_list, 'D:/BLAST/comp_nt/comparison_nt.faa')\n",
    "    util.produce_fasta_file(reference_utr_list, 'D:/BLAST/ref_utr/reference_utr.faa')\n",
    "    util.produce_fasta_file(comparison_utr_list, 'D:/BLAST/comp_utr/comparison_utr.faa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b888e74-a7c0-4a4b-90a8-e27d6215257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    w_d = os.getcwd()\n",
    "    os.chdir(\"D:/\")\n",
    "    subprocess.run('cd D:/BLAST/comp_prot &  makeblastdb -in comparison_proteins.faa -dbtype prot -out d://BLAST//comp_prot//comp_prot', shell=True, capture_output = True)\n",
    "    subprocess.run('cd D:/BLAST/ref_prot &  makeblastdb -in reference_proteins.faa -dbtype prot -out d://BLAST//ref_prot//ref_prot', shell=True, capture_output = True)\n",
    "    subprocess.run('cd D:/BLAST/ref_nt &  makeblastdb -in reference_nt.faa -dbtype nucl -out d://BLAST//ref_nt//ref_nt', shell=True, capture_output = True)\n",
    "    subprocess.run('cd D:/BLAST/comp_nt &  makeblastdb -in comparison_nt.faa -dbtype nucl -out d://BLAST//comp_nt//comp_nt', shell=True, capture_output = True)\n",
    "    subprocess.run('cd D:/BLAST/comp_utr &  makeblastdb -in comparison_utr.faa -dbtype nucl -out d://BLAST//comp_utr//comp_utr', shell=True, capture_output = True)\n",
    "    os.chdir(w_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d726ba4-9d93-4ba4-964b-97f5265233ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    w_d = os.getcwd()\n",
    "    os.chdir(\"D:/\")\n",
    "    subprocess.run('cd d:\\\\BLAST\\\\comp_prot & blastp -query D:/BLAST/ref_prot/reference_proteins.faa -db comp_prot -out ref_comp_hits.csv -evalue 1e-10 -seg no -outfmt  \"10 qaccver saccver qlen slen pident length mismatch gapopen qstart qend sstart send evalue bitscore\" -num_threads 16', shell=True, capture_output = True)\n",
    "    subprocess.run('cd d:\\\\BLAST\\\\ref_prot & blastp -query D:/BLAST/comp_prot/comparison_proteins.faa -db ref_prot -out comp_ref_hits.csv -evalue 1e-10 -seg no -outfmt  \"10 qaccver saccver qlen slen pident length mismatch gapopen qstart qend sstart send evalue bitscore\" -num_threads 16', shell=True, capture_output = True)\n",
    "    subprocess.run('cd d:\\\\BLAST\\\\ref_nt & blastn -query D:/BLAST/ref_utr/reference_utr.faa -db ref_nt -out utr_ref_hits.csv -evalue 1e-10 -outfmt  \"10 qaccver saccver qlen slen pident length mismatch gapopen qstart qend sstart send evalue bitscore\" -num_threads 16', shell=True, capture_output = True)\n",
    "    subprocess.run('cd d:\\\\BLAST\\\\comp_nt & blastn -query D:/BLAST/comp_utr/comparison_utr.faa -db comp_nt -out utr_comp_hits.csv -evalue 1e-10 -outfmt  \"10 qaccver saccver qlen slen pident length mismatch gapopen qstart qend sstart send evalue bitscore\" -num_threads 16', shell=True, capture_output = True)\n",
    "    subprocess.run('cd d:\\\\BLAST\\\\comp_utr & blastn -query D:/BLAST/comp_utr/comparison_utr.faa -db comp_utr -out utr_all_comp_hits.csv -evalue 1e-10 -outfmt  \"10 qaccver saccver qlen slen pident length mismatch gapopen qstart qend sstart send evalue bitscore\" -num_threads 16', shell=True, capture_output = True)\n",
    " \n",
    "    os.chdir(w_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b4d7d6-b618-4c76-a4f6-0b88ecea0ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    blast_results_rc = process_blast_output('D:\\\\BLAST\\\\comp_prot\\\\ref_comp_hits.csv', project_dir + '/blast_results_rc.pkl', True)\n",
    "    blast_results_cr = process_blast_output('D:\\\\BLAST\\\\ref_prot\\\\comp_ref_hits.csv', project_dir + '/blast_results_cr.pkl', True)\n",
    "    blast_results_utr_ref = process_blast_output('D:\\\\BLAST\\\\ref_nt\\\\utr_ref_hits.csv', project_dir + '/utr_results_ref.pkl', False)\n",
    "    blast_results_comp_ref = process_blast_output('D:\\\\BLAST\\\\comp_nt\\\\utr_comp_hits.csv', project_dir + '/utr_results_comp.pkl', False)\n",
    "    blast_results_utr_utr = process_blast_output('D:\\\\BLAST\\\\comp_utr\\\\utr_all_comp_hits.csv', project_dir + '/comp_results_utr_utr.pkl', False)\n",
    "    rbh_results = keep_reciprocal_best_hits(blast_results_rc, blast_results_cr, project_dir + '/rbh_results_temp.pkl')\n",
    "    rbh_results['query_info'] = rbh_results['query_ref'].map(protein_info_dict)\n",
    "    rbh_results['target_info'] = rbh_results['target_ref'].map(protein_info_dict)\n",
    "    organism_names = rbh_results[['target_species','target_species_name']].drop_duplicates().reset_index(drop=True)\n",
    "    organism_dict = {}\n",
    "    for i, r in organism_names.iterrows():\n",
    "        if 'BCG' in r['target_species_name']:\n",
    "            organism_names.at[i,'sname'] = 'M.bovis_BCG'\n",
    "        elif 'AF2122' in r['target_species_name']:\n",
    "            organism_names.at[i,'sname'] = 'M.bovis_AF2122/97'\n",
    "        else:\n",
    "            organism_names.at[i,'sname'] = r['target_species_name'][0] + '.' + r['target_species_name'].split(' ')[1]\n",
    "    for i, r in organism_names.iterrows():\n",
    "        organism_dict[r['target_species']] = r['sname']\n",
    "    rbh_results['target_species_sname'] = rbh_results['target_species'].map(organism_dict)\n",
    "    for i, r in rbh_results.iterrows():\n",
    "        rbh_results.at[i,'query_start'] = r['query_info'][4][1]\n",
    "        rbh_results.at[i,'target_start'] = r['target_info'][4][1]\n",
    "        rbh_results.at[i,'target_utr'] = r['target_info'][3]\n",
    "        rbh_results.at[i,'target_cds'] = r['target_info'][2][:-1]\n",
    "        rbh_results.at[i,'target_utr_start'] = r['target_info'][6][0]\n",
    "        rbh_results.at[i,'target_utr_end'] = r['target_info'][6][1]\n",
    "        rbh_results.at[i,'target_utr_5'] = r['target_info'][8]\n",
    "        rbh_results.at[i,'target_utr_5_start'] = r['target_info'][7][0]\n",
    "        rbh_results.at[i,'target_utr_5_end'] = r['target_info'][7][1]\n",
    "    blast_results_rc.to_csv(project_dir + '/blast_results_rc.csv')\n",
    "    blast_results_cr.to_csv(project_dir + '/blast_results_cr.csv')   \n",
    "    blast_results_utr_ref.to_csv(project_dir + '/blast_results_utr_ref.csv') \n",
    "    blast_results_comp_ref.to_csv(project_dir + '/blast_results_comp_ref.csv') \n",
    "    blast_results_utr_utr.to_csv(project_dir + '/blast_results_utr_utr.csv') \n",
    "    with open(project_dir + '/rbh_results.pkl', 'wb') as f:\n",
    "        pickle.dump(rbh_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97996fff-d3f4-4585-995f-b1bf15f8fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "#if full_run == False:\n",
    "    with open(project_dir + '/rbh_results.pkl', 'rb') as f:\n",
    "        rbh_results = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8925a82f-ea43-4596-be5a-c3fd97901dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbh_results[['query_ref', 'target_species_sname', 'target_utr_start', 'target_utr_end', 'target_utr_5_start', 'target_utr_5_end']].to_csv(project_dir + '/rbh_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc8736-5673-4733-b9f9-e3305f98c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_results_utr_utr = process_blast_output('D:\\\\BLAST\\\\comp_utr\\\\utr_all_comp_hits.csv', project_dir + '/comp_results_utr_utr.pkl', False)\n",
    "blast_results_utr_utr.to_csv(project_dir + '/blast_results_utr_utr.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f1f140b-2e98-4ca7-b29d-0fa3524a09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_refs = rbh_results[['query_ref']].drop_duplicates().reset_index(drop=True)['query_ref'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e351a576-47de-46d8-9fe9-eeee203afaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_alignments(num_subsets, subset_num, field_name, directory, ref_master_list):\n",
    "    ref_list = util.chunk_list(ref_master_list, num_subsets, subset_num)\n",
    "    for ref in ref_list:\n",
    "        temp_df = rbh_results[rbh_results.query_ref == ref]\n",
    "        seq_list = []\n",
    "        for i, r in temp_df.iterrows():\n",
    "            if len(r[field_name]) > 0:\n",
    "                seq_list.append([r['target_species_sname'], r[field_name]])\n",
    "        util.produce_fasta_file(seq_list, project_dir+'/testseq_'+str(subset_num)+'.fasta')\n",
    "        cline = MuscleCommandline(muscle_exe, input=project_dir+'/testseq_'+str(subset_num)+'.fasta', out=directory + '/All/align_'+ ref +'.fasta')\n",
    "        try:\n",
    "            stdout, stderr = cline()\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        temp = util.read_fasta_to_array(directory + '/All/align_'+ ref +'.fasta', species_order = [])\n",
    "        num_sequences = len(temp[0])\n",
    "        if num_sequences == num_species:\n",
    "            shutil.copyfile(directory + '/All/align_'+ ref +'.fasta', directory +'/Full_Ortholog/align_'+ ref +'.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0118534b-4a82-4cda-9064-90115486049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    #Parallel(n_jobs=-1)(delayed(run_alignments)(num_cores, core_number, 'target_cds', project_dir + '/CDS_Alignments', query_refs) for core_number in core_numbers)\n",
    "    #Parallel(n_jobs=-1)(delayed(run_alignments)(num_cores, core_number, 'target_utr', project_dir + '/UTR_Alignments', query_refs) for core_number in core_numbers)\n",
    "    Parallel(n_jobs=-1)(delayed(run_alignments)(num_cores, core_number, 'target_utr_5', project_dir + '/UTR_5_Alignments', query_refs) for core_number in core_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d20d3b-7240-47e7-9e67-b702f0326e83",
   "metadata": {},
   "source": [
    "##### Build tree from full orthologs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b9166-5ff9-4e13-8a47-c22edf3c528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run('cd \\\\users\\\\nicho\\\\IQTree & bin\\\\iqtree2 -q ' + project_dir + '/CDS_Alignments/Full_Ortholog/' + ' --prefix '+ project_dir + '/CDS_Alignments/Full_Ortholog_Tree/CDS_Full_Ortholog_Tree -m LG -B 1000 -T AUTO -o ' + organism_dict['GCF_000696675.2'], shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b7744e-9799-4915-b477-8b25bff5625c",
   "metadata": {},
   "source": [
    "###### Insert blank sequences for display and delete gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a87f394-00bb-4c34-b007-b4bd7286333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = util.read_fasta_to_array(project_dir+'/UTR_Alignments/All/align_GCF_000195955.2_Rv0044c.fasta', species_order = [])\n",
    "sequence_length = len(temp[1][0])\n",
    "blank_seq = '-' * sequence_length\n",
    "sequence_names = temp[0]\n",
    "sequences = temp[1]\n",
    "for k, v in organism_dict.items():\n",
    "    if not(v in sequence_names):\n",
    "        sequence_names.append(v)\n",
    "        sequences.append(blank_seq)\n",
    "for i, name in enumerate(sequence_names):\n",
    "    if name == organism_dict[reference_species]:\n",
    "        ref_species_index = i\n",
    "ref_insert_positions = []\n",
    "for i, letter in enumerate(sequences[ref_species_index]):\n",
    "    if letter == '-':\n",
    "        ref_insert_positions.append(i)\n",
    "insert_deleted_sequences = []\n",
    "for sequence in sequences:\n",
    "    temp_letter_list = []\n",
    "    for i,letter in enumerate(sequence):\n",
    "        if i in ref_insert_positions:\n",
    "            continue\n",
    "        else:\n",
    "            temp_letter_list.append(sequence[i])\n",
    "    insert_deleted_sequences.append(''.join(temp_letter_list))\n",
    "sequence_info = []\n",
    "for (sequence_name, sequence) in zip(sequence_names, insert_deleted_sequences):\n",
    "    sequence_info.append([sequence_name, sequence])\n",
    "util.produce_fasta_file(sequence_info,project_dir+ '/UTR_Alignments/All_Deleted_Gaps/align_GCF_000195955.2_Rv0044c.fasta')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d755a3-2e89-493a-a61b-7a7774fd32e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.call ('C:/\"Program Files\"/R/R-4.1.2/bin/x64/Rscript --vanilla D:/Project_Data/Project_7/R_Scripts/Motif_Plots.R', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e068072d-891d-43ce-95cd-bc7b16bd291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "g = sns.FacetGrid(rbh_results, col='target_species_name', height=5, col_wrap=3)\n",
    "g.map(sns.scatterplot, 'target_start', 'query_start', s=2)\n",
    "g.set_titles(row_template = '{row_name}', col_template = '{col_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d09197f-3410-47f5-bab2-e4251ee5664d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#####  Run Infernal/r-scape process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74167f04-1fc2-4e81-b3ce-25e6965420f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_dir = 'D:/Project_Data/Project_7'\n",
    "dataset_loc = project_dir + '/NCBI_Dataset_Corynebacteriales'\n",
    "r_scape_output_loc = project_dir + '/R_Scape_Results_3'\n",
    "merged_file_loc = dataset_loc + '/merged_file.txt'\n",
    "intergenic_alignment_loc = project_dir + '/UTR_Alignments/All'\n",
    "wsl_merged_file_loc = util.wslname(merged_file_loc)\n",
    "if 1==0:\n",
    "#if full_run == True:\n",
    "    with open(merged_file_loc, 'w') as outfile:\n",
    "        for dir in util.list_dirs(dataset_loc):\n",
    "            directory = dataset_loc + '/' + dir\n",
    "            for file in util.list_files(directory):\n",
    "                if file.endswith(\"genomic.fna\"):\n",
    "                    with open(directory + '/' + file, encoding=\"utf-8\", errors='ignore') as infile:\n",
    "                        outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae886c1b-1fa9-4f18-a55f-a32d1ae1bafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_utr(utr_s, utr_e, searchline):\n",
    "    result = re.search('NC_000962.3/(\\S*)\\s', searchline)\n",
    "    if not(result == None):\n",
    "        start = int(result.group(1).split('-')[0])\n",
    "        end = int(result.group(1).split('-')[1])\n",
    "        if ((start < utr_e) and (end > utr_s)) or  ((end < utr_e) and (start > utr_s)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def utr_in_file(filename, utr_s, utr_e):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            for l in f:\n",
    "                if match_utr(utr_s, utr_e, l) == True:\n",
    "                    return True\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae87dca0-bf69-4314-9d26-6a0d082f03a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f76653ce1ce4df190206b61ceec30d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alignment_ids = ['.'.join(x.split('.')[:-1]) for x in util.list_files(intergenic_alignment_loc)]\n",
    "alignment_ids = alignment_ids[31:]\n",
    "for alignment_id in tqdm(alignment_ids):\n",
    "    ref = alignment_id[6:]\n",
    "    temp_df = rbh_results[rbh_results.query_ref == ref]\n",
    "    temp_df_2 = temp_df[temp_df.target_species_sname == 'M.tuberculosis']\n",
    "    utr_start = temp_df_2.iloc[0]['target_utr_start']\n",
    "    utr_end = temp_df_2.iloc[0]['target_utr_end']\n",
    "    \n",
    "    intergenic_file = alignment_id + '.fasta'\n",
    "    analysis_directory = r_scape_output_loc + '/' + ref\n",
    "    wsl_analysis_directory = util.wslname(analysis_directory)\n",
    "    if not os.path.exists(analysis_directory):\n",
    "        os.makedirs(analysis_directory)\n",
    "    intergenic_region_alignment = intergenic_alignment_loc + '/' + intergenic_file\n",
    "    alignment = AlignIO.read(intergenic_region_alignment, \"fasta\")\n",
    "    AlignIO.write(alignment, analysis_directory + '/initial_align.sto', \"stockholm\");\n",
    "\n",
    "    # Initial run with HMM\n",
    "\n",
    "    subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; cmbuild --noss -F initial_cm.cm initial_align.sto'  , shell=True)\n",
    "    subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; cmsearch -A initial_search.sto initial_cm.cm ' + wsl_merged_file_loc  , shell=True) \n",
    "    if utr_in_file(analysis_directory + '/initial_search.sto', utr_start, utr_end) == False:\n",
    "        continue\n",
    "    # Second run with CM\n",
    "\n",
    "    subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; cmbuild -F interim_cm.cm initial_search.sto'  , shell=True)\n",
    "    subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; cmcalibrate interim_cm.cm', shell= True)\n",
    "    subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; cmsearch -A interim_search.sto interim_cm.cm ' + wsl_merged_file_loc  , shell=True)  \n",
    "    subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; ~/rscape_v2.0.0.g/bin/R-scape --cacofold --outname rscape_interim interim_search.sto'  , shell=True)\n",
    "    if utr_in_file(analysis_directory + '/interim_search.sto', utr_start, utr_end) == False:\n",
    "        continue\n",
    "   \n",
    "    # Final run with CaCofold CM\n",
    "\n",
    "    subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; cmbuild -F final_cm.cm rscape_interim.cacofold.sto'  , shell=True)\n",
    "    subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; cmcalibrate final_cm.cm', shell= True)\n",
    "    subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; cmsearch -A final_search.sto final_cm.cm ' + wsl_merged_file_loc  , shell=True)  \n",
    "    if utr_in_file(analysis_directory + '/final_search.sto', utr_start, utr_end) == False:\n",
    "        continue\n",
    "    subprocess.run('wsl cd ' + wsl_analysis_directory + ' ; ~/rscape_v2.0.0.g/bin/R-scape --cacofold --outname rscape_final final_search.sto'  , shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23da1081-450d-4ad3-9cc3-3de4df98fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(utr_start, utr_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b30077-5e1e-410f-9190-18a324c7ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis_directory + '/initial_search.sto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7306649-6aad-4a97-bc97-58152183873d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
