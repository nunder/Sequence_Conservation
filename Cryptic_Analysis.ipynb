{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e30ed4-8a0e-4a6f-96eb-dfe116dfb2de",
   "metadata": {},
   "source": [
    "#### Directories etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9c6377-5080-4c22-94db-feabe17cc47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\ete3-3.1.2-py3.7.egg\\ete3\\evol\\parser\\codemlparser.py:221: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\ete3-3.1.2-py3.7.egg\\ete3\\evol\\parser\\codemlparser.py:221: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fft import fft, fftfreq\n",
    "from Bio import Entrez, SeqIO, AlignIO, pairwise2, Align, Seq, motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from scipy.stats import binom\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from Comparative_Analysis import Utilities as util\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from Comparative_Analysis import Blast_Functions as blastfn\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import ete3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1988a242-f558-4643-b3a9-27272fa7bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'D:/Project_Data/Project_9'\n",
    "cryptic_input_path = \"F:/Datasets/CRYPTIC_DATA/\"\n",
    "seq_dir = 'D:/Project_Data/Project_8/Datasets/Actinobacteria_Ref_Rep_Lev_Complete'\n",
    "tb_species = 'NC_000962.3' \n",
    "tb_genome_filename = 'GCF_000195955.2_ASM19595v2_genomic.gbff'\n",
    "num_cores = 16\n",
    "core_numbers = list(range(1, num_cores+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e4a41b9-51a1-44ba-bee1-86fb6dd6855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in SeqIO.parse(seq_dir + '/' + tb_genome_filename, \"genbank\"):\n",
    "    full_sequence = str(record.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4392bfa0-c45b-4e75-8c2c-b766b2aa3779",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_df = pd.read_csv(project_dir +'/Barcode.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b88b412-d21e-4178-aef9-84e81e3c0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ee7e9e-6a66-485f-badf-22c81560e77f",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30ebdfd2-85cc-4bc6-86c5-9e3c6c9cf3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_sequences(position_list, variant_dict, position_dict):\n",
    "    base_sequence = []\n",
    "    for i in position_list:\n",
    "        base_sequence.append(full_sequence[i-1])     # Cryptic are 1 based \n",
    "    output_sequence_dict ={}\n",
    "    for k, v in variant_dict.items():\n",
    "        output_sequence_dict[k] = copy.deepcopy(base_sequence)\n",
    "    for i, pos in enumerate(position_list):\n",
    "        if pos in position_dict:\n",
    "            variant_info = position_dict[pos][1:]  # Miss out initlal \"ref\" record\n",
    "            for (name, alt) in variant_info:\n",
    "                output_sequence_dict[name][i] = alt.upper()\n",
    "    output_sequences = []\n",
    "    for k, v in output_sequence_dict.items():\n",
    "        output_sequences.append(['seq_'+str(k), ''.join(v)])\n",
    "    return output_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fefd2694-16c3-4f59-b516-08d2b64a3082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_sequences_to_score(position_list, variant_dict, position_dict, distinct_sequence_names):\n",
    "    base_sequence = []\n",
    "    for i in position_list:\n",
    "        base_sequence.append({full_sequence[i-1]})     # Cryptic are 1 based \n",
    "    output_sequence_dict ={}\n",
    "    for k, v in variant_dict.items():\n",
    "        if k in distinct_sequence_names:\n",
    "            output_sequence_dict[k] = copy.deepcopy(base_sequence)\n",
    "    for i, pos in enumerate(position_list):\n",
    "        if pos in position_dict:\n",
    "            variant_info = position_dict[pos][1:]  # Miss out initlal \"ref\" record\n",
    "            for (name, alt) in variant_info:\n",
    "                if name in output_sequence_dict:\n",
    "                    output_sequence_dict[name][i] = {alt.upper()}\n",
    "    temp_dict = {}\n",
    "    for k, v in output_sequence_dict.items():\n",
    "        temp_dict['seq_'+str(k)] = v\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d9acb43-19f3-45e0-8214-f9481910cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitch_1(list_1, list_2):\n",
    "    res =[]\n",
    "    for i, j in zip(list_1, list_2):\n",
    "        a = i.intersection(j)\n",
    "        if len(a) == 0:\n",
    "            a = i.union(j)\n",
    "        res.append(a)\n",
    "    return res\n",
    "\n",
    "def fitch_2(parent_list, child_list):\n",
    "    res = []\n",
    "    mutations = []\n",
    "    for i, j in zip(parent_list, child_list):\n",
    "        mutation = 0\n",
    "        a = i.intersection(j)\n",
    "        if len(a) == 0:\n",
    "            a = set(list(j)[0])\n",
    "            mutation = 1\n",
    "        res.append(a)\n",
    "        if mutation == 1:\n",
    "            mutations.append(1)\n",
    "        else:\n",
    "            mutations.append(0)\n",
    "    return (res, mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9db00dd-1420-47db-abea-32369fb5dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_formula(position_3_counts, tot_bin_counts):\n",
    "    return 1- binom.cdf(position_3_counts-1, tot_bin_counts,1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9eaf090-a2a6-4b2d-b054-602281be9016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mutation_bin_probability(mutation_counts):\n",
    "    bin_counts = [0,0,0]\n",
    "    for i, c in enumerate(mutation_counts):\n",
    "        bin_counts[i % 3] += c\n",
    "    if sum(bin_counts) == 0:\n",
    "        return (2)\n",
    "    else:\n",
    "        return (bin_counts, bin_formula(bin_counts[2], sum(bin_counts)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc25129-08e0-4ce1-9b17-a64f477c50d8",
   "metadata": {},
   "source": [
    "#### Create variant dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5fcbb04-2c85-4719-b420-2651cf1e2cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    variant_df = pd.read_csv(cryptic_input_path + \"VARIANTS.csv\") \n",
    "    with open(project_dir + '/variant_df.pkl', 'wb') as f:\n",
    "        pickle.dump(variant_df[['UNIQUEID', 'VARIANT', 'MUTATION_TYPE', 'IS_NULL', 'IS_HET', 'IS_FILTER_PASS', 'IS_SNP', 'REF', 'ALT', 'GENOME_INDEX']], f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77fe61cc-adfe-4aa1-97d1-ba7ef7ac00ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    position_dict = {}\n",
    "    variant_dict = {}\n",
    "    id_dict = {}\n",
    "    with open(project_dir + '/variant_df.pkl', 'rb') as f:\n",
    "        variant_df = pickle.load(f) \n",
    "        unique_ids = variant_df.UNIQUEID.unique()\n",
    "        for i, unique_id in enumerate(unique_ids):\n",
    "            id_dict[unique_id] = i\n",
    "\n",
    "        for i, r in variant_df.iterrows():\n",
    "            if r['IS_NULL'] == False and r['IS_FILTER_PASS'] == True and r['IS_HET'] == False and r['IS_SNP'] == True :\n",
    "                \n",
    "                if id_dict[r['UNIQUEID']] in variant_dict:\n",
    "                    variant_dict[id_dict[r['UNIQUEID']]].append((r['GENOME_INDEX'], r['ALT']))\n",
    "                else:\n",
    "                    variant_dict[id_dict[r['UNIQUEID']]] = [(r['GENOME_INDEX'], r['ALT'])]\n",
    "\n",
    "                if r['GENOME_INDEX'] in position_dict:\n",
    "                    position_dict[r['GENOME_INDEX']].append((id_dict[r['UNIQUEID']], r['ALT']))\n",
    "                else:\n",
    "                    position_dict[r['GENOME_INDEX']] = [r['REF'], (id_dict[r['UNIQUEID']], r['ALT'])]    # If first entry also include reference value for info\n",
    "\n",
    "    with open(project_dir + '/id_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(id_dict, f)\n",
    "    with open(project_dir + '/variant_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(variant_dict, f) \n",
    "    with open(project_dir + '/position_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(position_dict, f) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef9da2b4-26ab-4150-90e6-99fc3b388cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == False:\n",
    "    with open(project_dir + '/id_dict.pkl', 'rb') as f:\n",
    "        id_dict = pickle.load(f)  \n",
    "    with open(project_dir + '/variant_dict.pkl', 'rb') as f:\n",
    "        variant_dict = pickle.load(f)  \n",
    "    with open(project_dir + '/position_dict.pkl', 'rb') as f:\n",
    "        position_dict = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f26106-6d45-411e-b4bd-e5f796e37793",
   "metadata": {},
   "source": [
    "#### Output full sequences and distinct sequences based on barcode positions for construction of tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9a14de1-b8a7-495a-97f4-42b60a5e379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_snps = []\n",
    "for i, r in barcode_df.iterrows():\n",
    "    start = r['start'] + 1            # Barcode file is 1 indexed\n",
    "    lineage_name = r['lineage']\n",
    "    if start in position_dict and 'lineage' in lineage_name:   # Just TB lineages\n",
    "        barcode_snps.append(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3560e728-d206-477c-bd12-6295d775e767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77580/77580 [00:00<00:00, 106929.30it/s]\n"
     ]
    }
   ],
   "source": [
    "sequences = produce_sequences(barcode_snps, variant_dict, position_dict)\n",
    "util.produce_fasta_file(sequences, project_dir + '/' + 'tb_variants.faa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9468f0da-f0af-48d1-b9ee-2fc476fc3169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3045/3045 [00:00<00:00, 101539.64it/s]\n"
     ]
    }
   ],
   "source": [
    "distinct_sequences = []\n",
    "distinct_sequence_names = []\n",
    "temp_dict = {}\n",
    "for (ref, seq) in sequences:\n",
    "    temp_dict[seq] = ref\n",
    "for k, v in temp_dict.items():    \n",
    "    distinct_sequences.append([v, k])\n",
    "    distinct_sequence_names.append(int(v.split('_')[1]))\n",
    "util.produce_fasta_file(distinct_sequences, project_dir + '/' + 'distinct_tb_variants.faa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75a87d12-a23d-4a2c-9c78-d1bea113586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_tree = ete3.Tree(project_dir + '/' + 'distinct_tb_variants.nwk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d087cdd6-122c-462b-abbe-d6af48934b96",
   "metadata": {},
   "source": [
    "#### Build sequences of interest and then run Fitch algorithm to assess mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25c23fc6-bb41-4178-9d87-de1fad6571c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation_mutation_significance(start, stop):    # 1 based\n",
    "    positions = list(range(start,stop))\n",
    "    sequence_to_score_dict = produce_sequences_to_score(positions, variant_dict, position_dict, distinct_sequence_names)\n",
    "\n",
    "    for node in master_tree.traverse(\"postorder\"):\n",
    "        if node.is_leaf():\n",
    "            node.add_features(seq = sequence_to_score_dict[node.name])\n",
    "        else:\n",
    "            children = node.children\n",
    "            node.add_features(seq = fitch_1(children[0].seq, children[1].seq))\n",
    "    for k, v in sequence_to_score_dict.items():              \n",
    "        seq_length = len(v)\n",
    "        break\n",
    "\n",
    "    mutation_counts = [0 for i in range(seq_length)]\n",
    "    for node in master_tree.traverse(\"preorder\"):\n",
    "        if node.is_leaf():\n",
    "            continue\n",
    "        if node.is_root():\n",
    "            node.seq = [{list(x)[0]} for x in node.seq]\n",
    "        children = node.children\n",
    "        mutations = []\n",
    "        for child in children:\n",
    "            (temp_1, temp_2) = fitch_2(node.seq ,child.seq)\n",
    "            child.seq = temp_1\n",
    "            mutations.append(temp_2)\n",
    "        temp = []\n",
    "        for h, i, j in zip(mutation_counts, mutations[0], mutations[1]):\n",
    "            temp.append(h+max(i, j))\n",
    "        mutation_counts = temp        \n",
    "    return mutation_bin_probability(mutation_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8994a2be-4c4b-4774-9f25-abeb58efce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_boundaries = []\n",
    "for genome_record in SeqIO.parse(seq_dir + '/' + tb_genome_filename, \"genbank\"):\n",
    "    for feature in genome_record.features:\n",
    "        if feature.type == 'CDS':\n",
    "            a = feature.qualifiers  \n",
    "            cds_boundaries.append((a.get(\"locus_tag\")[0], int(feature.location.start), int(feature.location.end), int(feature.location.strand)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "447d334c-6e24-4dc5-ba19-7181821fa12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rv0001 ([546, 152, 5048], 0.0)\n",
      "Rv0002 ([274, 153, 879], 0.0)\n",
      "Rv0003 ([65, 148, 175], 9.768844403401644e-07)\n",
      "Rv0004 ([63, 44, 195], 0.0)\n",
      "Rv0005 ([1368, 487, 6976], 0.0)\n"
     ]
    }
   ],
   "source": [
    "for (locus, start, stop, strand) in cds_boundaries[0:5]:\n",
    "    if strand == 1:\n",
    "        print(locus, calculation_mutation_significance(start+1, stop+1))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df79aa-2eea-48f5-85fa-5bccb6c89aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cds_probs(num_subsets, subset_num, boundaries):\n",
    "    res = []\n",
    "    cds_boundaries = util.chunk_list(boundaries, num_subsets, subset_num)\n",
    "    for (locus, start, stop, strand) in cds_boundaries:\n",
    "        if strand == 1:\n",
    "            res.append([locus, calculation_mutation_significance(start+1, stop+1)])\n",
    "        else:\n",
    "            continue\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a256bdb-a08b-4e68-87f3-f75cce24b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_output = Parallel(n_jobs=-1)(delayed(generate_cds_probs)(num_cores, core_number, cds_boundaries[0:40]) for core_number in core_numbers)\n",
    "temp = [item for sublist in parallel_output for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6403d4c-82cf-474c-bb56-cbc7d751d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 =[x[0] for x in parallel_output]\n",
    "t2 =[x[1] for x in parallel_output]\n",
    "temp1 = [item for sublist in t1 for item in sublist]\n",
    "temp2 = [item for sublist in t2 for item in sublist]\n",
    "sns.scatterplot(y=temp1, x=temp2)\n",
    "\n",
    "#sns.ecdfplot(temp1, ax = ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2be064-6633-46a4-8b1c-2426464e5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list = []\n",
    "for i, (loc_name, x,y) in enumerate((cds_boundaries)):\n",
    "    if i < len(cds_boundaries) - 1:\n",
    "        temp = cds_boundaries[i+1][1]\n",
    "        if temp - y > 100:\n",
    "            res = max_orf(y, temp, in_frame=True, genbank_format = True)\n",
    "            if res[3][0] < 0.05 and res[3][1] > 0 and res[1] - res[0] > 100:\n",
    "                print(loc_name, res)\n",
    "                out_list.append([loc_name, res[0], res[1], res[2], res[3][0]])\n",
    "df=pd.DataFrame(out_list,columns=['locus','start','end','strand','p_value'])\n",
    "df.to_csv(cryptic_output_path + '/significant_degenerate_patterns_intergenic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07997aa4-1fc4-4180-b578-8700eab12a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d0e4e05-aac9-49ee-a8eb-0a0f820feff9",
   "metadata": {},
   "source": [
    "#### Legacy code (might be useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85db383d-032d-4d8c-bf96-f6fc0915f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tree(species_to_split, position):\n",
    "    temp = fast_position_dict[position].intersection(species_to_split)\n",
    "    temp_2 = species_to_split - temp\n",
    "    if len(temp_2) > 1 and len(temp) > 1:\n",
    "        return ([(position, temp, len(temp)), (position, temp_2, len(temp_2))])\n",
    "    else:\n",
    "        return([(-1, species_to_split, len(species_to_split))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bcd536-db90-4e91-b296-15599eab0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_split_position(species_to_split_list):\n",
    "    best_split_num = 1e20\n",
    "    best_position = 0\n",
    "    #for k in barcode_snps:\n",
    "    for k, v in fast_position_dict.items():\n",
    "        #v = fast_position_dict[k]\n",
    "        mutation_count = 0\n",
    "        for species_to_split in species_to_split_list:\n",
    "            num_species_to_split = len(species_to_split)\n",
    "            optimal_split = int(num_species_to_split/2)\n",
    "            mutation_count += abs(len(v.intersection(species_to_split)) - optimal_split)\n",
    "       \n",
    "        if abs(mutation_count) < abs(best_split_num):\n",
    "            best_position = k\n",
    "            best_split_num = abs(mutation_count)\n",
    "          \n",
    "    return(best_position, best_split_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f5aeb-1f8f-4449-a79d-61a7833a6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_species = [[-1,set(x for x in range(len(id_dict))),99,True]]\n",
    "pos = optimal_split_position([x[1] for x in all_species])[0]\n",
    "split_results = [split_tree(all_species[0][1], pos)]\n",
    "print( [(x[0], x[2]) for x in split_results[0]] )\n",
    "for i in range(1,10):\n",
    "    start = time.process_time()\n",
    "    split_results.append([])\n",
    "    posn = optimal_split_position([x[1] for x in split_results[i-1]])\n",
    "    pos= posn[0]\n",
    "    split_score = posn[1]\n",
    "    successful_splits = 0\n",
    "    for x in split_results[i-1]:\n",
    "        temp = split_tree(x[1], pos) \n",
    "        if len(temp) == 1:\n",
    "            split_results[i].append(temp[0])\n",
    "        else:\n",
    "            successful_splits +=1\n",
    "            split_results[i].append(temp[0])\n",
    "            split_results[i].append(temp[1])\n",
    "    print(max([x[2] for x in split_results[i]]), [(x[0], x[2]) for x in split_results[i]] )\n",
    "    if successful_splits == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4cd57d-ec97-4cd8-a443-b48a16127802",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for res in split_results:\n",
    "    for info in res:\n",
    "        temp.append(info[0])\n",
    "snps = set(temp)\n",
    "snps.remove(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda34318-083f-4e03-ba66-34d57db11940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consensus(seq_list):\n",
    "    consensus = []\n",
    "    seq_len = len(seq_list[0])\n",
    "    for i in range(seq_len):\n",
    "        temp = [x[i] for x in seq_list]\n",
    "        max_count = 0\n",
    "        consensus_letter = 'X'\n",
    "        for letter in ['A', 'C' ,'G', 'T']:\n",
    "            tempct = temp.count(letter)\n",
    "            if tempct > max_count:\n",
    "                max_count = tempct\n",
    "                consensus_letter = letter\n",
    "        consensus.append(consensus_letter)\n",
    "    return ''.join(consensus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
