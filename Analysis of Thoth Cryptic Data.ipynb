{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e30ed4-8a0e-4a6f-96eb-dfe116dfb2de",
   "metadata": {},
   "source": [
    "#### Directories etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c6377-5080-4c22-94db-feabe17cc47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fft import fft, fftfreq\n",
    "from Bio import Entrez, SeqIO, AlignIO, pairwise2, Align, Seq, motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from scipy.stats import binom\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from Comparative_Analysis import Utilities as util\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from Comparative_Analysis import Blast_Functions as blastfn\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from Comparative_Analysis import ORF_Functions as orffn\n",
    "from random import sample\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import ete3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988a242-f558-4643-b3a9-27272fa7bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'F:/Project_Data/Project_9'\n",
    "seq_dir = 'F:/Datasets/Actinobacteria_Ref_Rep_Lev_Complete'\n",
    "dictionary_dir = 'F:/Datasets/CRYPTIC_DATA/Cryptic_Dictionaries'\n",
    "mutation_count_dir = 'F:/Datasets/CRYPTIC_DATA/Cryptic_Mutation_Counts'\n",
    "mutation_count_dir = 'F:/Datasets/CRYPTIC_DATA/Cryptic_Mutation_Counts'\n",
    "tree_dir = 'F:/Datasets'\n",
    "tb_species = 'NC_000962.3' \n",
    "tb_genome_filename = 'GCF_000195955.2_ASM19595v2_genomic.gbff'\n",
    "mycobrowser_dir = 'F:/Datasets/Data_From_Publications'\n",
    "num_cores = 16\n",
    "core_numbers = list(range(1, num_cores+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235e1e1-a7fa-474b-8a88-72232e020b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in SeqIO.parse(seq_dir + '/' + tb_genome_filename, \"genbank\"):\n",
    "    full_sequence = str(record.seq)\n",
    "    tb_sequence = str(record.seq)\n",
    "for record in SeqIO.parse(project_dir + '/annot.gbk', \"genbank\"):\n",
    "    reannotated_sequence = str(record.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba7e94a-f3f3-4b38-b620-c4a62e55efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycobrowser_features =[]\n",
    "mycobrowser_df = pd.read_csv(mycobrowser_dir+'/Mycobrowser_Release_4.csv')\n",
    "for i, r in mycobrowser_df.iterrows():\n",
    "    if r['Strand'] == '+':\n",
    "        strand = 1\n",
    "    else:\n",
    "        strand = -1\n",
    "    mycobrowser_features.append([r['Feature'], r['Locus'],r['Start']-1, r['Stop'], strand, r['Product'], r['Comments']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b88b412-d21e-4178-aef9-84e81e3c0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ee7e9e-6a66-485f-badf-22c81560e77f",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562c1fbb-768e-4ab5-a781-b9a8ae96b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_formula(position_3_counts, tot_bin_counts):\n",
    "    return 1- binom.cdf(position_3_counts-1, tot_bin_counts,1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eaf090-a2a6-4b2d-b054-602281be9016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mutation_bin_probability(mutation_counts):\n",
    "    bin_counts = [0,0,0]\n",
    "    for i, c in enumerate(mutation_counts):\n",
    "        bin_counts[i % 3] += c\n",
    "    if sum(bin_counts) == 0:\n",
    "        return (bin_counts, 2)\n",
    "    else:\n",
    "        return (bin_counts, bin_formula(bin_counts[2], sum(bin_counts)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f0b860-4c57-4de7-997c-c2e7cc074d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_tree= ete3.Tree(tree_dir + '/' + 'tb_tree.nwk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea87943f-fab0-45c5-81eb-c365a0f1da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(master_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240d70ef-14d8-4bf2-a360-0e611506a410",
   "metadata": {},
   "source": [
    "#### Calculate probabilites for annotated (and reannotated PGAP) CDS regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b3bf0-ecda-4573-8e66-7fcde8acd18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_boundaries = []\n",
    "for genome_record in SeqIO.parse(seq_dir + '/' + tb_genome_filename, \"genbank\"):\n",
    "    for feature in genome_record.features:\n",
    "        if feature.type == 'CDS':\n",
    "            a = feature.qualifiers  \n",
    "            if a.get(\"pseudo\") == None:\n",
    "                pseudo = False\n",
    "            else:\n",
    "                pseudo = True\n",
    "            cds_boundaries.append((a.get(\"locus_tag\")[0], pseudo, a.get(\"product\")[0], int(feature.location.start), int(feature.location.end), int(feature.location.strand)))   \n",
    "reannotated_cds_boundaries = []\n",
    "for genome_record in SeqIO.parse(project_dir + '/annot.gbk', \"genbank\"):\n",
    "    for feature in genome_record.features:\n",
    "        if feature.type == 'CDS':\n",
    "            a = feature.qualifiers  \n",
    "            if a.get(\"pseudo\") == None:\n",
    "                pseudo = False\n",
    "            else:\n",
    "                pseudo = True\n",
    "            reannotated_cds_boundaries.append((a.get(\"locus_tag\")[0], pseudo, a.get(\"product\")[0], int(feature.location.start), int(feature.location.end), int(feature.location.strand)))   \n",
    "cds_boundaries.sort(key = lambda x: x[3])\n",
    "reannotated_cds_boundaries.sort(key = lambda x: x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e647b-16e4-4c53-8c59-787dacbd80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_df = pd.read_csv(project_dir+'/mutation_df.csv')\n",
    "alt_mutation_df = pd.read_csv(project_dir+'/alt_mutation_df.csv')\n",
    "gpi_mutation_df = pd.read_csv(project_dir+'/gpi_mutation_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad47ede-8f39-4d1e-8a59-48ed5618e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_and_non_zero_mutation_counts = mutation_df['Num_Mutations'].values.tolist()\n",
    "alt_zero_and_non_zero_mutation_counts = alt_mutation_df['Num_Mutations'].values.tolist()\n",
    "gpi_zero_and_non_zero_mutation_counts = gpi_mutation_df['Num_Mutations'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18baaf01-34e0-45ae-bc95-c2912c03303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(project_dir + '/alt_mutation_counts.pkl', 'wb') as f:\n",
    "        pickle.dump(alt_zero_and_non_zero_mutation_counts, f) \n",
    "with open(project_dir + '/gpi_mutation_counts.pkl', 'wb') as f:\n",
    "        pickle.dump(gpi_zero_and_non_zero_mutation_counts, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1f0ac-ba88-408c-9bb0-830226b2bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp =[]\n",
    "alt_temp = []\n",
    "gpi_temp = []\n",
    "alt_locus_mutation = []\n",
    "gpi_locus_mutation = []\n",
    "for (locus, pseudo, product, start, stop, strand) in cds_boundaries:\n",
    "    if pseudo == False:\n",
    "        if strand == 1:\n",
    "            temp.append(mutation_bin_probability(zero_and_non_zero_mutation_counts[start:stop]))\n",
    "            alt_temp.append(mutation_bin_probability(alt_zero_and_non_zero_mutation_counts[start:stop]))\n",
    "            gpi_temp.append(mutation_bin_probability(gpi_zero_and_non_zero_mutation_counts[start:stop]))\n",
    "            alt_locus_mutation.append([locus, mutation_bin_probability(alt_zero_and_non_zero_mutation_counts[start:stop])[1]])\n",
    "            gpi_locus_mutation.append([locus, mutation_bin_probability(gpi_zero_and_non_zero_mutation_counts[start:stop])[1]])\n",
    "        else:\n",
    "            temp.append(mutation_bin_probability(reversed(zero_and_non_zero_mutation_counts[start:stop])))\n",
    "            alt_temp.append(mutation_bin_probability(reversed(alt_zero_and_non_zero_mutation_counts[start:stop])))\n",
    "            gpi_temp.append(mutation_bin_probability(reversed(alt_zero_and_non_zero_mutation_counts[start:stop])))\n",
    "            alt_locus_mutation.append([locus, mutation_bin_probability(reversed(alt_zero_and_non_zero_mutation_counts[start:stop]))[1]])\n",
    "            gpi_locus_mutation.append([locus, mutation_bin_probability(reversed(gpi_zero_and_non_zero_mutation_counts[start:stop]))[1]])\n",
    "scores = []\n",
    "for x in temp:\n",
    "    scores.append(x[1])\n",
    "alt_scores = []\n",
    "for x in alt_temp:\n",
    "    alt_scores.append(x[1])\n",
    "gpi_scores = []\n",
    "for x in gpi_temp:\n",
    "    gpi_scores.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2991224-a253-4552-a1f3-9bc6d256ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(gpi_scores, bins =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45666fe-1792-43ed-8cf6-f198119ca24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot([x for x in gpi_zero_and_non_zero_mutation_counts if x >3], bins = 100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d783c-53e9-4bad-a696-8cddcbb69b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, c in enumerate(gpi_zero_and_non_zero_mutation_counts):\n",
    "    if c > 3000:\n",
    "        print(n, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c0417-c0c9-4a08-8739-3e19f9e4a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(zero_and_non_zero_mutation_counts)/len(zero_and_non_zero_mutation_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83658a-4a38-4fe5-a467-c5178f7d9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot([x for x in zero_and_non_zero_mutation_counts if (x > 250)], bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ac028-5464-47fb-ac58-5b53bded6d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == False:\n",
    "    with open(project_dir + '/id_dict.pkl', 'rb') as f:\n",
    "        id_dict = pickle.load(f)  \n",
    "    with open(project_dir + '/variant_dict.pkl', 'rb') as f:\n",
    "        variant_dict = pickle.load(f)  \n",
    "    with open(project_dir + '/position_dict.pkl', 'rb') as f:\n",
    "        position_dict = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b222e1f6-fb23-48b5-a2c1-d8faa9b41ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,pos in enumerate(alt_zero_and_non_zero_mutation_counts):\n",
    "    if n+1 in position_dict:\n",
    "        rat = pos/ len(position_dict[n+1])\n",
    "        if pos == 0 and len(position_dict[n+1]) > 0:\n",
    "            print(n,pos, len(position_dict[n+1]), rat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f6321f-5a4e-481b-80dd-b73ec38fbd18",
   "metadata": {},
   "source": [
    "#### Identify potential ORFS (min length 200) in inter-CDS regions of standard annotation and output to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3b790-e301-4599-a155-74a0e7ae05ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORFFinder = orffn.ORF_Finder()\n",
    "trans = util.Translator()\n",
    "min_intergenic_length = 100\n",
    "details =  []\n",
    "results =[]\n",
    "for i, (locus, pseudo, product, start, stop, strand) in enumerate(cds_boundaries):\n",
    "    if i < len(cds_boundaries) - 1:\n",
    "        if cds_boundaries[i+1][3] > stop + min_intergenic_length:\n",
    "            a =ORFFinder.max_orf(stop-40, cds_boundaries[i+1][3]+40, 1e-20, output_all_orfs = False, min_orf_length = 200)\n",
    "            if not(a==(0,0,0)):\n",
    "                ov = 0\n",
    "                info = ('','','','','','','')\n",
    "                for i, (loc, pse, pro, sta, sto, stra) in enumerate(reannotated_cds_boundaries):\n",
    "                    if a[1] > sta and a[0] < sto:\n",
    "                        ov = (min(a[1], sto) - max(a[0], sta)) / (sto - sta)\n",
    "                        if ov > 0.3:\n",
    "                            info =  (loc, pse, pro, sta, sto, stra, ov)\n",
    "                        \n",
    "                ov = 0\n",
    "                myco_info = ('','','','','')\n",
    "                for i, (loc, sta, sto, stra) in enumerate(mycobrowser_features):\n",
    "                    if a[1] > sta and a[0] < sto:\n",
    "                        ov = (min(a[1], sto) - max(a[0], sta)) / (sto - sta)\n",
    "                        if ov > 0.3:\n",
    "                            myco_info =  (loc, sta, sto, stra, ov)\n",
    "                        \n",
    "                sequ = trans.translate_sequence(full_sequence[a[0]:a[1]], a[2], 0)\n",
    "                details.append([a, sequ])\n",
    "                results.append([a[0],a[1],a[2],a[3],info[0],info[1],info[2],info[3],info[4],info[5],info[6],myco_info[0],myco_info[1],myco_info[2],myco_info[3],myco_info[4]])\n",
    "results_df = pd.DataFrame(results, columns = ['start_pos','end_pos','strand','score','PGAP_ref','PGAP_pseudogene','PGAP_product', 'PGAP_start', 'PGAP_end','PGAP_strand', 'PGAP_overlap', 'Mycob_ref','Mycob_start', 'Mycob_end','Mycob_strand', 'Mycob_overlap'])\n",
    "results_df.to_csv(project_dir + '/cds_candidates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198ce0ae-2b01-482b-83cb-93c720537916",
   "metadata": {},
   "source": [
    "#### Find all (maximal nested) ORFs and filter out ORFS on opposite strand which would have same non-synonymous positions with larger ORF on other strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea12a609-41c4-402f-a220-c09b6cc10fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ORFFinder = orffn.ORF_Finder(full_sequence)\n",
    "a = ORFFinder.max_orf(0, 4411532, output_orfs = 'Nested', min_orf_length = 50)\n",
    "a.sort(key = lambda x: x[3], reverse = True)\n",
    "orf_list = [a[0]]\n",
    "for x in tqdm(a[1:]):\n",
    "    matched = 0\n",
    "    for v in orf_list:\n",
    "        if v[0]<=x[0] and v[1]>=x[1]:\n",
    "            if x[2] == v[2]:\n",
    "                if (v[0] - x[0])%3 == 0:\n",
    "                    matched = 1\n",
    "                    break\n",
    "            else:\n",
    "                if (v[0] - x[0])%3 == 1:\n",
    "                    matched = 1\n",
    "                    break\n",
    "    if matched == 0:\n",
    "        orf_list.append(x)\n",
    "orf_list.sort(key = lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eaa87f-ac8c-4fa4-9b70-241cfda7bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for (start, stop, strand, length) in tqdm(orf_list):\n",
    "    matches_annotated_orf = False\n",
    "    for (locus_1, pseudo_1, product_1, start_1, stop_1, strand_1) in cds_boundaries:\n",
    "        if (pseudo_1 == False and strand_1 == strand and strand_1 == 1 and stop_1 == stop) or (pseudo_1 == False and strand_1 == strand and strand_1 == -1 and start_1 == start):\n",
    "            matches_annotated_orf = True\n",
    "            break\n",
    "    if matches_annotated_orf == True:\n",
    "        continue\n",
    "    if strand == 1:\n",
    "        temp.append((mutation_bin_probability(alt_zero_and_non_zero_mutation_counts[start:stop]), stop-start))\n",
    "    else:\n",
    "        temp.append((mutation_bin_probability(reversed(alt_zero_and_non_zero_mutation_counts[start:stop])), stop-start))\n",
    "scores = []\n",
    "for (x, y) in temp:\n",
    "    scores.append([x[1], y])\n",
    "scores_df = pd.DataFrame(scores, columns = ['score','length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48ce947-f0a5-4e14-a990-70d9cb33ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ultra_conserved_candidates = []\n",
    "lengths = []\n",
    "mutation_len = len(alt_zero_and_non_zero_mutation_counts)\n",
    "i = 0\n",
    "start = 0\n",
    "while i < mutation_len:\n",
    "    if alt_zero_and_non_zero_mutation_counts[i] == 0:\n",
    "        i+=1\n",
    "    else:\n",
    "        stop = i\n",
    "        zero_length = stop - start - 1\n",
    "        if zero_length > 150 or zero_length < 8:\n",
    "            pass\n",
    "        else:\n",
    "            lengths.append(zero_length)\n",
    "            ultra_conserved_candidates.append([start, stop])\n",
    "        i+=1 \n",
    "        start = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271cf957-4308-4c0e-9467-b9ad85d57a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = lengths, bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b963babf-8aec-44d9-8628-180defffd830",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for x in ultra_conserved_candidates:\n",
    "    sequence = tb_sequence[x[0]:x[1]]\n",
    "    name = 'Start_'+str(x[0])+'_Stop_'+str(x[1])\n",
    "    temp.append([name, sequence])\n",
    "util.produce_fasta_file(temp, project_dir + '/' + 'ultra_conserved_candidates.faa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc705923-8a61-496f-8b40-154a34896aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for (feature, locus, start, stop, strand, product, comments) in mycobrowser_features:\n",
    "    if feature == 'CDS':\n",
    "        if strand == 1:\n",
    "            sequence = tb_sequence[start:stop]\n",
    "        else:\n",
    "            sequence = util.reverse_complement(tb_sequence[start:stop])\n",
    "        temp.append([locus, sequence])\n",
    "util.produce_fasta_file(temp, project_dir + '/' + 'tb_cds.faa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bc856e-e0aa-45bc-930a-b01a62e80ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = scores_df, x= 'score', bins =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d60a1-8bff-4ed0-a620-d8787f92e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = scores_df, x = 'length', y ='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8bbd93-8f6d-461c-8719-c146a7177000",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = []\n",
    "for x in orf_list:\n",
    "    prob.append(x[4])\n",
    "sns.histplot(prob, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2769ef-9358-406c-a22a-e88be6b93338",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_features = []\n",
    "for genome_record in SeqIO.parse(project_dir + '/annot.gbk', \"genbank\"):\n",
    "    for feature in genome_record.features:\n",
    "        if feature.type != 'source':\n",
    "            annotated_features.append((int(feature.location.start), int(feature.location.end), int(feature.location.strand)))   \n",
    "for genome_record in SeqIO.parse(seq_dir + '/' + tb_genome_filename, \"genbank\"):\n",
    "    for feature in genome_record.features:\n",
    "        if feature.type != 'source':\n",
    "            annotated_features.append((int(feature.location.start), int(feature.location.end), int(feature.location.strand)))   \n",
    "annotated_features.sort(key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd77402-5afe-4b13-9f1e-1a14e569d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_overlapping_orfs = []\n",
    "for i, orf in enumerate(orf_list):\n",
    "    max_ov = 0\n",
    "    for (sta, sto, stra) in annotated_features:\n",
    "        if orf[0] < sto and orf[1] > sta:\n",
    "            ov = (min(orf[1], sto) - max(orf[0], sta)) / (orf[1] - orf[0])\n",
    "            max_ov = max(ov, max_ov)\n",
    "    if max_ov < 0.1:\n",
    "        non_overlapping_orfs.append(orf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ad8e1a-000c-4abd-9a45-2d4e548b6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_overlapping_orf_list = []\n",
    "temp = []\n",
    "for (start, stop, strand, length) in tqdm(non_overlapping_orfs):\n",
    "    if strand == 1:\n",
    "        temp.append((mutation_bin_probability(alt_zero_and_non_zero_mutation_counts[start:stop]), stop-start))\n",
    "        non_overlapping_orf_list.append((start, stop, strand, length, mutation_bin_probability(alt_zero_and_non_zero_mutation_counts[start:stop])))\n",
    "    else:\n",
    "        temp.append((mutation_bin_probability(reversed(alt_zero_and_non_zero_mutation_counts[start:stop])), stop-start))\n",
    "        non_overlapping_orf_list.append((start, stop, strand, length,mutation_bin_probability(reversed(alt_zero_and_non_zero_mutation_counts[start:stop]))))\n",
    "scores = []\n",
    "for (x, y) in temp:\n",
    "    scores.append([x[1], y])\n",
    "scores_non_overlapping_df = pd.DataFrame(scores, columns = ['score','length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d38027-a70a-402e-9318-fe2c514037b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = scores_non_overlapping_df, x= 'score', bins =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef75be3c-e093-4faf-a5e0-585aef3e1267",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = scores_non_overlapping_df, x = 'length', y ='score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2683970-7a45-419b-875a-0ca44f8b7a66",
   "metadata": {},
   "source": [
    "#### Produce FASTA file with CDS candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214885e2-505b-42a5-a423-dd784b69cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = util.Translator()\n",
    "temp = []\n",
    "for x in non_overlapping_orf_list:\n",
    "    if x[4][1] < 1e-5 or x[4][1]==2:\n",
    "        if x[2] == 1:\n",
    "            prot = trans.translate_sequence(tb_sequence[x[0]:x[1]], 1, 0)\n",
    "        else:\n",
    "            prot = trans.translate_sequence(util.reverse_complement(tb_sequence[x[0]:x[1]]), 1, 0)\n",
    "        name = 'Start_'+str(x[0])+'_Stop_'+str(x[1])+'_Strand_'+str(x[2])\n",
    "        temp.append([name, prot[:-1]])\n",
    "util.produce_fasta_file(temp, project_dir + '/' + 'tb_orf_candidates.faa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac2021-b052-4228-8238-370142c988fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dir = 'F:/Datasets/NCBI_Refseq_Mycobacteriaceae_All_Levels/ncbi_dataset/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc322b53-12eb-40e8-b765-be36b4b1443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_dirs = util.list_dirs(seq_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf70bf87-882c-4d3d-9337-2d55ce23f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comparator_full_sequence_dataset(num_subsets, subset_num, dir_list): \n",
    "    sequence_dirs = util.chunk_list(dir_list, num_subsets, subset_num)\n",
    "    temp_list = []\n",
    "    for dirname in (sequence_dirs):\n",
    "            for genome_record in SeqIO.parse(seq_dir + '/' + dirname + '/genomic.gbff', \"genbank\"):\n",
    "                accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "                comparator_sequence = str(genome_record.seq)\n",
    "                if comparator_sequence.count('A') + comparator_sequence.count('C') + comparator_sequence.count('G') + comparator_sequence.count('T') < len(comparator_sequence):\n",
    "                    continue\n",
    "                if len(comparator_sequence) > 100:\n",
    "                    name = accession_ver + '@'+str(0)+'_'+str(len(comparator_sequence))\n",
    "                    temp_list.append([name, comparator_sequence])\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f753147-7989-422d-999e-0519b1c64d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comparator_orf_dataset(num_subsets, subset_num, dir_list): \n",
    "    sequence_dirs = util.chunk_list(dir_list, num_subsets, subset_num)\n",
    "    trans = util.Translator()\n",
    "    temp_list = []\n",
    "    for dirname in (sequence_dirs):\n",
    "            for genome_record in SeqIO.parse(seq_dir + '/' + dirname + '/genomic.gbff', \"genbank\"):\n",
    "                accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "                comparator_sequence = str(genome_record.seq)\n",
    "                if comparator_sequence.count('A') + comparator_sequence.count('C') + comparator_sequence.count('G') + comparator_sequence.count('T') < len(comparator_sequence):\n",
    "                    continue\n",
    "                ORFFinder = orffn.ORF_Finder(comparator_sequence)\n",
    "                temp = ORFFinder.max_orf(0, len(comparator_sequence), output_orfs = 'Nested', min_orf_length = 50)\n",
    "                temp.sort(key = lambda x: x[3], reverse = True)\n",
    "                for x in temp:\n",
    "                    if x[2] == 1:\n",
    "                        prot = trans.translate_sequence(comparator_sequence[x[0]:x[1]], 1, 0)\n",
    "                    else:\n",
    "                        prot = trans.translate_sequence(util.reverse_complement(comparator_sequence[x[0]:x[1]]), 1, 0)\n",
    "                    name = accession_ver + '@'+str(x[0])+'_'+str(x[1])+'_'+str(x[2])\n",
    "                    if len(prot) > 10:\n",
    "                        temp_list.append([name, prot[:-1]])\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d90fc35-6f4f-4f46-b10b-f4fa2e66170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator_full_sequence_list = []\n",
    "if 1==1:\n",
    "    parallel_output = Parallel(n_jobs=-1)(delayed(generate_comparator_full_sequence_dataset)(num_cores, core_number, sequence_dirs) for core_number in core_numbers)\n",
    "    for x in parallel_output:\n",
    "        for y in x:\n",
    "            comparator_full_sequence_list.append(y)\n",
    "util.produce_fasta_file(comparator_full_sequence_list, project_dir + '/' + 'comparator_full_sequences.faa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24007643-4ce9-44bc-b865-b1a142d1768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator_orf_list = []\n",
    "if 1==1:\n",
    "    parallel_output = Parallel(n_jobs=-1)(delayed(generate_comparator_orf_dataset)(num_cores, core_number, sequence_dirs) for core_number in core_numbers)\n",
    "    for x in parallel_output:\n",
    "        for y in x:\n",
    "            comparator_orf_list.append(y)\n",
    "util.produce_fasta_file(comparator_orf_list, project_dir + '/' + 'comparator_orf_candidates.faa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd1cf6-bb31-407e-b00a-457b9b0384b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "blastfn.build_blast_db(project_dir, 'comparator_full_sequences.faa', 'Comparator_Full_Sequences', 'F:/Datasets/BLAST/Comparator_Full_Sequences', db_type = 'nucl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd637a2-9793-4d04-826c-d9d177fc05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "blastfn.build_blast_db(project_dir, 'comparator_orf_candidates.faa', 'Comparator_ORF_Candidates', 'F:/Datasets/BLAST/Comparator_ORF_Candidates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e0beaa-dbd5-4085-ac45-372b32b4e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "blastfn.run_blastn('F:/Datasets/BLAST/Comparator_Full_Sequences', 'ultra_conserved_candidates.faa', 'Comparator_Full_Sequences', outfile = 'hits.csv', e_value = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45633ec-193b-452b-a240-b3ce5b707719",
   "metadata": {},
   "outputs": [],
   "source": [
    "blastfn.run_blastn('F:/Datasets/BLAST/Comparator_Full_Sequences', 'tb_cds.faa', 'Comparator_Full_Sequences', outfile = 'cds_hits.csv', e_value = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c6afdc-75a1-4144-bc15-c1170106dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "blastfn.run_blastp('F:/Datasets/BLAST/Comparator_ORF_Candidates', 'tb_orf_candidates.faa', 'Comparator_ORF_Candidates', outfile = 'hits.csv', e_value = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f22cb5-509b-443c-8ec8-fe1f5f25338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('F:/Project_Data/Project_10/names_dict.pkl', 'rb') as f:\n",
    "    names_dict = pickle.load(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b45ea14-8eee-4bdb-9c34-05a90c158a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = blastfn.process_blast_output('F:/Datasets/BLAST/Comparator_Full_Sequences/hits.csv', names_dict, top_hit_only = False)\n",
    "temp.to_csv('F:/Project_Data/Project_10/ultra_conserved_blast_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9cd613-7b8f-441e-85fa-f7a113e5f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = blastfn.process_blast_output('F:/Datasets/BLAST/Comparator_ORF_Candidates/hits.csv', names_dict, top_hit_only = False)\n",
    "temp.to_csv('F:/Project_Data/Project_10/orf_candidates_blast_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f96bc5-6a84-4ad0-adce-92d0e1574fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = blastfn.process_blast_output('F:/Datasets/BLAST/Comparator_Full_Sequences/cds_hits.csv', names_dict, top_hit_only = False)\n",
    "temp.to_csv('F:/Project_Data/Project_10/cds_blast_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93696eef-27de-4070-b4d8-3a47e7319a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_df = blastfn.process_blast_output('F:/Datasets/BLAST/Comparator_Full_Sequences/hits.csv', names_dict, top_hit_only = False)\n",
    "temp_df = blast_df[blast_df['target_species_name'] == 'Mycobacterium tuberculosis H37Rv']\n",
    "\n",
    "ultra_conserved_sections = list(temp_df['query_ref'].unique())\n",
    "ultra_conserved_section_dict = {}\n",
    "for x in ultra_conserved_sections:\n",
    "    temp = x.split('_')\n",
    "    ultra_conserved_section_dict[x] = (int(temp[1]),int(temp[3]))\n",
    "master_list = []\n",
    "for x in ultra_conserved_sections:\n",
    "    temp_list = []\n",
    "    temp_2_df = temp_df[temp_df['query_ref'] == x]\n",
    "    for i, r in temp_2_df.iterrows():\n",
    "        start = min(int(r['target_start_alignment']), int(r['target_end_alignment']))\n",
    "        stop = max(int(r['target_start_alignment']), int(r['target_end_alignment']))\n",
    "        for k, v in ultra_conserved_section_dict.items():\n",
    "            if v[1] > start and v[0] < stop:\n",
    "                temp_list.append((k))\n",
    "    a = list(set(temp_list))\n",
    "    a.sort(key = lambda x: int(x.split('_')[1]))\n",
    "    master_list.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16f993-53f5-4b39-96af-9df960b3f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_list.sort(key = lambda x: int(x[0].split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0aed84-bc50-4189-bbc0-543062a6731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(set([tuple(i) for i in master_list]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58adecc-c679-47c6-946b-90b0be366491",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sort(key = lambda x: int(x[0].split('_')[1]))\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab99491-776b-4ce7-92bb-d46d346a241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for x in a:\n",
    "    n+=1\n",
    "    print('**************************************************************************************************')\n",
    "    print('**************************************************************************************************')\n",
    "    print(x)\n",
    "    for i in x:\n",
    "        seq_start = int(i.split('_')[1])\n",
    "        seq_stop = int(i.split('_')[3])\n",
    "        for (feature, locus, start, stop, strand, product, comments) in mycobrowser_features:\n",
    "            if seq_start < stop and seq_stop > start:\n",
    "                print(i, locus, start, stop, strand, product)\n",
    "    if n > 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05496c83-06a7-427e-b8de-27dda63d5fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
