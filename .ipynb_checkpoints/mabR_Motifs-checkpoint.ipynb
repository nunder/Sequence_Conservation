{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e30ed4-8a0e-4a6f-96eb-dfe116dfb2de",
   "metadata": {},
   "source": [
    "#### Import packages, set directories and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c6377-5080-4c22-94db-feabe17cc47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from Bio import Entrez, SeqIO, AlignIO, pairwise2, Align, Seq, motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from Comparative_Analysis import Utilities as util\n",
    "from joblib import Parallel, delayed\n",
    "from Comparative_Analysis import Blast_Functions as blastfn\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from scipy.stats import chi2, binom\n",
    "from Comparative_Analysis import Alignment as alignfn\n",
    "from Bio.Align.Applications import MuscleCommandline\n",
    "import subprocess\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c1ca3d-a68f-4a9d-a5c4-25df7385b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'F:/Project_Data/mabR_Project'\n",
    "mycobacteria_seq_dir = 'F:/Datasets/NCBI_Refseq_Mycobacteriaceae_Complete_Annot_20230511/data'\n",
    "tb_species = 'AL123456.3' \n",
    "tb_annotation_dirname = 'GCA_000195955.2'\n",
    "min_region_length = 7 \n",
    "full_build = False\n",
    "num_cores = 16\n",
    "core_numbers = list(range(1, num_cores+1))\n",
    "muscle_exe = 'C:/Users/nicho/Muscle/muscle3.8.31_i86win32.exe'\n",
    "full_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bcbac1-03df-43f0-813e-0ca8f97a28bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycobacteria_dirs = []\n",
    "for dir in util.list_dirs(mycobacteria_seq_dir):\n",
    "    if os.path.exists(mycobacteria_seq_dir + '/' + dir + '/genomic.gbff'):\n",
    "        mycobacteria_dirs.append(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d6cb4b-f436-4866-8be5-fa1232f4d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_mycobacteria_rbh = pd.read_csv(project_dir + '/tb_mycobacteria_reciprocal_best_hits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e687d1b4-31ac-4d5c-a571-d05535336de9",
   "metadata": {},
   "source": [
    "#### Produce reference FASTA files (a) TB and (b) all mycobacteria for searching against motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3ef8bf-ee07-48a6-90ea-52542e7f19fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_record = next(SeqIO.parse(mycobacteria_seq_dir + '/' + tb_annotation_dirname + '/genomic.gbff', \"genbank\"))\n",
    "mtb_sequence = str(genome_record.seq)\n",
    "accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "util.produce_fasta_file([[accession_ver, mtb_sequence]], project_dir + '/mtb_seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d173f9d-f5bd-49d4-8ae1-789fae6e2a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    temp = []\n",
    "    for dir in util.list_dirs(mycobacteria_seq_dir): \n",
    "        if os.path.exists(mycobacteria_seq_dir + '/' + dir + '/genomic.gbff'):\n",
    "            for genome_record in (SeqIO.parse(mycobacteria_seq_dir + '/' + dir + '/genomic.gbff', \"genbank\")):\n",
    "                accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "                full_sequence = str(genome_record.seq)\n",
    "                temp.append([accession_ver, full_sequence])\n",
    "    util.produce_fasta_file(temp, project_dir + '/all_seq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fbf555-1082-451c-827f-492e9f228f5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Functions to locate arbitrary region in organism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6df13d-3ee1-485b-b5c7-8d788256b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotated_regions_dataset(num_subsets, subset_num, dir_list, seqdir): \n",
    "    output = []\n",
    "    sequence_dirs = util.chunk_list(dir_list, num_subsets, subset_num)\n",
    "    for dirname in sequence_dirs:\n",
    "        annotated_regions = []\n",
    "        intergenic_regions = []\n",
    "        for record in (SeqIO.parse(seqdir + '/'+dirname+'/genomic.gbff', \"genbank\")):\n",
    "            accession_ver = record.annotations['accessions'][0] + '.' + str(record.annotations['sequence_version'])\n",
    "            for feature in record.features:\n",
    "                a = feature.qualifiers\n",
    "                if feature.type not in ['source','gene'] and (int(feature.location.start) < int(feature.location.end)) and (int(feature.location.end) - int(feature.location.start)) < 1000000:\n",
    "                    if not(a.get(\"product\") == None):\n",
    "                           product = a.get(\"product\")[0]\n",
    "                    if not(a.get(\"locus_tag\")==None):\n",
    "                        locus_tag = a.get(\"locus_tag\")[0]\n",
    "                    else:\n",
    "                        locus_tag = feature.type\n",
    "                    annotated_regions.append((locus_tag, product, feature.type, int(feature.location.start), int(feature.location.end), str(feature.location.strand)))\n",
    "            annotated_regions.sort(key = lambda x: x[4])\n",
    "            prev_strand = 0\n",
    "            prev_locus = ''\n",
    "            prev_product = ''\n",
    "            max_stop = 0\n",
    "            for n, (locus, product, feature_type, start, stop, strand) in enumerate(annotated_regions):\n",
    "                if start > max_stop:\n",
    "                    intergenic_regions.append([prev_locus+':'+locus, prev_product + ':' + product, 'Inter-feature',max_stop, start, str(prev_strand)+':'+str(strand)])\n",
    "                if stop > max_stop:\n",
    "                    prev_locus = locus\n",
    "                    prev_product = product\n",
    "                    prev_strand = strand\n",
    "                max_stop = max(max_stop, stop)    \n",
    "            for x in intergenic_regions:\n",
    "                annotated_regions.append(x)\n",
    "            annotated_regions.sort(key = lambda x : x[4])\n",
    "            output.append([accession_ver, annotated_regions])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cad641-7b47-4eff-b637-970c4593b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_output = Parallel(n_jobs=-1)(delayed(annotated_regions_dataset)(num_cores, core_number, mycobacteria_dirs, mycobacteria_seq_dir) for core_number in core_numbers)\n",
    "annotated_regions_dict = {}\n",
    "for x in parallel_output:\n",
    "    for y in x:\n",
    "        annotated_regions_dict[y[0]] = y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e3d2c-4c89-4649-9e43-457a28c4a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def location(accession_ver, start1, end1):\n",
    "    feature_matches = []\n",
    "    for (locus, product, feature, start, stop, strand) in annotated_regions_dict[accession_ver]:\n",
    "            if start< end1 and stop > start1:\n",
    "                overlap = str(int(100*(min(end1, stop) - max(start1, start))/ (end1-start1)))+'%'\n",
    "                feature_matches.append([locus, product, feature, overlap, strand])\n",
    "    return feature_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd747b2c-841f-40e5-982d-45d812215121",
   "metadata": {},
   "source": [
    "#### Create dictionary of upstream sequences - sequence continue upstream to the next CDS not next feature (e.g. if intervening repeat region this is included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21696e2c-0779-4ad9-b1ee-63781969bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_upstream_sequence_dataset(num_subsets, subset_num, dir_list, seqdir): \n",
    "    sequence_dirs = util.chunk_list(dir_list, num_subsets, subset_num)\n",
    "    upstream_cds_regions = []\n",
    "    for dirname in (sequence_dirs):\n",
    "        all_features = []\n",
    "        cds_features = []\n",
    "        for genome_record in SeqIO.parse(mycobacteria_seq_dir + '/' + dirname + '/genomic.gbff', \"genbank\"):\n",
    "            accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "            full_sequence = str(genome_record.seq)\n",
    "            len_full_sequence = len(full_sequence)\n",
    "            for feature in genome_record.features:\n",
    "                if feature.type in ['gene', 'source']:\n",
    "                    continue\n",
    "                a = feature.qualifiers\n",
    "                feature_type = feature.type\n",
    "                if a.get(\"locus_tag\") != None:\n",
    "                    locus_tag = a.get(\"locus_tag\")[0]\n",
    "                    accession_locus = accession_ver + '@' + locus_tag\n",
    "                else:\n",
    "                    accession_locus  = ''\n",
    "                (start, stop, strand) = (int(feature.location.start), int(feature.location.end), int(feature.location.strand))\n",
    "                all_features.append([accession_locus, feature_type, start, stop, strand])\n",
    "                if feature_type == 'CDS':\n",
    "                    cds_features.append([accession_locus, feature_type, start, stop, strand])\n",
    "            \n",
    "            features = cds_features  # Replace with line below if you want to go upstream only to next annotated feature and not next CDS\n",
    "            #features = all_features\n",
    "            \n",
    "            # Positive strand upstream \n",
    "            features.sort(key = lambda x: x[2])\n",
    "            max_stop = 0\n",
    "            for (accession_locus, feature_type, start, stop, strand) in features:\n",
    "                if max_stop < start and feature_type == 'CDS' and strand == 1 and start - max_stop < 100000:    #Avoid joins where biopython interprets inconsistently \n",
    "                    upstream_cds_regions.append([accession_locus, max_stop, start, strand, full_sequence[max_stop: start+3]])\n",
    "                max_stop = max(max_stop, stop)\n",
    "            # Negative strand upstream\n",
    "            features.sort(key = lambda x: x[3], reverse = True)\n",
    "            min_start = len(full_sequence)-1\n",
    "            for (accession_locus, feature_type, start, stop, strand) in features:\n",
    "                if stop < min_start and feature_type == 'CDS' and strand == -1 and min_start - stop < 100000:\n",
    "                    upstream_cds_regions.append([accession_locus, stop, min_start, strand, reverse_complement(full_sequence[stop-3: min_start])])\n",
    "                min_start = min(min_start, start)\n",
    "    return (upstream_cds_regions)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8075f18-ddc6-43c2-aaec-d25000f9d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if full_build == True:\n",
    "if 1==1:\n",
    "    mycobacteria_upstream_dict = {}\n",
    "    parallel_output = Parallel(n_jobs=-1)(delayed(generate_upstream_sequence_dataset)(num_cores, core_number, mycobacteria_dirs, mycobacteria_seq_dir) for core_number in core_numbers)\n",
    "    for x in parallel_output:\n",
    "        for n in x:\n",
    "            mycobacteria_upstream_dict[n[0]] = [n[1], n[2], n[3], n[4]]\n",
    "    with open(project_dir + '/mycobacteria_upstream_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(mycobacteria_upstream_dict, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b4bf2c-e1bb-4623-aed5-c0da8fb1f9c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Functions to run MEME and FIMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66efc6cc-4049-4566-bca3-404079e7a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_meme(search_regions_loc, output_dir, min_width, min_sites):\n",
    "    subprocess.run('wsl export PATH=$HOME/meme/bin:$HOME/meme/libexec/meme-5.4.1:usr/bin:$PATH ; meme '+ util.wslname(search_regions_loc) + ' -oc '+ util.wslname(output_dir) +' -dna -evt 0.01 -revcomp -mod anr -brief 4000 -minw ' + str(min_width) +' -maxw 200 -minsites ' + str(min_sites)\n",
    "               , shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faaf599-3275-429b-ad53-99f29695e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fimo(motif_file, sequence_to_search_file, output_dir):\n",
    "    subprocess.run('wsl export PATH=$HOME/meme/bin:$HOME/meme/libexec/meme-5.4.1:usr/bin:$PATH ; fimo -oc ' + util.wslname(output_dir) + ' ' + util.wslname(motif_file) + ' ' + util.wslname(sequence_to_search_file)\n",
    "               , shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304afe39-8235-471a-9093-ed083a01db8a",
   "metadata": {},
   "source": [
    "#### Produce dictionary with upstream and downstream sequences relative to CDS locus id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0123bd-bff9-4ef8-885b-bb6ba9691e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_upstream_dict = {}\n",
    "tb_downstream_dict = {}\n",
    "all_features = []\n",
    "genome_record =  next(SeqIO.parse(mycobacteria_seq_dir + '/'+tb_annotation_dirname+'/genomic.gbff', \"genbank\"))\n",
    "full_sequence = str(genome_record.seq)\n",
    "len_full_sequence = len(full_sequence)\n",
    "for feature in genome_record.features:\n",
    "    if feature.type in ['gene', 'source']:\n",
    "        continue\n",
    "    a = feature.qualifiers\n",
    "    feature_type = feature.type\n",
    "    if a.get(\"locus_tag\") != None:\n",
    "        locus_tag = a.get(\"locus_tag\")[0]\n",
    "    else:\n",
    "        locus_tag  = ''\n",
    "    (start, stop, strand) = (int(feature.location.start), int(feature.location.end), int(feature.location.strand))\n",
    "    all_features.append([locus_tag, feature_type, start, stop, strand])\n",
    "\n",
    "# Positive strand upstream \n",
    "all_features.sort(key = lambda x: x[2])\n",
    "max_stop = 0\n",
    "for (locus, feature_type, start, stop, strand) in all_features:\n",
    "    if max_stop < start and feature_type == 'CDS' and strand == 1 and start - max_stop < 100000:    #Avoid joins where biopython interprets inconsistently \n",
    "        tb_upstream_dict[locus] = full_sequence[max_stop: start+3]\n",
    "    max_stop = max(max_stop, stop)\n",
    "# Negative strand upstream\n",
    "all_features.sort(key = lambda x: x[3], reverse = True)\n",
    "min_start = len(full_sequence)-1\n",
    "for (locus, feature_type, start, stop, strand) in all_features:\n",
    "    if stop < min_start and feature_type == 'CDS' and strand == -1 and min_start - stop < 100000:\n",
    "        tb_upstream_dict[locus] = util.reverse_complement(full_sequence[stop-3: min_start])\n",
    "    min_start = min(min_start, start)\n",
    "    \n",
    "# Positive strand downstream\n",
    "all_features.sort(key = lambda x: x[3], reverse = True)\n",
    "min_start = len(full_sequence)-1\n",
    "for (locus, feature_type, start, stop, strand) in all_features:\n",
    "    if stop < min_start and feature_type == 'CDS' and strand == 1 and min_start - stop < 100000:\n",
    "        tb_downstream_dict[locus] = full_sequence[stop-3: min_start]\n",
    "    min_start = min(min_start, start)\n",
    "# Negative strand downstream \n",
    "all_features.sort(key = lambda x: x[2])\n",
    "max_stop = 0\n",
    "for (locus, feature_type, start, stop, strand) in all_features:\n",
    "    if max_stop < start and feature_type == 'CDS' and strand == -1 and start - max_stop < 100000:    #Avoid joins where biopython interprets inconsistently \n",
    "        tb_downstream_dict[locus] = util.reverse_complement(full_sequence[max_stop: start+3])\n",
    "    max_stop = max(max_stop, stop)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb740d-f4e8-4842-b6f6-0084271d62e2",
   "metadata": {},
   "source": [
    "#### Import list of significantly up/downregulated genes and produce fasta file of upstream sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe78c9-fd29-4b8c-bc7d-3ce16e4fb4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "regulation_type_dict = {}\n",
    "p_val_dict = {}\n",
    "downreg_genes = pd.read_excel(project_dir + '/2022-10-02_data_NU_NAs_renamed.xlsx', sheet_name = 'significant genes downregulated')\n",
    "upreg_genes = pd.read_excel(project_dir + '/2022-10-02_data.xlsx', sheet_name = 'significant genes upregulated')\n",
    "all_genes = pd.read_excel(project_dir + '/2022-10-02_data.xlsx', sheet_name = 'all genes')\n",
    "gene_list = []\n",
    "for i, r in downreg_genes.iterrows():\n",
    "    gene_list.append(r['Locus'])\n",
    "    regulation_type_dict[r['Locus']] = 'Downregulated'\n",
    "for i, r in upreg_genes.iterrows():\n",
    "    gene_list.append(r['Locus'])\n",
    "    regulation_type_dict[r['Locus']] = 'Upregulated'\n",
    "for i, r in all_genes.iterrows():\n",
    "    if r['padj'] == 'NA':\n",
    "        p_val_dict[r['Locus']] = 999\n",
    "    else:    \n",
    "        p_val_dict[r['Locus']] = r['padj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f57e96-7a0f-48eb-8d5b-008b3a27e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_upstream_tb_regions = []\n",
    "significant_downstream_tb_regions = []\n",
    "for gene in gene_list:\n",
    "    locus = str(gene)\n",
    "    if locus in tb_upstream_dict:\n",
    "        upstream_region = tb_upstream_dict[locus][:-3]  # Remove start codon of downstream gene\n",
    "        if len(upstream_region) >= min_region_length:\n",
    "            significant_upstream_tb_regions.append([locus, upstream_region])\n",
    "    if locus in tb_downstream_dict:\n",
    "        downstream_region = tb_downstream_dict[locus][:-3]  # Remove start codon of downstream gene\n",
    "        if len(downstream_region) >= min_region_length:\n",
    "            significant_downstream_tb_regions.append([locus, downstream_region])\n",
    "util.produce_fasta_file(significant_upstream_tb_regions, project_dir + '/significant_upstream_tb_regions.faa')\n",
    "util.produce_fasta_file(significant_downstream_tb_regions, project_dir + '/significant_downstream_tb_regions.faa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8399606-8ab1-4292-ae09-29791de85a15",
   "metadata": {},
   "source": [
    "#### Run MEME, search against tb using FIMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7330b9c-0cb3-4362-82f8-7ede1e1045f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_meme(project_dir + '/significant_upstream_tb_regions.faa',project_dir + '/MEME_Upstream_Output',3,5)\n",
    "run_meme(project_dir + '/significant_downstream_tb_regions.faa',project_dir + '/MEME_Downstream_Output',3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb56b27-9fff-483b-906e-dd001e482986",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fimo(project_dir + '/MEME_Upstream_Output/meme.txt', project_dir + '/mtb_seq' , project_dir + '/FIMO_Upstream_Output')\n",
    "run_fimo(project_dir + '/MEME_Downstream_Output/meme.txt', project_dir + '/mtb_seq' , project_dir + '/FIMO_Downstream_Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69039c-1b24-46ce-b54f-319bc84cce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "fimo_upstream_hits = pd.read_csv(project_dir + '/FIMO_Upstream_Output/fimo.tsv', sep='\\t')\n",
    "fimo_downstream_hits = pd.read_csv(project_dir + '/FIMO_Downstream_Output/fimo.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb7fce3-013b-475d-88ab-3d678ea162eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_meme(project_dir + '/Intergenic_Regions/Rv2248/mycobacteria_intergenic_regions.fasta',project_dir + '/Temp2_MEME_Output',3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ed4dca-dc4f-43d4-80b9-8981ae530ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fimo(project_dir + '/Temp_MEME_Output/meme.txt', project_dir + '/all_seq' , project_dir + '/Temp_FIMO_Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e43d6e-86cb-4cfa-b4e2-e052cde8e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_matched_sequence_file(hit_df, output_file):\n",
    "    matched_sequences = []\n",
    "    for i, r in hit_df.iterrows():\n",
    "        if '#' in r['motif_id']:\n",
    "            continue\n",
    "        if float(r['q-value']) < 1e-3:\n",
    "            matched_sequences.append([str(r['start'])+'_'+str(r['stop']), r['matched_sequence']])\n",
    "    util.produce_fasta_file(matched_sequences, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c4e8b6-c759-4859-89b2-d544a2996524",
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_matched_sequence_file(fimo_upstream_hits, project_dir + '/fimo_upstream_hit_sequences.faa')\n",
    "produce_matched_sequence_file(fimo_downstream_hits, project_dir + '/fimo_downstream_hit_sequences.faa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7598e4-63e8-4dbd-9deb-55bc1438fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_meme(project_dir + '/fimo_upstream_hit_sequences.faa', project_dir + '/Second_MEME_Upstream_Output',3,5)\n",
    "run_meme(project_dir + '/fimo_downstream_hit_sequences.faa', project_dir + '/Second_MEME_Downstream_Output',3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc9df09-edea-48ac-8508-a91e50e06b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fimo(project_dir + '/Second_MEME_Upstream_Output/meme.txt', project_dir + '/all_seq' , project_dir + '/Second_FIMO_Upstream_Output')\n",
    "run_fimo(project_dir + '/Second_MEME_Downstream_Output/meme.txt', project_dir + '/all_seq' , project_dir + '/Second_FIMO_Downstream_Output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1dadb3-0799-4a79-834b-e430c1715702",
   "metadata": {},
   "source": [
    "#### Final motif and searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed590f-b6b9-4206-b591-b6ca506b3041",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_fimo_hits = pd.read_csv(project_dir + '/Temp_FIMO_Output/fimo.tsv', sep='\\t')\n",
    "hit_dict = {}\n",
    "for i, r in temp_fimo_hits.iterrows():\n",
    "    if '#' in r['motif_id']:\n",
    "        continue\n",
    "    organism = r['sequence_name']\n",
    "    motif_id = r['motif_alt_id']\n",
    "    if float(r['q-value']) < 1e-4 and motif_id == 'MEME-1':\n",
    "        temp = location(r['sequence_name'],int(r['start']), int(r['stop']))\n",
    "        if len(temp) > 0:\n",
    "            temp.sort(key = lambda x: float(x[3].strip('%')), reverse = True)\n",
    "            main_location = temp[0]\n",
    "        else:\n",
    "            main_location = ''\n",
    " \n",
    "\n",
    "        info = [int(r['start']), int(r['stop']), r['strand'], float(r['q-value']), main_location, r['matched_sequence']]\n",
    "        if organism in hit_dict:\n",
    "            hit_dict[organism].append(info)\n",
    "        else:\n",
    "            hit_dict[organism] = [info]\n",
    "\n",
    "for k, v in hit_dict.items():\n",
    "    v.sort(key = lambda x: x[0])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8348eac6-ce7c-49c2-9add-12fbe2913f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = []\n",
    "v = hit_dict[tb_species]\n",
    "for n, (start, stop, strand, q, loc, matched_seq) in enumerate(v):\n",
    "    for x in loc[0].split(':'):\n",
    "        genes.append(x)\n",
    "b = set(genes)\n",
    "inters = b.intersection(set(gene_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5206da2-724d-45a1-b11e-32cf459397df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(b), len(inters), len(gene_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22919f-59a6-4fa9-8d96-b881acecb5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.intersection(set(gene_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfbe301-ff1c-4246-94f6-d00c85c84099",
   "metadata": {},
   "outputs": [],
   "source": [
    "1- binom.cdf(len(inters), len(b),(len(gene_list))/3900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59131b-c9a2-411d-8658-f9c6aeff20f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(hit_info, columns = ['name', 'variable', 'value']).to_csv(project_dir + '/Hit_Counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7876e157-c075-4044-b5eb-18e182da0f55",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Buiild phylo tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e913452-4203-42f1-9a0c-eb6f50c13353",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = len(tb_mycobacteria_rbh['target_species_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae63ded-7e41-4437-9069-1fc771ab8a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ortholog_refs = []\n",
    "temp = tb_mycobacteria_rbh.groupby('query_ref').agg({'target_ref': \"count\", 'percent_identical_matches': \"min\"}).reset_index()\n",
    "temp = temp.query('target_ref == @max_len and percent_identical_matches > 85')\n",
    "for i, r in temp.iterrows():\n",
    "    full_ortholog_refs.append(r['query_ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f29d1-311f-41f8-aec4-10d742a249e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_protein_dataset(num_subsets, subset_num, dir_list, seqdir): \n",
    "    sequence_dirs = util.chunk_list(dir_list, num_subsets, subset_num)\n",
    "    all_cds = []\n",
    "    all_tb_cds = []\n",
    "    names = []\n",
    "    sequences = []\n",
    "    locations = []\n",
    "    all_cds_nt = []\n",
    "    all_cds_200_up_nt = []\n",
    "    for dirname in (sequence_dirs):\n",
    "        for genome_record in SeqIO.parse(seqdir + '/' + dirname + '/genomic.gbff', \"genbank\"):\n",
    "            accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "            names.append([accession_ver, genome_record.annotations['organism']])\n",
    "            full_sequence = str(genome_record.seq)\n",
    "            sequences.append([accession_ver, full_sequence])\n",
    "            for feature in genome_record.features:\n",
    "                a = feature.qualifiers\n",
    "                if feature.type == 'CDS' and a.get(\"translation\") != None and a.get(\"locus_tag\") != None:\n",
    "                    locus_tag = a.get(\"locus_tag\")[0]\n",
    "                    accession_locus = accession_ver + '@' + locus_tag\n",
    "                    translation = a.get(\"translation\")[0]\n",
    "                    (start, stop, strand) = (int(feature.location.start), int(feature.location.end), int(feature.location.strand))\n",
    "                    if strand == 1:\n",
    "                        nt_sequence = full_sequence[start: stop]\n",
    "                        nt_sequence_200_up = full_sequence[start-200: start]\n",
    "                    else:\n",
    "                        nt_sequence = util.reverse_complement(full_sequence[start:stop])\n",
    "                        nt_sequence_200_up = util.reverse_complement(full_sequence[stop:stop+200])\n",
    "                    locations.append([accession_locus, (start, stop, strand)])\n",
    "                    all_cds.append([accession_locus, translation])\n",
    "                    all_cds_nt.append([accession_locus, nt_sequence])\n",
    "                    all_cds_200_up_nt.append([accession_locus, nt_sequence_200_up])\n",
    "    return (all_cds, names, locations, sequences, all_cds_nt, all_cds_200_up_nt)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b870157-c0aa-499e-a1e9-2fed6b97592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_build = True\n",
    "if full_build == True:\n",
    "    parallel_output = Parallel(n_jobs=-1)(delayed(generate_protein_dataset)(num_cores, core_number, mycobacteria_dirs, mycobacteria_seq_dir) for core_number in core_numbers)\n",
    "    protein_dict = {}\n",
    "    for x in parallel_output:\n",
    "        for temp in x[0]:\n",
    "            protein_dict[temp[0]] = temp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef5d679-1c5b-4600-886a-a393f4e1cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_alignment_dict = {}\n",
    "for ref in tqdm(full_ortholog_refs):\n",
    "    temp_seq = []\n",
    "    temp = tb_mycobacteria_rbh[tb_mycobacteria_rbh['query_ref'] == ref]\n",
    "    for i, r in temp.iterrows():\n",
    "        temp_seq.append([r['target_species_name'].replace(' ','_'),protein_dict[r['target_ref']]])\n",
    "    util.produce_fasta_file(temp_seq, project_dir +'/temp_seq.fasta')    \n",
    "    cline = MuscleCommandline(muscle_exe, input= project_dir +'/temp_seq.fasta', out=project_dir +'/temp_seq_alignment.fasta')\n",
    "    result = cline();    \n",
    "    alignment = util.read_fasta_to_array(project_dir +'/temp_seq_alignment.fasta')    \n",
    "    for (name, sequence) in zip(alignment[0], alignment[1]):\n",
    "        if name in concatenated_alignment_dict:\n",
    "            temp2 = concatenated_alignment_dict[name]\n",
    "            concatenated_alignment_dict[name] = temp2 + sequence\n",
    "        else:\n",
    "            concatenated_alignment_dict[name] = sequence\n",
    "temp  = []\n",
    "for k, v in concatenated_alignment_dict.items():\n",
    "    temp.append([k, v])\n",
    "util.produce_fasta_file(temp, project_dir + '/concatenated_alignment.fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49496085-01a5-49e8-bcc3-8512d46fb7d8",
   "metadata": {},
   "source": [
    "#### Number of motif hits in different species and output so can be merged with R to display info against phylo tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3b880-f758-4b77-a272-0a4d052bf030",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dict = {}\n",
    "for dirname in (mycobacteria_dirs):\n",
    "        for genome_record in SeqIO.parse(mycobacteria_seq_dir + '/' + dirname + '/genomic.gbff', \"genbank\"):\n",
    "            accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "            names_dict[accession_ver] = genome_record.annotations['organism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f1c29-7df7-4422-a35d-33eb7022e6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_info = []\n",
    "for k, v in hit_dict.items():\n",
    "    hit_info.append([names_dict[k].replace(' ','_'),'Num_hits', len(v)])\n",
    "pd.DataFrame(hit_info, columns = ['name', 'variable', 'value']).to_csv(project_dir + '/Hit_Counts.csv')\n",
    "    \n",
    "    #hit_info.append([organism_name.replace(' ','_'), 'Num_hits', len(temp_fimo_hit_positions)])\n",
    "    #    print(organism_name.replace(' ','_'), len(temp_fimo_hit_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c5d06-3fcf-45ab-9e6c-db6a851fa1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ortholog_in_mtb(accession_ver, locus):\n",
    "    gene = accession_ver + '@' + locus\n",
    "    temp = tb_mycobacteria_rbh.query('target_ref == @gene and query_species == @tb_species')\n",
    "    if len(temp) == 1:\n",
    "        for i, r in temp.iterrows():\n",
    "            temp2 = r['query_ref']\n",
    "            return temp2.split('@')[1]\n",
    "    else:\n",
    "        return 'No_orth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee14d6-2213-4814-86e0-6013ffc34a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ortholog_appearances = {}\n",
    "for k, val in hit_dict.items():\n",
    "    for v in val:\n",
    "        if len(v[4]) > 0:\n",
    "            x = v[4][0].split(':')\n",
    "            temp = ':'.join([ortholog_in_mtb(k,u) for u in x])\n",
    "            if temp in ortholog_appearances:\n",
    "                ortholog_appearances[temp] +=1\n",
    "            else:\n",
    "                ortholog_appearances[temp] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ba391d-ea6f-4166-ba89-fcf32553d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for k, v in ortholog_appearances.items():\n",
    "    temp.append([k, v])\n",
    "temp.sort(key = lambda x: x[1], reverse=True)\n",
    "for x in temp:\n",
    "    if 'Rv2248' in x[0]:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b319bc8b-6416-41e0-898d-9c02d0547352",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, val in hit_dict.items():\n",
    "    for v in val:\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5fdc2c-22cf-4675-a222-9872b8264f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
