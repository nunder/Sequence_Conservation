{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e36786c5-8a4d-4b87-9f58-d6a718cc37c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from Bio import Entrez, SeqIO, AlignIO, pairwise2, Align, Seq, motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from scipy.stats import binom\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "from Comparative_Analysis import Sequence_Analysis_Routines as sar\n",
    "from Comparative_Analysis import Utilities as util\n",
    "from Comparative_Analysis import Alignment as align\n",
    "from Comparative_Analysis import Blast_Functions as blastfn\n",
    "import random\n",
    "import copy\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "from Bio.Align.Applications import MuscleCommandline\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c8f9536-cd01-45c5-abdb-ef4e9a9dba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_run = True\n",
    "project_dir = 'D:/Project_Data/Project_8'\n",
    "datasets_dir = project_dir + '/Datasets'\n",
    "output_dir = project_dir + '/RScape_Local_Run_2'\n",
    "wsl_output_loc = util.wslname(output_dir)\n",
    "seq_dir = 'D:/Actinobacteria_Ref_Rep_Lev_Complete'\n",
    "blast_dir = 'D:/BLAST/actinobacteria_ref_rep_comp'\n",
    "blast_db_name = 'actinobacteria_ref_rep_comp'\n",
    "num_cores = 16\n",
    "core_numbers = list(range(1, num_cores+1))\n",
    "reference_species_filename = 'GCF_000195955.2_ASM19595v2_genomic.gbff'\n",
    "species_list = util.list_files(seq_dir)\n",
    "species_list = [x for x in species_list if '.gbff' in x]    # Exclude other files generated in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc8b101-a92f-43bc-bf17-b9010419bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_dict = {}\n",
    "def create_filename_dict(num_subsets, subset_num, id_list):\n",
    "    ids = util.chunk_list(id_list, num_subsets, subset_num)\n",
    "    temp = []\n",
    "    for id in (ids):\n",
    "        for genome_record in SeqIO.parse(seq_dir + '/' + id, \"genbank\"):\n",
    "            organism_name = genome_record.annotations['organism']\n",
    "            accession_ver = genome_record.annotations['accessions'][0] + '.' + str(genome_record.annotations['sequence_version'])\n",
    "            temp.append((accession_ver, id))\n",
    "    return temp\n",
    "parallel_output = Parallel(n_jobs=-1)(delayed(create_filename_dict)(num_cores, core_number, species_list) for core_number in core_numbers)\n",
    "temp = [item for sublist in parallel_output for item in sublist]\n",
    "for (accession_ver, filename) in temp:\n",
    "    filename_dict[accession_ver] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efec2081-870d-4770-bb11-ad26b1632717",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/Project_Data/Project_8/Output/gene_info_dict.pkl', 'rb') as f:\n",
    "    gene_info_dict = pickle.load(f) \n",
    "with open('D:/Project_Data/Project_8/Output//names_dict.pkl', 'rb') as f:\n",
    "    names_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9276d32-87b9-4a02-9273-c33d796993a3",
   "metadata": {},
   "source": [
    "##### Generate files containing all genic and intergenic regions in reference organism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad963602-bf2d-4080-a2bd-dd76b074886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "genome_record = next(SeqIO.parse(seq_dir + '/' + reference_species_filename, \"genbank\"))\n",
    "full_sequence = str(genome_record.seq)\n",
    "mycobrowser_df = pd.read_excel(datasets_dir+'/Mycobrowser_Release_4.xlsx')\n",
    "for i, r in mycobrowser_df.iterrows():\n",
    "    if r['Strand'] == '+':\n",
    "        strand = 1\n",
    "    else:\n",
    "        strand = -1\n",
    "    features.append([r['Locus'],r['Start']-1, r['Stop'], strand])\n",
    "features.sort(key=lambda x: x[1])\n",
    "feature_info = []\n",
    "for i, feature in enumerate(features):\n",
    "    if feature[3] == 1:\n",
    "        feature_sequence = full_sequence[feature[1]: feature[2]]\n",
    "    else:\n",
    "        feature_sequence = util.reverse_complement(full_sequence[feature[1]: feature[2]])\n",
    "    if feature[1] < feature[2]:  \n",
    "        if i > 0 and feature[1] > features[i-1][2]:\n",
    "            utr_coords = (features[i-1][2], feature[1])\n",
    "            if feature[3] == 1:\n",
    "                utr_sequence = full_sequence[features[i-1][2]: feature[1]]\n",
    "            else:\n",
    "                utr_sequence =  util.reverse_complement(full_sequence[features[i-1][2]: feature[1]])\n",
    "            utr_length = len(utr_sequence)\n",
    "        else:\n",
    "            utr_coords = (0,0)\n",
    "            utr_sequence = ''\n",
    "            utr_length = 0\n",
    "        feature_info.append([feature[0], feature[1], feature[2], feature_sequence, len(feature_sequence), utr_coords[0], utr_coords[1], utr_sequence, utr_length])\n",
    "genic_intergenic_df = pd.DataFrame(feature_info, columns = ['Locus', 'Start' , 'End', 'Sequence', 'Length', 'Upstream_Start' , 'Upstream_End', 'Upstream_Sequence', 'Upstream_Length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a2571d5-8455-4e72-b734-54acd8424424",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(datasets_dir + '/RFAM_Hits_H37Rv_sorted.csv')\n",
    "temp_out = []\n",
    "for i, r in temp.iterrows():\n",
    "    if r['strand'] == '+':\n",
    "        start = int(r['seq from'])\n",
    "        end = int(r['seq to'])\n",
    "        sequ = full_sequence[start: end]\n",
    "    else:\n",
    "        start = int(r['seq to'])\n",
    "        end = int(r['seq from'])\n",
    "        sequ = util.reverse_complement(full_sequence[start:end])\n",
    "    seq_len = len(sequ)\n",
    "    temp_out.append([r['#idx'], 0, 0, '',0,start, end, sequ, seq_len])\n",
    "rfam_df = pd.DataFrame(temp_out, columns = ['Locus', 'Start' , 'End', 'Sequence', 'Length', 'Upstream_Start' , 'Upstream_End', 'Upstream_Sequence', 'Upstream_Length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5d47f83-317a-4f55-aeaa-dbe0c891fc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Locus</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Length</th>\n",
       "      <th>Upstream_Start</th>\n",
       "      <th>Upstream_End</th>\n",
       "      <th>Upstream_Sequence</th>\n",
       "      <th>Upstream_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>10887</td>\n",
       "      <td>10960</td>\n",
       "      <td>GGCCTATAGCTCAGGCGGTTAGAGCGCTTCGCTGATAACGAAGAGG...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>11112</td>\n",
       "      <td>11184</td>\n",
       "      <td>GGGCCTTAGCTCAGTTGGTAGAGCACTGCCTTTGCAAGGCAGGGGT...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>25644</td>\n",
       "      <td>25726</td>\n",
       "      <td>GGCGAGTGGCGGAATGGCAGACGCGCTGGCTTCAGGTGCCAGTGTC...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>79204</td>\n",
       "      <td>79294</td>\n",
       "      <td>TGACGCGATGTGGGAGAACCTCCATGTCGAGGCGCCGTAGGAGCAA...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>80218</td>\n",
       "      <td>80316</td>\n",
       "      <td>AGAGCCAGATACGGTGAAAGTCGCACGTCCGGTTCGAAGGGCGGCC...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4168345</td>\n",
       "      <td>4168430</td>\n",
       "      <td>GAGGATTCGCCTAGTGGCCTATGGCGCTCGCCTGGAACGCGGGTTG...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4199131</td>\n",
       "      <td>4199217</td>\n",
       "      <td>GGTGGCGTGTCCGAGCGGCCTAAGGAGCACGCCTCGAAAGCGTGTG...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4216865</td>\n",
       "      <td>4216937</td>\n",
       "      <td>GCGCCCGTAGCTCAACGGATAGAGCATCTGACTACGGATCAGAAGG...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4216968</td>\n",
       "      <td>4217056</td>\n",
       "      <td>GGAGGCGTGCCAGAGCGGCCGAATGGGGCTCACTGCTAATGAGTTG...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>4222581</td>\n",
       "      <td>4222667</td>\n",
       "      <td>GGTGGCGTGGCAGAGCGGCCTAATGCACTCGCCTTGAAAGCGAGAG...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Locus  Start  End Sequence  Length  Upstream_Start  Upstream_End  \\\n",
       "0      33      0    0                0           10887         10960   \n",
       "1      40      0    0                0           11112         11184   \n",
       "2      84      0    0                0           25644         25726   \n",
       "3      82      0    0                0           79204         79294   \n",
       "4      91      0    0                0           80218         80316   \n",
       "..    ...    ...  ...      ...     ...             ...           ...   \n",
       "87     81      0    0                0         4168345       4168430   \n",
       "88     71      0    0                0         4199131       4199217   \n",
       "89     56      0    0                0         4216865       4216937   \n",
       "90     76      0    0                0         4216968       4217056   \n",
       "91     64      0    0                0         4222581       4222667   \n",
       "\n",
       "                                    Upstream_Sequence  Upstream_Length  \n",
       "0   GGCCTATAGCTCAGGCGGTTAGAGCGCTTCGCTGATAACGAAGAGG...               73  \n",
       "1   GGGCCTTAGCTCAGTTGGTAGAGCACTGCCTTTGCAAGGCAGGGGT...               72  \n",
       "2   GGCGAGTGGCGGAATGGCAGACGCGCTGGCTTCAGGTGCCAGTGTC...               82  \n",
       "3   TGACGCGATGTGGGAGAACCTCCATGTCGAGGCGCCGTAGGAGCAA...               90  \n",
       "4   AGAGCCAGATACGGTGAAAGTCGCACGTCCGGTTCGAAGGGCGGCC...               98  \n",
       "..                                                ...              ...  \n",
       "87  GAGGATTCGCCTAGTGGCCTATGGCGCTCGCCTGGAACGCGGGTTG...               85  \n",
       "88  GGTGGCGTGTCCGAGCGGCCTAAGGAGCACGCCTCGAAAGCGTGTG...               86  \n",
       "89  GCGCCCGTAGCTCAACGGATAGAGCATCTGACTACGGATCAGAAGG...               72  \n",
       "90  GGAGGCGTGCCAGAGCGGCCGAATGGGGCTCACTGCTAATGAGTTG...               88  \n",
       "91  GGTGGCGTGGCAGAGCGGCCTAATGCACTCGCCTTGAAAGCGAGAG...               86  \n",
       "\n",
       "[92 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfam_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad67350d-b3f3-4fec-bd71-8466a5d06a39",
   "metadata": {},
   "source": [
    "##### Run HMMER and INFERNAL iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e68a9322-7491-4f70-8cc2-b54d60e2e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "genic_test = genic_df[genic_df.Locus.isin(['Rv0756c'])]    # True downstream gene\n",
    "intergenic_test = intergenic_df[intergenic_df.Locus.isin(['Rv0757'])]   # Annotation order upstream gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "95e53ca8-17c6-4ed2-8af6-4b7ad72e2c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rv0756c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "hmmer_eval =  1e-10\n",
    "hmmer_eval2 = 1e-5\n",
    "query_file = 'genic_region.faa'\n",
    "hm_model_file = 'hmm.hmm'\n",
    "for i, r in genic_test.iterrows():\n",
    "    if r['Length'] >= 60:\n",
    "        sequence_list = [[r['Locus'], r['Sequence']]]\n",
    "        locus_id = r['Locus']\n",
    "        print(locus_id)\n",
    "        results_dir = output_dir + '/' + locus_id\n",
    "        if not os.path.exists(results_dir):\n",
    "            os.makedirs(results_dir)\n",
    "        util.produce_fasta_file(sequence_list, results_dir + '/' + query_file)\n",
    "\n",
    "        blastfn.nhmmer_search_sequence(results_dir, query_file, datasets_dir, 'full_sequences.faa', 'align_0.sto', 'output.txt', 'hsummary_0.txt', hmmer_eval) \n",
    "        if not os.path.exists(results_dir +'/hsummary_0.txt'):\n",
    "            continue\n",
    "        blastfn.align_keep_top_hit_per_species(results_dir, 'hsummary_0.txt', 'align_0.sto', 'align_bh_0.sto', 'HMMER', hmmer_eval)\n",
    "        \n",
    "        #for i in range(3):\n",
    "        #    if i == 2:\n",
    "        #        heval = hmmer_eval2\n",
    "        #    else:\n",
    "        #        heval = hmmer_eval\n",
    "        #        blastfn.hmmer_build(results_dir, 'align_bh_'+str(i)+'.sto' ,hm_model_file)\n",
    "        #        blastfn.nhmmer_search_model(results_dir, hm_model_file, datasets_dir, 'full_sequences.faa', 'align_'+str(i+1)+'.sto', 'output.txt', 'hsummary_'+str(i+1)+'.txt', heval)      #seq_dir, 'full_sequences.faa'\n",
    "        #        blastfn.align_keep_top_hit_per_species(results_dir, 'hsummary_'+str(i+1)+'.txt', 'align_'+str(i+1)+'.sto', 'align_bh_'+str(i+1)+'.sto', 'HMMER', heval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "44759a44-4289-483d-8b12-6826a4e14a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(accession, stop, start):\n",
    "    output_values = []\n",
    "    for feature_info in gene_info_dict[accession]:\n",
    "        start_f = int(feature_info[1])\n",
    "        stop_f = int(feature_info[2])\n",
    "        if stop_f - start_f  > 100000:   #Something wrong!\n",
    "            continue\n",
    "        start_1 = min(stop, start)\n",
    "        stop_1 = max(stop, start)\n",
    "        if stop_1 > start_f and start_1 < stop_f:\n",
    "            overlap = (min(stop_f, stop_1) - max(start_f, start_1)) / (stop_1 - start_1)\n",
    "            output_values.append((feature_info, overlap))\n",
    "    return output_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "29e3a39e-20fe-406c-bd60-2f004cc1568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "homolog_hits = []\n",
    "with open(output_dir + '/' + locus_id + '/hsummary_0.txt', 'r') as f:  \n",
    "    for l in f:\n",
    "        if (not ('#' in l)):\n",
    "            a = l.split()\n",
    "            accession = a[0]\n",
    "            species = names_dict[a[0]]\n",
    "            seq_from = int(a[6])\n",
    "            seq_to = int(a[7])\n",
    "            if a[11] == '+':\n",
    "                strand = 1\n",
    "            else:\n",
    "                strand = -1\n",
    "            e_value = float(a[12])\n",
    "            start = min(seq_from,seq_to) - 1\n",
    "            stop = max(seq_from, seq_to)\n",
    "            if e_value < 1e-10:\n",
    "                for feature in (find_features(accession, start, stop)):\n",
    "                    if feature[1] > 0.9 and not (feature[0][0][-2:] == 'IG'):\n",
    "                        homolog_hits.append((accession, filename_dict[accession], start, stop, strand, e_value))\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3c3e402c-51d8-4c8a-883a-e64833e9e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_upstream_search_regions(num_subsets, subset_num, data_list):\n",
    "    data_subset = util.chunk_list(data_list, num_subsets, subset_num)\n",
    "    temp = []\n",
    "    for (accession, filename, start, stop, strand, e_value) in (data_subset):\n",
    "        for genome_record in SeqIO.parse(seq_dir + '/' + filename, \"genbank\"):\n",
    "            full_sequence = str(genome_record.seq)\n",
    "            if strand == 1:\n",
    "                upstream_sequence = full_sequence[max(0, start - 1000): start]\n",
    "            else:\n",
    "                upstream_sequence = util.reverse_complement(full_sequence[stop: (stop+1000)])\n",
    "            temp.append((accession, upstream_sequence))\n",
    "    return temp\n",
    "parallel_output = Parallel(n_jobs=-1)(delayed(create_upstream_search_regions)(num_cores, core_number, homolog_hits) for core_number in core_numbers)\n",
    "temp = [item for sublist in parallel_output for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba1e2137-9cdf-4f2d-8b88-e7a79b6b3f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [00:00<00:00, 47143.83it/s]\n"
     ]
    }
   ],
   "source": [
    "util.produce_fasta_file(temp, output_dir + '/upstream_regions.faa')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "865c3f3b-6483-4032-b796-e3d1ce0d7798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NC_000962.3 GCF_000195955.2_ASM19595v2_genomic.gbff 850740 851466 -1 4.6e-210\n",
      "GCCACCAGGATCAGCGTGGCTGCGACCAGGCGTACCCGTAGGGGCAGCCTTCCTCGAAGGTGTCTGGCCATTGCCGCGTTCTCCTCGGGCTGCCGATCCGATTAACTACCAAGACTCATCGAGGCTCCCGCAGTACGTAGCCCACCCCGCGCAGCGTGTGCAGCAGCCGCTTCTCCCCAGTGTCGATCTTGCGGCGCAGATACGACACGTAGGACTCGACGACGTTGACATCACCACCGAAGTCGTAGCGCCAAACGTGGTCGAGAATCTTAGGCTTGCTCAGCACGGTGCCCGCGTTGATCACGAAATAGCGCAGCAGGGTGAATTCGGTGGGCGACAGCGACACCGGTTGGCCCGCCTTCCACACTTCGTGGGTCTCCTCGTCGAGCTCGATATCGGCGAACGTCAGTCGAACATTACGTGGTTCCTTGTTGCCCTTGCCCGCGCGTCGCAGGATGACCCGCAGCCTGGCCACGACCTCCTCCAAACTGAAGGGCTTTGTCACATAGTCGTCACCACCCAGGGTCAGACCCGCGATCTTGTCCTGTAGCGAGTCACGGGCCGTCAGGAACAACGCCGGGGCATCGATGCCGTCGGCGCGCAGCCGGCGCAGCACCCCAAAGCCGTCCATCCCGGGCATCATCACATCGAGGATCACCGCGTCCGGCCGGGTTTCCCGGGCCCGATCCAGCGCCTGTGCCCCGTTGGTCGCGGTGTAGACTTCAAAGCCCTGGAACTTGAGGCTCACCGACAGCAGTTCAACGATGTTGGCCTCATCATCGACCACGAGGACACGAGCCTCCGGTGTGGTGTTTTCGCCTGGGGTTCCCGCCGTCACGAGATCAACCCCTTTCCGCATTGGTTGAACGTTACCTTCACAGTCATTGTGTAATTCCTGAAAGCTCGTTGCCAGTAGTCTGCTAACAGTCTGCCAGGAATCGCCAAATCAGCTTGGACCGTTGCCGCTCAATCCACGGCGCGCCGTGAATACACTCGCAGA\n"
     ]
    }
   ],
   "source": [
    "for (accession, filename, start, stop, strand, e_value) in homolog_hits:\n",
    "        for genome_record in SeqIO.parse(seq_dir + '/' + filename, \"genbank\"):\n",
    "            full_sequence = str(genome_record.seq)\n",
    "            print(accession, filename, start, stop, strand, e_value)\n",
    "            if strand == 1:\n",
    "                upstream_sequence = full_sequence[max(0, start - 1000): start]\n",
    "            else:\n",
    "                upstream_sequence = util.reverse_complement(full_sequence[stop: (stop+1000)])\n",
    "            print(upstream_sequence)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d7027fef-50c1-446d-b25c-4fe256371c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rv0757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "hmmer_eval =  1e-10\n",
    "hmmer_eval_2 = 1e-5\n",
    "infernal_eval = 1e-5\n",
    "query_file = 'intergenic_region.faa'\n",
    "hm_model_file = 'hmm.hmm'\n",
    "cm_model_file = 'cm.cm'\n",
    "for i, r in intergenic_test.iterrows():\n",
    "    if r['Length'] >= 0:\n",
    "        sequence_list = [[r['Locus'], r['Sequence']]]\n",
    "        locus_id = r['Locus']\n",
    "        print(locus_id)\n",
    "        results_dir = output_dir + '/' + locus_id + '_IG'\n",
    "        if not os.path.exists(results_dir):\n",
    "            os.makedirs(results_dir)\n",
    "        util.produce_fasta_file(sequence_list, results_dir + '/' + query_file)\n",
    "\n",
    "        blastfn.nhmmer_search_sequence(results_dir, query_file, output_dir, 'upstream_regions.faa', 'align_0.sto', 'output.txt', 'hsummary.txt', hmmer_eval) \n",
    "        if not os.path.exists(results_dir +'/hsummary.txt'):\n",
    "            continue\n",
    "        blastfn.align_keep_top_hit_per_species(results_dir, 'hsummary.txt', 'align_0.sto', 'align_bh_0.sto', 'HMMER', hmmer_eval)\n",
    "        for i in range(4):\n",
    "            blastfn.hmmer_build(results_dir, 'align_bh_'+str(i)+'.sto' ,hm_model_file)\n",
    "            blastfn.nhmmer_search_model(results_dir, hm_model_file, output_dir, 'upstream_regions.faa', 'align_'+str(i+1)+'.sto', 'output.txt', 'hsummary_'+str(i+1)+'.txt', hmmer_eval_2)      #seq_dir, 'full_sequences.faa'\n",
    "            blastfn.align_keep_top_hit_per_species(results_dir, 'hsummary_'+str(i+1)+'.txt', 'align_'+str(i+1)+'.sto', 'align_bh_'+str(i+1)+'.sto', 'HMMER', hmmer_eval_2)\n",
    "\n",
    "\n",
    "        blastfn.infernal_build_and_calib(results_dir, 'align_bh_4.sto' ,'cm_1.cm', False)\n",
    "        blastfn.infernal_search(results_dir, 'cm_1.cm', output_dir, 'upstream_regions.faa', 'search_1.sto', 'search_hits_1.txt', 'summary_1.txt', infernal_eval) \n",
    "        if os.path.getsize(results_dir + '/search_hits_1.txt') > 1e7:\n",
    "            continue\n",
    "        blastfn.align_keep_top_hit_per_species(results_dir, 'summary_1.txt', 'search_1.sto', 'search_bh_1.sto', 'INFERNAL', infernal_eval)\n",
    "        blastfn.run_rscape(results_dir, 'search_bh_1.sto', 'rscape_1')\n",
    "\n",
    "        #2\n",
    "        blastfn.infernal_build_and_calib(results_dir, 'rscape_1.cacofold.R2R.sto' ,'cm_2.cm')\n",
    "        blastfn.infernal_search(results_dir, 'cm_2.cm', output_dir, 'upstream_regions.faa', 'search_2.sto', 'search_hits_2.txt', 'summary_2.txt', infernal_eval) \n",
    "        if os.path.getsize(results_dir + '/search_hits_2.txt') > 1e7:\n",
    "            continue\n",
    "        blastfn.align_keep_top_hit_per_species(results_dir, 'summary_2.txt', 'search_2.sto', 'search_bh_2.sto', 'INFERNAL', infernal_eval)\n",
    "        blastfn.run_rscape(results_dir, 'search_bh_2.sto', 'rscape_2')\n",
    "\n",
    "       #3\n",
    "        #'search_bh_2.sto'\n",
    "        blastfn.infernal_build_and_calib(results_dir, 'rscape_2.cacofold.R2R.sto' ,'cm_3.cm')\n",
    "        blastfn.infernal_search(results_dir, 'cm_3.cm', output_dir, 'upstream_regions.faa', 'search_3.sto', 'search_hits_3.txt', 'summary_3.txt', infernal_eval) \n",
    "        if os.path.getsize(results_dir + '/search_hits_3.txt') > 1e7:\n",
    "            continue\n",
    "        blastfn.align_keep_top_hit_per_species(results_dir, 'summary_3.txt', 'search_3.sto', 'search_bh_3.sto', 'INFERNAL', infernal_eval)\n",
    "        blastfn.run_rscape(results_dir, 'search_3.sto', 'rscape_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "322f6b64-c06c-423c-bf5b-6c3dd193d2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "a = util.list_dirs(project_dir + '/R_Scape_Results_RFAM')\n",
    "print(len(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5ec9b5d-c6fc-4d41-b15d-bb5b30962552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c8b22a4-dc61-404c-a8ee-45c2a1326a05",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (Temp/ipykernel_7196/2662094211.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\nicho\\AppData\\Local\\Temp/ipykernel_7196/2662094211.py\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    print(id, combined_e_value)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "seq_ids = util.list_dirs(project_dir + '/R_Scape_Results_RFAM')\n",
    "for id in seq_id:\n",
    "    if os.path.exists(project_dir + '/R_Scape_Results_RFAM' + '/' + str(seq_id) + '/rscape_1.cov'):\n",
    "        with open(project_dir + '/R_Scape_Results_RFAM' + '/' + str(seq_id) + '/rscape_1.cov', 'r') as f:  \n",
    "            e_values = []\n",
    "            for l in f:\n",
    "                if (not ('#' in l)):\n",
    "                    a = l.split()\n",
    "                    e_values.append(float(a[4]))\n",
    "        if len(e_values) > 0:\n",
    "            tot = sum([math.log(x) for x  in e_values])\n",
    "            num = len(e_values)\n",
    "            combined_e_value = 1-chi2.cdf(-2*tot, 2*num)\n",
    "        else:\n",
    "            combined_e_value = 999\n",
    "        print(id, combined_e_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73bec41c-0a49-4ba5-8c78-1537071ab88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.091874917731218e-08"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [6.5e-7, 0.0053, 0.0204]\n",
    "tot = sum([math.log(x) for x  in data])\n",
    "num = len(data)\n",
    "from scipy.stats import chi2\n",
    "1-chi2.cdf(-2*tot, 2*num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326874cc-c8ea-4729-9a08-b84f55201c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
