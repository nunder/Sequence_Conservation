{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50da8fa4-e4d1-4e99-9df9-f2593cc0c057",
   "metadata": {},
   "source": [
    "##### Import modules and set up file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9417e01-aa2a-4297-8948-c0c526434b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_run = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "694b2495-3118-4d6a-9934-5f46d80dfa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\ete3-3.1.2-py3.7.egg\\ete3\\evol\\parser\\codemlparser.py:221: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\ete3-3.1.2-py3.7.egg\\ete3\\evol\\parser\\codemlparser.py:221: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    }
   ],
   "source": [
    "from Comparative_Analysis import Sequence_Analysis_Routines as sar\n",
    "from Comparative_Analysis import HMM as hmm\n",
    "from Comparative_Analysis import Utilities as util\n",
    "from Comparative_Analysis import Alignment_HMM as alignment_hmm\n",
    "from Comparative_Analysis import Alignment_Analysis as alignment_analysis\n",
    "from Comparative_Analysis import Alignment as align\n",
    "from Comparative_Analysis import Master_Alignment_HMM as master_alignment_hmm\n",
    "from Comparative_Analysis import Multi_Species_Master_Alignment_HMM as multi_species_master_alignment_hmm\n",
    "from Comparative_Analysis import Arneson_Ernst_HMM as ae_hmm\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from scipy import optimize as opt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import logomaker as lm\n",
    "import math\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import ete3;\n",
    "import pickle\n",
    "import copy\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "773a1d9c-8b02-447d-8b4c-41e9d5d24f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'D:/Project_Data/Project_6'\n",
    "genome_datasets_dir = project_dir + '/Datasets/NCBI_Datasets'\n",
    "literature_datasets_dir = project_dir + '/Datasets/Data_From_Publications'\n",
    "output_dir = project_dir + '/Output'\n",
    "protein_fasta_output_loc = output_dir + '/Protein_Sequences'\n",
    "outgroup_protein_fasta_output_loc = output_dir + '/Protein_Sequences_With_Outgroup'\n",
    "sonic_paranoid_run_name = 'Run_Without_Outgroup'\n",
    "outgroup_sonic_paranoid_run_name = 'Run_With_Outgroup'\n",
    "sonic_paranoid_output_loc = output_dir + '/Sonic_Paranoid_Output'\n",
    "ortholog_dir = sonic_paranoid_output_loc + '/runs/' + sonic_paranoid_run_name + '/ortholog_groups'\n",
    "outgroup_ortholog_dir = sonic_paranoid_output_loc + '/runs/' + outgroup_sonic_paranoid_run_name + '/ortholog_groups'\n",
    "non_cds_output_dir = output_dir + '/Multiple_Alignment_Data/Downstream_Non_CDS'\n",
    "upstream_non_cds_output_dir = output_dir + '/Multiple_Alignment_Data/Upstream_Non_CDS'\n",
    "cds_output_dir = output_dir + '/Multiple_Alignment_Data/CDS'\n",
    "extended_cds_output_dir = output_dir + '/Multiple_Alignment_Data/Extended_CDS'\n",
    "extended_non_cds_regions_output_dir = output_dir + '/Multiple_Alignment_Data/Extended_Non_CDS'\n",
    "outgroup_cds_output_dir = output_dir + '/Multiple_Alignment_Data/CDS_With_Outgroup'\n",
    "outgroup_concatenated_cds_output_dir = output_dir + '/Multiple_Alignment_Data/CDS_With_Outgroup_Concatenated'\n",
    "hmm_parameters_output_dir = output_dir +'/HMM_Model_Parameters'\n",
    "conservation_analysis_output_dir = output_dir + '/Conservation_Analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56139988-efa1-4bb1-9cd3-4cdd90020453",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = 16\n",
    "core_numbers = list(range(1, num_cores+1))\n",
    "tb_species = 'GCF_000195955.2'\n",
    "outgroup_species = 'GCF_000696675.2'\n",
    "non_cds_offset = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf829bb3-e529-4170-ad7b-9d885d57f851",
   "metadata": {},
   "source": [
    "##### Determine genomes in ortholog family, generate protein files and run Sonic Paranoid (both with and without outgroup - outgroup needed for tree building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df7a7627-bb45-4679-97ef-ed8f209447fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_ids_with_outgroup = util.list_dirs(genome_datasets_dir)\n",
    "genome_ids = util.list_dirs(genome_datasets_dir)\n",
    "genome_ids.remove(outgroup_species)\n",
    "non_target_genome_ids = util.list_dirs(genome_datasets_dir)\n",
    "non_target_genome_ids.remove(outgroup_species)\n",
    "non_target_genome_ids.remove(tb_species)\n",
    "num_ids = len(genome_ids)\n",
    "num_ids_with_outgroup = len(genome_ids_with_outgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be93725-4667-49ca-b2bc-430c0c7e9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    for folder in sar.tqdm(genome_ids):\n",
    "        sar.generate_protein_file(genome_datasets_dir + '/' + folder + '/genomic.gbff', protein_fasta_output_loc + '/' + folder + '.faa')\n",
    "    for folder in sar.tqdm(genome_ids_with_outgroup):\n",
    "        sar.generate_protein_file(genome_datasets_dir + '/' + folder + '/genomic.gbff', outgroup_protein_fasta_output_loc + '/' + folder + '.faa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828d159-34d6-4f7e-878c-e31b598573a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    sar.run_sonic_paranoid(protein_fasta_output_loc, sonic_paranoid_output_loc, sonic_paranoid_run_name)\n",
    "    sar.run_sonic_paranoid(outgroup_protein_fasta_output_loc, sonic_paranoid_output_loc, outgroup_sonic_paranoid_run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39369771-8cd9-4438-89a5-d426702ac448",
   "metadata": {},
   "source": [
    "##### Generate objects containing orthologs and sequence information for each ortholog group / species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051a50d7-e6dc-42a7-9675-e58d8ae157b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75075/75075 [00:03<00:00, 23123.21it/s]\n",
      "100%|██████████| 84312/84312 [00:03<00:00, 23730.84it/s]\n"
     ]
    }
   ],
   "source": [
    "orthologs = sar.Ortholog_Grouping(ortholog_dir)\n",
    "outgroup_orthologs = sar.Ortholog_Grouping(outgroup_ortholog_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e9977fb-f334-4f33-a820-535d87f4105a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 94.35it/s]\n",
      "100%|██████████| 16/16 [00:00<?, ?it/s]\n",
      "100%|██████████| 16/16 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "seq_data = sar.Ortholog_Sequence_Dataset(orthologs, genome_datasets_dir, genome_ids, non_cds_offset, tb_species) \n",
    "outgroup_seq_data = sar.Ortholog_Sequence_Dataset(outgroup_orthologs, genome_datasets_dir, genome_ids_with_outgroup, non_cds_offset, tb_species) \n",
    "all_copy_seq_data = sar.Ortholog_Sequence_Dataset(orthologs, genome_datasets_dir, genome_ids, non_cds_offset, tb_species, single_copy = False) \n",
    "#print(outgroup_seq_data.species_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6d5c8c-fdd4-459f-ad82-b74bb46e0ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq_data.generate_synteny_plot()\n",
    "#seq_data.generate_ortholog_count_plot()\n",
    "#all_copy_seq_data.generate_master_count_plot()\n",
    "seq_data.generate_unassigned_gene_count_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e3b630-5c42-499e-8389-5532f4dca58c",
   "metadata": {},
   "source": [
    "##### Perform CDS and extended CDS (including intergenic regions) alignments for each full ortholog group and save to folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb33f80-a608-425f-bf01-6a0fe7a77226",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_species = num_ids\n",
    "min_species_with_outgroup = num_ids_with_outgroup\n",
    "groups = random.sample(orthologs.full_single_copy_ortholog_groups, len(orthologs.full_single_copy_ortholog_groups))  #Permutation ensures even distribution of processing speeds\n",
    "outgroup_groups = random.sample(outgroup_orthologs.full_single_copy_ortholog_groups, len(outgroup_orthologs.full_single_copy_ortholog_groups))  #Permutation ensures even distribution of processing speeds\n",
    "if full_run == True:\n",
    "    #par = Parallel(n_jobs=-1)(delayed(align.align_and_build)(outgroup_groups, num_cores, core_number, outgroup_seq_data.sequence_data, 'cds_length', 'cds_seq', outgroup_cds_output_dir+'/', min_species_with_outgroup) for core_number in tqdm(core_numbers))\n",
    "    #par = Parallel(n_jobs=-1)(delayed(align.align_and_build)(groups, num_cores, core_number, seq_data.sequence_data, 'cds_length', 'cds_seq', cds_output_dir+'/', min_species) for core_number in tqdm(core_numbers))\n",
    "    #par = Parallel(n_jobs=-1)(delayed(align.align_and_build)(groups, num_cores, core_number, seq_data.sequence_data, 'cds_extended_region_length', 'cds_extended_region_seq', extended_cds_output_dir+'/', min_species) for core_number in tqdm(core_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0e38ce-4872-4cce-ae48-441f7653e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_region_ids = util.list_files(extended_cds_output_dir+'/')\n",
    "e_ids = [int(i.split('.')[0]) for i in extended_region_ids]\n",
    "for group_id in tqdm(e_ids):      \n",
    "    align.extract_non_cds_regions_from_alignment(seq_data.sequence_data, tb_species, 1250, extended_cds_output_dir, extended_non_cds_regions_output_dir, group_id, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c537a867-2e88-4080-a888-9a4f16fb9e81",
   "metadata": {},
   "source": [
    "##### Run IQTree on concatenated CDS alignments to generate tree and rename with full names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42928a48-444f-4b46-a8eb-d668dd4565e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    alignment_names = util.list_files(outgroup_cds_output_dir)\n",
    "    util.concatenate_fasta(outgroup_cds_output_dir, alignment_names, outgroup_concatenated_cds_output_dir + '/concatenated_cds.fasta')\n",
    "    subprocess.run('cd \\\\users\\\\nicho\\\\IQTree & bin\\\\iqtree2 -s ' + outgroup_concatenated_cds_output_dir + '/concatenated_cds.fasta' + ' --prefix '+ output_dir + \n",
    "                   '/Trees/Concatenated_JC_Tree -m JC -B 1000 -T AUTO -o ' + outgroup_species, shell=True)\n",
    "    master_tree = ete3.Tree(output_dir + '/Trees/Concatenated_JC_Tree.treefile')\n",
    "    for node in master_tree.traverse():\n",
    "        if node.is_leaf():\n",
    "            node.name = outgroup_seq_data.organism_dict[node.name] \n",
    "    master_tree.write(format=0, outfile= output_dir + '/Trees/Concatenated_JC_Tree_Full_Names.treefile')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a16ea0b-011d-45b8-9716-609647baa411",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_tree = ete3.Tree(output_dir + '/Trees/Concatenated_JC_Tree.treefile')\n",
    "phylogenetic_distance_dict = {}\n",
    "for gid in non_target_genome_ids:\n",
    "    phylogenetic_distance_dict[gid] = master_tree.get_distance(gid, tb_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40396ae4-b80d-4ebd-ab66-e40e6712c758",
   "metadata": {},
   "source": [
    "##### Fit overall Alignment and Pairwise HMMs using EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e885b08-1828-4633-9c60-4eeaab22efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_symbols = 4\n",
    "num_states = 3\n",
    "minimum_fit_length = 10\n",
    "initial_params = [0.95, 0.5, 0.95, 0.5, 0.95, 0.5, 0.56370018, 0.52131172, 0.33906948]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0dd043-8444-462b-b3af-0b689425dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    Alignment_HMM_Model = alignment_hmm.Alignment_HMM (num_symbols, num_states, extended_non_cds_regions_output_dir, tb_species, species_order = genome_ids)\n",
    "    parameter_fits = Alignment_HMM_Model.EM_update(num_cores, initial_params, minimum_fit_length)\n",
    "    fitted_parameters = parameter_fits[3]\n",
    "    with open(hmm_parameters_output_dir + '/' + 'full_parameter_fit.pkl', 'wb') as f:\n",
    "        pickle.dump(fitted_parameters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1b4b3-11cc-4e5a-aea4-3d29f0810066",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    parameter_fits = []\n",
    "    for id in non_target_genome_ids:\n",
    "        parameter_fits.append((id, Alignment_HMM_Model.EM_update(num_cores, initial_params, minimum_fit_length, all_species = False, comparison_species = id)[3]))\n",
    "    with open(hmm_parameters_output_dir + '/' + 'pairwise_parameter_fits.pkl', 'wb') as f:\n",
    "        pickle.dump(parameter_fits, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75965597-303a-442b-9c61-2f2d1420e1b0",
   "metadata": {},
   "source": [
    "##### Fit overall HMM to pairwise HMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55473b24-e661-4d7f-a9df-e4a485723fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_generate_pairwise_state_probabilities(num_subsets, subset_num, ids, num_states, pairwise_fitted_parameters):\n",
    "    ids = util.chunk_list(ids, num_subsets, subset_num)\n",
    "    pairwise_observation_probabilities = []\n",
    "    for group_id in ids:\n",
    "        temp = []\n",
    "        alignment = align.Alignment(extended_non_cds_regions_output_dir +'/'+str(group_id)+'.fasta', tb_species, 'NT', species_order = genome_ids)\n",
    "        alignment.modify_sequence(1,False,False)\n",
    "        for params in pairwise_fitted_parameters:\n",
    "                transition_probabilities, mutation_probabilities = Alignment_HMM_Model.alignment_hmm_model_inputs(params[1])\n",
    "                observation_probabilities = Alignment_HMM_Model.calculate_observation_probs(mutation_probabilities, alignment.modified_sequence_list, alignment, all_species=False, comparison_species = params[0])\n",
    "                initial_state_probabilities = [1.0/num_states]*num_states\n",
    "                hmm_model = hmm.HMM(initial_state_probabilities, transition_probabilities, observation_probabilities)\n",
    "                hmm_model.calculate_probabilities()\n",
    "                temp.append(hmm_model.state_probabilities)\n",
    "        pairwise_observation_probabilities.append(temp) \n",
    "    return pairwise_observation_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce5182ac-6442-40fc-9286-c32fcb173955",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/Project_Data/Project_6/Output/Multiple_Alignment_Data/Extended_Non_CDS/10000.fasta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\nicho\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\nicho\\AppData\\Local\\Temp/ipykernel_17092/2696686650.py\", line 6, in parallel_generate_pairwise_state_probabilities\n  File \"C:\\Users\\nicho\\Documents\\GitHub\\Sequence_Conservation\\Comparative_Analysis\\Alignment.py\", line 177, in __init__\n    temp = util.read_fasta_to_array(fileloc, species_order)\n  File \"C:\\Users\\nicho\\Documents\\GitHub\\Sequence_Conservation\\Comparative_Analysis\\Utilities.py\", line 136, in read_fasta_to_array\n    with open(filename,'r') as ofile:\nFileNotFoundError: [Errno 2] No such file or directory: 'D:/Project_Data/Project_6/Output/Multiple_Alignment_Data/Extended_Non_CDS/10000.fasta'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17092/1077952466.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfile_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextended_non_cds_regions_output_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mparallel_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparallel_generate_pairwise_state_probabilities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcore_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairwise_fitted_parameters\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcore_number\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcore_numbers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mpairwise_observation_probabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparallel_output\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhmm_parameters_output_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'pairwise_observation_probabilities.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Bioinformatics\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Bioinformatics\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Bioinformatics\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[1;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/Project_Data/Project_6/Output/Multiple_Alignment_Data/Extended_Non_CDS/10000.fasta'"
     ]
    }
   ],
   "source": [
    "if full_run == True:\n",
    "    with open(hmm_parameters_output_dir + '/' + 'pairwise_parameter_fits.pkl', 'rb') as f:\n",
    "        pairwise_fitted_parameters = pickle.load(f)\n",
    "    file_ids = util.list_files(extended_non_cds_regions_output_dir + '/')\n",
    "    ids = [(i.split('.')[0]) for i in file_ids] \n",
    "    parallel_output = Parallel(n_jobs=-1)(delayed(parallel_generate_pairwise_state_probabilities)(num_cores, core_number, ids, num_states, pairwise_fitted_parameters) for core_number in core_numbers)\n",
    "    pairwise_observation_probabilities = [item for sublist in parallel_output for item in sublist]\n",
    "    with open(hmm_parameters_output_dir + '/' + 'pairwise_observation_probabilities.pkl', 'wb') as f:\n",
    "        pickle.dump(pairwise_observation_probabilities, f)\n",
    "else:\n",
    "    with open(hmm_parameters_output_dir + '/' + 'pairwise_observation_probabilities.pkl', 'rb') as f:\n",
    "        pairwise_observation_probabilities = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c503c-dec6-4473-aa3b-38b41ed2b3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    Master_Alignment_HMM_Model = master_alignment_hmm.Master_Alignment_HMM (pairwise_observation_probabilities)\n",
    "    initial_params = [0.8, 0.5, 0.9, 0.3]\n",
    "    parameter_fits = Master_Alignment_HMM_Model.EM_update(num_cores, initial_params, minimum_fit_length)\n",
    "    fitted_parameters = parameter_fits[3]\n",
    "    print(fitted_parameters)\n",
    "    with open(hmm_parameters_output_dir + '/' + 'master_parameter_fit.pkl', 'wb') as f:\n",
    "        pickle.dump(fitted_parameters, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7ee55c-6761-4018-a55e-5f010e7ff587",
   "metadata": {},
   "source": [
    "#####  Fit overall species specific HMM to pairwise HMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bbb69f-fcbd-49f9-b352-459ab22e3038",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    num_comparison_species = len(pairwise_observation_probabilities[0])\n",
    "    Multi_Species_Master_Alignment_HMM_Model = multi_species_master_alignment_hmm.Multi_Species_Master_Alignment_HMM (pairwise_observation_probabilities)\n",
    "    initial_params = [0.8, 0.5, [0.9]*num_comparison_species, [0.3]*num_comparison_species]\n",
    "    parameter_fits = Multi_Species_Master_Alignment_HMM_Model.EM_update(num_cores, initial_params, minimum_fit_length)\n",
    "    #print(parameter_fits)\n",
    "    fitted_parameters = parameter_fits[3]\n",
    "    print(fitted_parameters)\n",
    "    with open(hmm_parameters_output_dir + '/' + 'multi_species_master_parameter_fit.pkl', 'wb') as f:\n",
    "        pickle.dump(fitted_parameters, f)\n",
    "    species_conservation_parameter_dict = {}    # Used to plot against phylogenetic distance below\n",
    "    for i, gid in enumerate(non_target_genome_ids):\n",
    "        species_conservation_parameter_dict[gid] = parameter_fits[1][0][i]\n",
    "    with open(hmm_parameters_output_dir + '/' + 'multi_species_conservation_parameter_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(species_conservation_parameter_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d25ad-5053-4d86-a9d4-c6f8ba51527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hmm_parameters_output_dir + '/' + 'multi_species_conservation_parameter_dict.pkl', 'rb') as f:\n",
    "    species_conservation_parameter_dict = pickle.load(f)\n",
    "species_name_labels = []\n",
    "log_conservation = []\n",
    "phylo_distance = []\n",
    "for gid in non_target_genome_ids:\n",
    "    species_name_labels.append(gid)\n",
    "    log_conservation.append(-1*math.log(species_conservation_parameter_dict[gid]))\n",
    "    phylo_distance.append(phylogenetic_distance_dict[gid])\n",
    "conservations_df = pd.DataFrame(\n",
    "    {'Species': species_name_labels,\n",
    "     '-Log conservation probability': log_conservation,\n",
    "     'Phylogenetic distance': phylo_distance\n",
    "    })\n",
    "ax = sns.scatterplot(data = conservations_df, x = 'Phylogenetic distance', y = '-Log conservation probability', s= 20, hue = 'Species')\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='6') # for legend text\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='8') # for legend title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016fb960-7994-4247-9feb-154d3609cb65",
   "metadata": {},
   "source": [
    "#####  Fit Arneson Ernst HMM to alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01765f1a-dd3f-4c71-a43d-ad67363c5cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = 3\n",
    "num_symbols = 4\n",
    "minimum_fit_length = 10\n",
    "initial_mutation_probs = np.random.rand(num_states,num_ids,3)\n",
    "for i in range(num_states):\n",
    "    for j in range(num_ids):\n",
    "        tot = 0\n",
    "        for k in range(3):\n",
    "            tot += initial_mutation_probs[i, j, k]\n",
    "        for k in range(3):\n",
    "            initial_mutation_probs[i, j, k] = initial_mutation_probs[i, j, k] / tot\n",
    "#print(initial_mutation_probs)\n",
    "initial_params = [0.95, 0.5, 0.95, 0.5, 0.95, 0.5, initial_mutation_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ba083-9720-4fb3-81a6-49c308b87398",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_run == True:\n",
    "    AE_HMM_Model = ae_hmm.Alignment_HMM (num_symbols, num_states, extended_non_cds_regions_output_dir, tb_species, species_order = genome_ids)\n",
    "    parameter_fits = AE_HMM_Model.EM_update(num_cores, initial_params, minimum_fit_length)\n",
    "    print(parameter_fits)\n",
    "    fitted_parameters = parameter_fits[3]\n",
    "    with open(hmm_parameters_output_dir + '/' + 'AE_parameter_fit.pkl', 'wb') as f:\n",
    "        pickle.dump(fitted_parameters, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3669c845-286e-4aa1-97e4-8a2dee230519",
   "metadata": {},
   "source": [
    "##### Load HMM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea7f2a-cd8b-4d52-bf7b-f3b8bde0536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hmm_parameters_output_dir + '/' + 'full_parameter_fit.pkl', 'rb') as f:\n",
    "    full_fitted_parameters = pickle.load(f)\n",
    "with open(hmm_parameters_output_dir + '/' + 'pairwise_parameter_fits.pkl', 'rb') as f:\n",
    "    pairwise_fitted_parameters = pickle.load(f)\n",
    "with open(hmm_parameters_output_dir + '/' + 'master_parameter_fit.pkl', 'rb') as f:\n",
    "    master_fitted_parameters = pickle.load(f)\n",
    "with open(hmm_parameters_output_dir + '/' + 'multi_species_master_parameter_fit.pkl', 'rb') as f:\n",
    "    multi_species_master_fitted_parameters = pickle.load(f)\n",
    "with open(hmm_parameters_output_dir + '/' + 'AE_parameter_fit.pkl', 'rb') as f:\n",
    "    AE_fitted_parameters = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3d362-46c0-40e5-9ecc-dbd80525bcfa",
   "metadata": {},
   "source": [
    "##### Analyse ortholog groups for conservation and other features and output to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56c44ad-31d8-407f-88b1-591812aa7bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Alignment_HMM_Model = alignment_hmm.Alignment_HMM (4, 3, extended_non_cds_regions_output_dir, tb_species, species_order = genome_ids)\n",
    "Master_Alignment_HMM_Model = master_alignment_hmm.Master_Alignment_HMM (pairwise_observation_probabilities)\n",
    "Multi_Species_Master_Alignment_HMM_Model = multi_species_master_alignment_hmm.Multi_Species_Master_Alignment_HMM (pairwise_observation_probabilities)\n",
    "AE_HMM_Model = ae_hmm.Alignment_HMM (4, 3, non_cds_output_dir, tb_species, species_order = genome_ids)\n",
    "literature_annotations_df_list = [pd.read_excel(literature_datasets_dir+'/Mycobrowser_Release_4.xlsx'), pd.read_excel(literature_datasets_dir+'/DeJesus2013.xlsx')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153917ac-dd0e-444e-bbc8-c0f8f9792628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_build_analysis_dictionary(num_subsets, subset_num, ids, analysis_type, model_type):\n",
    "    ids = util.chunk_list(ids, num_subsets, subset_num)\n",
    "    output_list = []\n",
    "    for group_id in ids:\n",
    "        alignment = align.Alignment(alignment_dir+'/'+str(group_id)+'.fasta', tb_species, 'NT')\n",
    "        if model_type == 'Simple':\n",
    "            analysis = alignment_analysis.Alignment_Analysis(analysis_type, alignment, seq_data, group_id, 3, pairwise_fitted_parameters, 'Simple', 2, \n",
    "                                           master_fitted_parameters, extended_non_cds_regions_output_dir, tb_species, genome_ids, pairwise_observation_probabilities, \n",
    "                                           Alignment_HMM_Model, Master_Alignment_HMM_Model, literature_annotations_df_list)\n",
    "        elif model_type == 'Multi_Species':\n",
    "            analysis = alignment_analysis.Alignment_Analysis(analysis_type, alignment, seq_data, group_id, 3, pairwise_fitted_parameters, 'Multi_Species', 2, \n",
    "                                           multi_species_master_fitted_parameters, extended_non_cds_regions_output_dir, tb_species, genome_ids, pairwise_observation_probabilities, \n",
    "                                           Alignment_HMM_Model, Multi_Species_Master_Alignment_HMM_Model, literature_annotations_df_list)\n",
    "        elif model_type == 'AE':\n",
    "            analysis = alignment_analysis.Alignment_Analysis(analysis_type, alignment, seq_data, group_id, 3, pairwise_fitted_parameters, 'AE', 3, \n",
    "                                           AE_fitted_parameters, extended_non_cds_regions_output_dir, tb_species, genome_ids, pairwise_observation_probabilities, \n",
    "                                           Alignment_HMM_Model, AE_HMM_Model, literature_annotations_df_list)\n",
    "        else:\n",
    "            pass\n",
    "        output_list.append((group_id, analysis))\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8f2946-1234-4fb8-acdd-e936b8995dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if full_run == True:\n",
    "if 1==1:\n",
    "    for model_type in ['Simple', 'Multi_Species', 'AE']:\n",
    "        analysis_type = 'Extended_CDS'\n",
    "        alignment_dir = extended_cds_output_dir\n",
    "        dict_name = model_type + '_' + 'extended_cds_conservation_info_dictionary'\n",
    "        alignment_info_dict = {}\n",
    "        file_ids = util.list_files(alignment_dir+'/')\n",
    "        ids = [int(i.split('.')[0]) for i in file_ids]\n",
    "        parallel_output = Parallel(n_jobs=-1)(delayed(parallel_build_analysis_dictionary)(num_cores, core_number, ids, analysis_type, model_type) for core_number in tqdm(core_numbers))\n",
    "        dictionary_list = [item for sublist in parallel_output for item in sublist]\n",
    "        alignment_info_dict = {}\n",
    "        for (group, analysis) in dictionary_list:\n",
    "            alignment_info_dict[seq_data.master_species_info(group, 'locus_tag')] = analysis\n",
    "        with open(conservation_analysis_output_dir + '/' + dict_name + '.pkl', 'wb') as f:\n",
    "            pickle.dump(alignment_info_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d6fe30-3c19-4261-8b29-fd1928a0a860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c3ee4c-3007-4088-9100-edc15dc26016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e776f28-0dd2-4ac4-9d46-da9433a0b0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
