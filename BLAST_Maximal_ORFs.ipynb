{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef24ce4-4729-44b6-8d43-fbdf47b9033a",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Set up packages and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9105f9b4-46be-44fd-b947-d3c47ce2fa01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fft import fft, fftfreq\n",
    "from Bio import Entrez, SeqIO, AlignIO, pairwise2, Align, Seq, motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from scipy.stats import binom\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "from Comparative_Analysis import Sequence_Analysis_Routines as sar\n",
    "from Comparative_Analysis import Utilities as util\n",
    "from Comparative_Analysis import Alignment as align\n",
    "import random\n",
    "import copy\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import subprocess\n",
    "from Bio.Blast import NCBIWWW, NCBIXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1988a242-f558-4643-b3a9-27272fa7bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'D:/Project_Data/Project_6'\n",
    "literature_datasets_dir = project_dir + '/Datasets/Data_From_Publications'\n",
    "output_dir = project_dir + '/Output'\n",
    "refseq_dir = 'D:/Tests/NCBI_Dataset_Mycobacteria'\n",
    "cryptic_output_path = \"D:/Project_Data/CRYPTIC_DATA/Cryptic_Data_Analysis\"\n",
    "num_cores = 16\n",
    "core_numbers = list(range(1, num_cores+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "abef54a8-1fd0-4a05-94de-bc9e2f647844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_list = util.list_dirs(refseq_dir)\n",
    "reference_species = 'GCF_000195955.2'\n",
    "species_list_excl_ref = [x for x in species_list if x!= reference_species]\n",
    "len(species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "73a6e9ec-f8a4-4724-a568-47d69682f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_nts = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f28e8-a111-4d47-a7d6-9fbe2e08e2d4",
   "metadata": {},
   "source": [
    "##### Translation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "94a2ed1e-1303-4248-9b29-728cce1b9485",
   "metadata": {},
   "outputs": [],
   "source": [
    "codon_dict = {}\n",
    "with open('D:/Project_Data/Project_3/Datasets/Reference_Tables/Standard_Code.txt') as f:\n",
    "    for l in f:\n",
    "        codon_dict[str(l[1:4])] = l[5]\n",
    "def translate_sequence(input_seq, strand, rf):\n",
    "    output_seq = ''\n",
    "    if strand == 1:\n",
    "        seq = input_seq[rf:]\n",
    "    else:\n",
    "        seq = align.reverse_complement(input_seq)[rf:]\n",
    "    for i in range(0,len(seq)-2,3):\n",
    "        if seq[i:(i+3)] in codon_dict:\n",
    "            output_seq += codon_dict[seq[i:(i+3)]]\n",
    "        else:\n",
    "            output_seq += 'X'\n",
    "    return output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6f975dff-4e95-44f1-978b-5c46eee3e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_orf(sequence, start, end, strand):\n",
    "    return translate_sequence(sequence[start:end], strand, 0)              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc300757-df8c-42d8-a7a0-352213a45d3f",
   "metadata": {},
   "source": [
    "##### Output nt sequences in FASTA format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ab243605-4807-411c-8195-401b1a404c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_blast_file(record_list, output_filename):\n",
    "    with open(output_filename, 'w',  newline='') as outfile:\n",
    "        line_length = 60\n",
    "        for record in tqdm(record_list):\n",
    "            sequence = record[1]\n",
    "            lines = []\n",
    "            sequence_length = len(sequence)\n",
    "            number_of_lines = math.ceil(sequence_length / line_length)\n",
    "            lines.append(\">\" +record[0]+ \"\\n\")\n",
    "            for i in range(number_of_lines):\n",
    "                subsequence = sequence[i*line_length:(i+1)*line_length]\n",
    "                lines.append(subsequence + \"\\n\")\n",
    "            outfile.write(''.join(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc97354-4eec-4741-b8b0-58b7be52aa9b",
   "metadata": {},
   "source": [
    "##### Function to find maximal open reading frame between two co-ordinates with mutation probability less than defined p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "23757841-ce5e-4eaa-9f83-c94f63b145a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_maximal_orfs(sequence, seq_start, seq_stop, output_all_orfs = False, min_orf_length = 0):\n",
    "    max_len = 0\n",
    "    orfs_found = []\n",
    "    start_pos = -999\n",
    "    end_pos = -999\n",
    "    for frame in ['Forward', 'Reverse']:\n",
    "        if frame == 'Forward':\n",
    "            temp = (sequence[seq_start: seq_stop])\n",
    "        else:\n",
    "            temp = align.reverse_complement(sequence[seq_start: seq_stop])\n",
    "        seq_len = len(temp)\n",
    "        for rf in range(3):\n",
    "            i = rf\n",
    "            while i < seq_len - 2:\n",
    "                orf_length = 0\n",
    "                test_codon = temp[i: i+3] \n",
    "                if test_codon in ['ATG','GTG','TTG']:  \n",
    "                    for j in range(i + 3, seq_len - 2, 3):\n",
    "                        test_codon_2 = temp[j: j+3] \n",
    "                        if test_codon_2 in ['TAG','TGA','TAA']:\n",
    "                            orf_length = j - i\n",
    "                            break\n",
    "                            \n",
    "                if orf_length > 0:\n",
    "                    if frame == 'Forward':\n",
    "                        orf_start =  seq_start + i\n",
    "                        orf_end = seq_start + j+3\n",
    "                        orf_strand = 1\n",
    "                    else:\n",
    "                        orf_start =  seq_start + seq_len-(j+3)\n",
    "                        orf_end = seq_start + seq_len-i\n",
    "                        orf_strand = -1\n",
    "                    \n",
    "                    if orf_length >= min_orf_length:\n",
    "                        orfs_found.append((orf_start, orf_end, orf_strand, orf_length))\n",
    "\n",
    "                if orf_length > max_len and orf_length >= min_orf_length:                                           \n",
    "                    max_len = orf_length\n",
    "                    start_pos = orf_start\n",
    "                    end_pos = orf_end\n",
    "                    strand = orf_strand \n",
    "\n",
    "                if orf_length > 0:\n",
    "                    i = j\n",
    "                else:\n",
    "                    i +=3\n",
    "    if output_all_orfs == True:\n",
    "        sorted_orfs = sorted(orfs_found, key=lambda x: x[3], reverse=True)\n",
    "        return sorted_orfs                \n",
    "    elif start_pos == -999:\n",
    "        return(0,0,0,0)\n",
    "    else:\n",
    "        return(start_pos, end_pos, strand, max_len)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d030d-93fc-42d5-9a5d-15c81d94f5a9",
   "metadata": {},
   "source": [
    "##### Function to find nearest upstream start to an alignment making it an open reading frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "50304da6-9a6a-4049-8652-9b2dd20cd51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_orf_sequence(sequence, seq_start, seq_stop, strand, max_lookback = 100):\n",
    "    out_seq = ''\n",
    "    if strand == 1:\n",
    "            temp = (sequence[seq_start - max_lookback * 3: seq_stop])\n",
    "    else:\n",
    "            temp = align.reverse_complement(sequence[seq_start: seq_stop + max_lookback * 3])\n",
    "    for lookback in range(max_lookback, -1, -1):\n",
    "        if temp[lookback * 3: (lookback+1) *3 ] in ['ATG','GTG','TTG']:\n",
    "            out_seq = translate_sequence(temp[lookback * 3:],1,0)\n",
    "            break\n",
    "    return(out_seq)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ef9e8-e455-4ec3-b342-29749e142d86",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Extract full sequences from each organism and create directory of start and stops for each annotated cds (use Mycobrowser for MTb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "565c760b-8f05-4aba-989f-e3400c233392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_myco_info(num_subsets, subset_num, species_master_list):\n",
    "    output = []\n",
    "    species_list = util.chunk_list(species_master_list, num_subsets, subset_num)\n",
    "    for i, species in tqdm(enumerate(species_list)):\n",
    "        features = []\n",
    "        genome_record = next(SeqIO.parse(refseq_dir + '/'+species+'/genomic.gbff', \"genbank\"))\n",
    "        full_sequence = str(genome_record.seq)\n",
    "        if full_sequence.count('A') + full_sequence.count('C') + full_sequence.count('G') + full_sequence.count('T') < len(full_sequence):\n",
    "            continue\n",
    "        organism = genome_record.annotations['organism']\n",
    "        \n",
    "        #  Read feature information\n",
    "        if species == reference_species:\n",
    "            mycobrowser_df = pd.read_excel(literature_datasets_dir+'/Mycobrowser_Release_4.xlsx')\n",
    "            for i, r in mycobrowser_df.iterrows():\n",
    "                if r['Strand'] == '+':\n",
    "                    strand = 1\n",
    "                else:\n",
    "                    strand = -1\n",
    "                features.append((r['Locus'],r['Start']-1, r['Stop'], strand))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            for feature in genome_record.features:\n",
    "                    a = feature.qualifiers\n",
    "                    if a.get(\"locus_tag\")!= None and int(feature.location.end) - int(feature.location.start) < 100000:  #  Exclude strange Biopython parsing where starts with complement join and looks like a CDS is full length of genome!    and feature.type == 'CDS':\n",
    "                        locus_tag = a.get(\"locus_tag\")[0]\n",
    "                        features.append([locus_tag, int(feature.location.start), int(feature.location.end), int(feature.location.strand)])\n",
    "        \n",
    "        #  Find maximal orfs, non-overlapping orfs and their protein sequences, and assign a reference to each\n",
    "        maximal_orfs = find_all_maximal_orfs(full_sequence, 0, len(full_sequence), True, min_nts)\n",
    "        \n",
    "        protein_references = []\n",
    "        maximal_orf_proteins = []\n",
    "        for i, orf in enumerate(maximal_orfs):\n",
    "            temp = translate_orf(full_sequence, orf[0], orf[1], orf[2])\n",
    "            maximal_orf_proteins.append([species+'_'+str(i), temp[:-1]])\n",
    "            protein_references.append((species+'_'+str(i), orf))\n",
    "\n",
    "        non_overlapping_maximal_orfs = []\n",
    "        for orf in maximal_orfs:\n",
    "            overlap = False\n",
    "            for cds in features:\n",
    "                if min(cds[2], orf[1]) - max(cds[1], orf[0]) > 0.3 * (orf[1] - orf[0]):\n",
    "                    overlap = True\n",
    "                    break\n",
    "            if overlap == False:\n",
    "                non_overlapping_maximal_orfs.append(orf)\n",
    "                \n",
    "        non_overlapping_maximal_orf_proteins = []\n",
    "        for i, orf in enumerate(non_overlapping_maximal_orfs):\n",
    "            temp = translate_orf(full_sequence, orf[0], orf[1], orf[2])\n",
    "            non_overlapping_maximal_orf_proteins.append([species+'_NO_'+str(i), temp[:-1]])\n",
    "            protein_references.append((species+'_NO_'+str(i), orf))\n",
    "        \n",
    "            \n",
    "        \n",
    "        output.append((species, organism, full_sequence, features, maximal_orfs, non_overlapping_maximal_orfs, maximal_orf_proteins, non_overlapping_maximal_orf_proteins, protein_references))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "97f4b284-aa63-4fff-b41d-fffd139c06ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "myco_info_dict = {}\n",
    "names_dict = {}\n",
    "parallel_output = Parallel(n_jobs=-1)(delayed(generate_myco_info)(num_cores, core_number, species_list) for core_number in core_numbers)\n",
    "for core_output in parallel_output:\n",
    "    for results in core_output:\n",
    "        myco_info_dict[results[0]] = (results[1], results[2], results[3], results[4], results[5], results[6], results[7], results[8])\n",
    "        names_dict[results[0]] = results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6a61b3df-8406-4065-8f4a-788d7afd236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_reference_dict = {}\n",
    "for species in species_list:\n",
    "    for ref in myco_info_dict[species][7]:\n",
    "        protein_reference_dict[ref[0]] = ref[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4046ad-c780-42ac-843e-375ce3d2e0aa",
   "metadata": {},
   "source": [
    "##### Output two blast files - one (subject) containing all translated mORFs, the other (query) just the ones for the reference species "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "66a5ad12-f3b7-4a08-ba72-1960f22779a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ae07a46e9140408205ab588539567d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5881544 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8bd2a38ccaa49f8a3e473410e5658d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4377 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05afeefbc2b48abb4669a820e4312cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59882 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subject_protein_list = []\n",
    "for species in species_list:\n",
    "    for maximal_orf_protein in myco_info_dict[species][5]:\n",
    "        subject_protein_list.append(maximal_orf_protein)\n",
    "produce_blast_file(subject_protein_list, refseq_dir + '/subject_proteins.faa')\n",
    "\n",
    "query_protein_list = myco_info_dict[reference_species][6]\n",
    "produce_blast_file(query_protein_list, refseq_dir + '/no_overlap_morf_query_proteins.faa')\n",
    "\n",
    "query_protein_list = myco_info_dict[reference_species][5]\n",
    "produce_blast_file(query_protein_list, refseq_dir + '/morf_query_proteins.faa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5fe6a4-dcf0-4b12-9257-c73f35691298",
   "metadata": {},
   "source": [
    "##### Create blast database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8b87b4ec-e4d2-4ffe-b758-eaff64002f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "    w_d = os.getcwd()\n",
    "    os.chdir(\"D:/\")\n",
    "    subprocess.run('cd d:\\\\Tests\\\\NCBI_Dataset_Mycobacteria & makeblastdb -in subject_proteins.faa -dbtype prot -out max_prot', shell=True, capture_output = True)\n",
    "    os.chdir(w_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "244d3567-db99-4a95-b433-9efbe359cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "    w_d = os.getcwd()\n",
    "    os.chdir(\"D:/\")\n",
    "    subprocess.run('cd d:\\\\BLAST\\\\maxprot & blastp -query d:\\\\Tests\\\\NCBI_Dataset_Mycobacteria\\\\morf_query_proteins.faa -db max_prot -out blastp_results2.csv -evalue 1e-6 -seg no -outfmt  \"10 qaccver saccver qlen slen pident length mismatch gapopen qstart qend sstart send sstrand evalue bitscore\" -num_threads 16', shell=True, capture_output = True)\n",
    "    os.chdir(w_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b4e84804-bbbe-4838-b85e-5743d0a0f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_results = pd.read_csv(\"D:\\\\BLAST\\\\maxprot\\\\blastp_results2.csv\", header = None)\n",
    "blast_results.columns = ['query_accession_ver', 'subject_accession_ver', 'query_length', 'subject_length', 'percent_identical_matches','alignment_length', 'number_mismatches', 'number_of_gap_openings', 'query_start_alignment', 'query_end_alignment', 'subject_start_alignment', 'subject_end_alignment', 'subject_strand', 'e_value', 'bit_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2c38f7b8-7ec4-417b-992b-1d6aaf67dcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_results = blast_results.query('subject_length == subject_end_alignment and query_length == query_end_alignment')\n",
    "blast_results['query_info']=  blast_results['query_accession_ver'].map(protein_reference_dict)\n",
    "blast_results['subject_info']=  blast_results['subject_accession_ver'].map(protein_reference_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c6b58be1-ea16-49bd-8b78-1c8eaf236e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in blast_results.iterrows():\n",
    "    blast_results.at[i, 'query_species'] = '_'.join(r.query_accession_ver.split('_')[0:2])\n",
    "    blast_results.at[i, 'subject_species'] = '_'.join(r.subject_accession_ver.split('_')[0:2])\n",
    "blast_results = blast_results.query('not (query_species == subject_species)')\n",
    "blast_results['query_species_name'] = blast_results['query_species'].map(names_dict)\n",
    "blast_results['subject_species_name'] = blast_results['subject_species'].map(names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "63063bfb-5940-452e-9e78-ce89df91f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in blast_results.iterrows():\n",
    "    if r.query_info[2] == 1:\n",
    "        blast_results.at[i, 'query_start_pos'] = r.query_info[0] + (r.query_start_alignment - 1) * 3\n",
    "        blast_results.at[i, 'query_end_pos'] = r.query_info[0] + (r.query_end_alignment - 1) * 3 + 6 # doesn't include stop codon in blast\n",
    "    else:\n",
    "        blast_results.at[i, 'query_start_pos'] = r.query_info[0] + (r.query_end_alignment - r.query_length) * 3\n",
    "        blast_results.at[i, 'query_end_pos'] = r.query_info[1] - (r.query_start_alignment - 1) * 3\n",
    "       \n",
    "    if r.subject_info[2] == 1:\n",
    "        blast_results.at[i, 'subject_start_pos'] = r.subject_info[0] + (r.subject_start_alignment - 1) * 3\n",
    "        blast_results.at[i, 'subject_end_pos'] = r.subject_info[0] + (r.subject_end_alignment - 1) * 3 + 6 # doesn't include stop codon in blast\n",
    "    else:\n",
    "        blast_results.at[i, 'subject_start_pos'] = r.subject_info[0] + (r.subject_end_alignment - r.subject_length) * 3\n",
    "        blast_results.at[i, 'subject_end_pos'] = r.subject_info[1] - (r.subject_start_alignment - 1) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4f4514c9-173e-43cf-9e44-e8f20e2897ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_results = blast_results.loc[blast_results.groupby(['query_accession_ver','subject_species'])['bit_score'].idxmax()]\n",
    "blast_results['species_count'] = blast_results.groupby('query_accession_ver')['query_accession_ver'].transform('size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "26cbac6e-330d-4190-8e37-05db34c696f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_results.to_csv(project_dir + '/blast_results_tb_maximal_orfs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e8c43269-31e9-48e0-94a5-219799e5039b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicho\\AppData\\Local\\Temp/ipykernel_16392/1169293613.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.at[i,'sequence'] = translate_orf(myco_info_dict[r.subject_species][1], int(r.subject_start_pos), int(r.subject_end_pos), subject_strand)\n",
      "C:\\Users\\nicho\\AppData\\Local\\Temp/ipykernel_16392/1169293613.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.at[i,'nearest_upstream_orf_sequence'] = find_nearest_orf_sequence(myco_info_dict[r.subject_species][1], int(r.subject_start_pos), int(r.subject_end_pos), subject_strand, max_lookback = 100)\n"
     ]
    }
   ],
   "source": [
    "df = blast_results[blast_results.species_count > 7]\n",
    "for i, r in df.iterrows():\n",
    "    subject_strand = r.subject_info[2]\n",
    "    df.at[i,'sequence'] = translate_orf(myco_info_dict[r.subject_species][1], int(r.subject_start_pos), int(r.subject_end_pos), subject_strand)\n",
    "    df.at[i,'nearest_upstream_orf_sequence'] = find_nearest_orf_sequence(myco_info_dict[r.subject_species][1], int(r.subject_start_pos), int(r.subject_end_pos), subject_strand, max_lookback = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ea471d0e-1da2-4d7b-988e-d36ba6842deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(project_dir + '/blast_results_maximal_orfs.high_hits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e4888-6e4f-450c-b297-4d74fecf3ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_blast_results = blast_results[blast_results.query_species == reference_species]\n",
    "plt.figure(figsize=(16, 16))\n",
    "g = sns.FacetGrid(tb_blast_results, col='subject_species', height=6, col_wrap=3)\n",
    "g.map(sns.scatterplot, 'subject_start_pos', 'query_start_pos', s=20)\n",
    "#sns.scatterplot(data = blast_results, y = 'subject_start_pos', x = 'query_start_pos', s=1, hue = 'annotated_cds_in_query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d58765-bfa5-4e97-b0d4-c386d9a02683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5aead327-4194-4c7c-a9d1-b99700ebe234",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Load variant dataset and create variant dictionary (0 indexed for genome position - whereas CRyPtiC data uses 1 start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7638b75f-0ae0-4f3c-a633-97c5be43cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_count_df = pd.read_csv(cryptic_output_path + '/filtered_variant_summary_df.csv')\n",
    "variant_count_df = variant_count_df[variant_count_df['MUTATION_PCT'] < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ffea312a-e6f6-4166-9b04-8b2a568f0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = variant_count_df.groupby(['GENOME_INDEX'])[['MYKROBE_LINEAGE_NAME_2']].count().reset_index()\n",
    "temp_dict = dict(zip(temp.GENOME_INDEX, temp.MYKROBE_LINEAGE_NAME_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "34bddba0-89fe-4532-ae03-6247b1ee0157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3a9628515845d2b951a8cb6faf9f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4411532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mutation_counts_dict = {}\n",
    "for i in tqdm(range(len(myco_info_dict[reference_species][1]))):\n",
    "    if (i+1) in temp_dict:\n",
    "        mutation_counts_dict[i] = temp_dict[(i+1)]\n",
    "    else:\n",
    "        mutation_counts_dict[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c0fc41-e2c9-4d90-8e31-23a7cb729503",
   "metadata": {},
   "source": [
    "##### Define binomial probabilities for testing mutation counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "29c2e26e-fadd-46f8-a879-fdd9f9da3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_formula(max_bin_counts, tot_bin_counts, in_frame = False):\n",
    "    return 1- binom.cdf(max_bin_counts-1, tot_bin_counts,1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b82b5020-d385-47b7-a5c2-bc484dfbf9ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mutation_bin_probability(start, end, strand):\n",
    "    mutations = []\n",
    "    for i in range(start,end):\n",
    "        for j in range(mutation_counts_dict[i]):\n",
    "            mutations.append(i)\n",
    "    bin_counts = [0,0,0]\n",
    "    for m in mutations:\n",
    "        if strand == 1:\n",
    "            bin_counts[(m-(start))%3] +=1\n",
    "        else:\n",
    "            bin_counts[((end-1)-m)%3] +=1\n",
    "    if sum(bin_counts) == 0:\n",
    "        return (2)\n",
    "    else:\n",
    "        return (bin_formula(bin_counts[2], sum(bin_counts)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0fc24677-4372-406c-9b54-dca2d2ed1e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17660632866964088"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutation_bin_probability(1282029, 1282218,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401c3881-587b-48b8-84df-78f8b9ac2f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for orf in non_overlapping_query_maximal_orfs:\n",
    "    temp = mutation_bin_probability(orf[0],orf[1],orf[2]) \n",
    "    if temp < 0.0002:\n",
    "        print(orf, mutation_bin_probability(orf[0],orf[1],orf[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b2982e-2c27-4314-a415-64cc168dfd0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47f5587-a44e-49cf-b309-5bdc3f7b2b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_organism_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01fa4cd-56c4-4f8f-8b0b-c16f35241fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orfs_maximal_in_gaps = []\n",
    "non_included_boundaries = []\n",
    "for i, (locus,start,stop,strand) in enumerate(cds_boundary_dict[reference_species]):\n",
    "    if i==0 or stop >= cds_boundary_dict[reference_species][i-1][2]:\n",
    "        non_included_boundaries.append(cds_boundary_dict[reference_species][i])\n",
    "\n",
    "for i, (locus,start,stop,strand) in enumerate(non_included_boundaries):\n",
    "    temp = []\n",
    "    if i < len(non_included_boundaries) - 1:\n",
    "        temp = find_all_maximal_orfs(full_sequences[reference_species_index], stop, non_included_boundaries[i+1][1], output_all_orfs = True, min_orf_length = 30)\n",
    "        for orf in temp:\n",
    "            orfs_maximal_in_gaps.append(orf)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
