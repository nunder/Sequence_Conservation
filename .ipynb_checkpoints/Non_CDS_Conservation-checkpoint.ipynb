{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50da8fa4-e4d1-4e99-9df9-f2593cc0c057",
   "metadata": {},
   "source": [
    "##### Import modules and set up file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3b889ee-319a-42bf-b247-4febba954254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicho\\Anaconda3\\envs\\Projects\\lib\\site-packages\\ete3-3.1.2-py3.7.egg\\ete3\\evol\\parser\\codemlparser.py:221: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\nicho\\Anaconda3\\envs\\Projects\\lib\\site-packages\\ete3-3.1.2-py3.7.egg\\ete3\\evol\\parser\\codemlparser.py:221: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    }
   ],
   "source": [
    "from Comparative_Analysis import Sequence_Analysis_Routines as sar\n",
    "from Comparative_Analysis import HMM as hmm\n",
    "from Comparative_Analysis import Utilities as util\n",
    "from Comparative_Analysis import Alignment_HMM as alignment_hmm\n",
    "from Comparative_Analysis import Alignment_Analysis as alignment_analysis\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from scipy import optimize as opt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import logomaker as lm\n",
    "import math\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import ete3;\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773a1d9c-8b02-447d-8b4c-41e9d5d24f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'D:/Project_Data/Project_3'\n",
    "sonic_paranoid_run_name = 'Run_Without_Outgroup'\n",
    "outgroup_sonic_paranoid_run_name = 'Run_With_Outgroup'\n",
    "genome_datasets_dir = project_dir + '/Datasets/NCBI_Datasets_Close_Species/'\n",
    "output_dir = project_dir + '/Output/Close_Species'\n",
    "protein_fasta_output_loc = output_dir + '/Protein_Sequences'\n",
    "outgroup_protein_fasta_output_loc = output_dir + '/Protein_Sequences_With_Outgroup'\n",
    "sonic_paranoid_output_loc = output_dir + '/Sonic_Paranoid_Output'\n",
    "ortholog_file_ref = sonic_paranoid_output_loc + '/runs/' + sonic_paranoid_run_name + '/ortholog_groups/flat.ortholog_groups.tsv'\n",
    "outgroup_ortholog_file_ref = sonic_paranoid_output_loc + '/runs/' + outgroup_sonic_paranoid_run_name + '/ortholog_groups/flat.ortholog_groups.tsv'\n",
    "non_cds_output_dir = output_dir + '/Multiple_Alignment_Data/Non_CDS'\n",
    "upstream_non_cds_output_dir = output_dir + '/Multiple_Alignment_Data/Upstream_Non_CDS'\n",
    "cds_output_dir = output_dir + '/Multiple_Alignment_Data/CDS'\n",
    "extended_cds_output_dir = output_dir + '/Multiple_Alignment_Data/Extended_CDS'\n",
    "outgroup_cds_output_dir = output_dir + '/Multiple_Alignment_Data/CDS_With_Outgroup'\n",
    "outgroup_concatenated_cds_output_dir = output_dir + '/Multiple_Alignment_Data/CDS_With_Outgroup_Concatenated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56139988-efa1-4bb1-9cd3-4cdd90020453",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = 16\n",
    "core_numbers = list(range(1, num_cores+1))\n",
    "non_cds_offset = 50\n",
    "extended_cds_offset = 100\n",
    "tb_species = 'GCF_000195955.2'\n",
    "outgroup_species = 'GCF_000696675.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf829bb3-e529-4170-ad7b-9d885d57f851",
   "metadata": {},
   "source": [
    "##### Determine genomes in ortholog family, generate protein files and run Sonic Paranoid (both with and without outgroup - outgroup needed for tree building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7a7627-bb45-4679-97ef-ed8f209447fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_ids_with_outgroup = util.list_dirs(genome_datasets_dir)\n",
    "genome_ids = util.list_dirs(genome_datasets_dir)\n",
    "genome_ids.remove(outgroup_species)\n",
    "num_ids = len(genome_ids)\n",
    "num_ids_with_outgroup = len(genome_ids_with_outgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be93725-4667-49ca-b2bc-430c0c7e9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in sar.tqdm(genome_ids):\n",
    "    sar.generate_protein_file(genome_datasets_dir + '/' + folder + '/genomic.gbff', protein_fasta_output_loc + '/' + folder + '.faa')\n",
    "for folder in sar.tqdm(genome_ids_with_outgroup):\n",
    "    sar.generate_protein_file(genome_datasets_dir + '/' + folder + '/genomic.gbff', outgroup_protein_fasta_output_loc + '/' + folder + '.faa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828d159-34d6-4f7e-878c-e31b598573a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sar.run_sonic_paranoid(protein_fasta_output_loc, sonic_paranoid_output_loc, sonic_paranoid_run_name)\n",
    "#sar.run_sonic_paranoid(outgroup_protein_fasta_output_loc, sonic_paranoid_output_loc, outgroup_sonic_paranoid_run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39369771-8cd9-4438-89a5-d426702ac448",
   "metadata": {},
   "source": [
    "##### Generate ortholog object and object containing sequence information for each ortholog group / species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "051a50d7-e6dc-42a7-9675-e58d8ae157b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75075/75075 [00:03<00:00, 23053.29it/s]\n",
      "100%|██████████| 84312/84312 [00:03<00:00, 23179.47it/s]\n"
     ]
    }
   ],
   "source": [
    "orthologs = sar.Ortholog_Grouping(ortholog_file_ref)\n",
    "outgroup_orthologs = sar.Ortholog_Grouping(outgroup_ortholog_file_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e9977fb-f334-4f33-a820-535d87f4105a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:27<00:00,  2.45s/it]\n"
     ]
    }
   ],
   "source": [
    "seq_data = sar.Ortholog_Sequence_Dataset(orthologs, genome_datasets_dir, genome_ids, non_cds_offset, tb_species) \n",
    "#outgroup_seq_data = sar.Ortholog_Sequence_Dataset(outgroup_orthologs, genome_datasets_dir, genome_ids_with_outgroup, non_cds_offset, tb_species) \n",
    "#print(outgroup_seq_data.species_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e3b630-5c42-499e-8389-5532f4dca58c",
   "metadata": {},
   "source": [
    "##### Perform CDS and non-CDS alignments for each full ortholog group and save to folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb33f80-a608-425f-bf01-6a0fe7a77226",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_species = num_ids\n",
    "min_species_with_outgroup = num_ids_with_outgroup\n",
    "groups = random.sample(orthologs.full_single_copy_ortholog_groups, len(orthologs.full_single_copy_ortholog_groups))  #Permutation ensures even distribution of processing speeds\n",
    "outgroup_groups = random.sample(outgroup_orthologs.full_single_copy_ortholog_groups, len(outgroup_orthologs.full_single_copy_ortholog_groups))  #Permutation ensures even distribution of processing speeds\n",
    "#par = Parallel(n_jobs=-1)(delayed(sar.align_and_build)(outgroup_groups, num_cores, core_number, outgroup_seq_data.sequence_data, 'cds_length', 'cds_seq', outgroup_cds_output_dir+'/', min_species_with_outgroup) for core_number in tqdm(core_numbers))\n",
    "#par = Parallel(n_jobs=-1)(delayed(sar.align_and_build)(groups, num_cores, core_number, seq_data.sequence_data, 'cds_length', 'cds_seq', cds_output_dir+'/', min_species) for core_number in tqdm(core_numbers))\n",
    "#par = Parallel(n_jobs=-1)(delayed(sar.align_and_build)(groups, num_cores, core_number, seq_data.sequence_data, 'non_cds_offset_length', 'non_cds_offset_seq', non_cds_output_dir+'/', min_species) for core_number in tqdm(core_numbers))\n",
    "#par = Parallel(n_jobs=-1)(delayed(sar.align_and_build)(groups, num_cores, core_number, seq_data.sequence_data, 'upstream_non_cds_offset_length', 'upstream_non_cds_offset_seq', upstream_non_cds_output_dir+'/', min_species) for core_number in tqdm(core_numbers))\n",
    "#par = Parallel(n_jobs=-1)(delayed(sar.align_and_build)(groups, num_cores, core_number, seq_data.sequence_data, 'cds_extended_region_length', 'cds_extended_region_seq', extended_cds_output_dir+'/', min_species) for core_number in tqdm(core_numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4552a5b9-a396-450f-956b-0494d74e13af",
   "metadata": {},
   "source": [
    "##### Run IQTree on concatenated CDS alignments to generate tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42928a48-444f-4b46-a8eb-d668dd4565e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_names = util.list_files(outgroup_cds_output_dir)\n",
    "sar.concatenate_fasta(outgroup_cds_output_dir, alignment_names, outgroup_concatenated_cds_output_dir + '/concatenated_cds.fasta')\n",
    "#subprocess.run('cd \\\\users\\\\nicho\\\\IQTree & bin\\\\iqtree2 -s ' + outgroup_concatenated_cds_output_dir + '/concatenated_cds.fasta' + ' --prefix '+ output_dir + '/Trees/Concatenated_JC_Tree -m JC -B 1000 -T AUTO -o ' + outgroup_species, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40396ae4-b80d-4ebd-ab66-e40e6712c758",
   "metadata": {},
   "source": [
    "##### Fit Alignment HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e885b08-1828-4633-9c60-4eeaab22efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_symbols = 4\n",
    "num_states = 3\n",
    "minimum_fit_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7da4636-b1db-4d25-a846-72c8fc4190a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1621/1621 [00:01<00:00, 1491.52it/s]\n"
     ]
    }
   ],
   "source": [
    "Alignment_HMM_Model = alignment_hmm.Alignment_HMM (num_symbols, num_states, non_cds_output_dir, tb_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db153df6-e6b8-4ff7-8604-6f81cfe121e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_fit_alignment_hmm (params):\n",
    "    core_numbers = range(1, num_cores+1)\n",
    "    a = Parallel(n_jobs=-1)(delayed(Alignment_HMM_Model.fit_alignment_hmm)(params, num_cores, core_number, non_cds_offset, minimum_fit_length) for core_number in core_numbers)\n",
    "    print(params, sum(a))\n",
    "    return sum(a)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d1a5f9d-bc38-4bfa-8b79-a293a874fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [0.95, 0.5, 0.95, 0.5, 0.95, 0.5, 0.9,0.5,0.2]\n",
    "bound_tuple = [(0.001,0.999),(0.001,0.999),(0.001,0.999),(0.001,0.999),(0.001,0.999),(0.001,0.999),(0.001,0.999),(0.001,0.999),(0.001,0.999)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82200c87-52e2-4f7e-b85d-c10048624d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = opt.minimize(parallel_fit_alignment_hmm, params, method = 'Nelder-Mead', bounds = bound_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7ed99fa-6a3f-4180-b38c-bdb8253c1ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitted_parameters = [0.95369268, 0.60983828, 0.83517505, 0.22289673, 0.79386769, 0.1580283, 0.89283101, 0.56297521, 0.14392359] \n",
    "fitted_parameters = [0.79185005, 0.960987, 0.83863594, 0.751462, 0.9568103, 0.1157162, 0.85319079, 0.30944991, 0.02530253]\n",
    "#fitted_parameters = res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd80c7d-b15d-4a58-b6bb-e26fe8ea1327",
   "metadata": {},
   "source": [
    "##### Remove portions of alignment gapped for TB and prepare data to plot entropies and logos and estimate conserved regions based on calibrated HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f4bea3e-4ac8-4e32-a1f1-5337d85ff5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1621 [00:00<?, ?it/s]\n",
      "100%|██████████| 586/586 [00:00<00:00, 22144.10it/s]\n",
      "  0%|          | 0/1621 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Alignment_HMM_Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18568/941795294.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mgroup_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0malignment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAlignment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malignment_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.fasta'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_species\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NT'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0malignment_info_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malignment_analysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAlignment_Analysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malignment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_cds_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitted_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproject_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdict_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malignment_info_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\Sequence_Conservation\\Comparative_Analysis\\Alignment_Analysis.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, alignment, num_states, non_cds_offset, seq_type, group_id, fitted_parameters, project_dir)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0minitial_state_probabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnum_states\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnum_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mtransition_probabilities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutation_probabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAlignment_HMM_Model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malignment_hmm_model_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitted_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mobservation_probabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAlignment_HMM_Model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malignment_hmm_mutation_probs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmutation_probabilities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malignment_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malignment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhmm_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHMM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state_probabilities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransition_probabilities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservation_probabilities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Alignment_HMM_Model' is not defined"
     ]
    }
   ],
   "source": [
    "for seq_type in ['Downstream', 'Upstream']:\n",
    "    if seq_type == 'Downstream':\n",
    "        alignment_dir = non_cds_output_dir\n",
    "        dict_name = 'downstream_conservation_info_dictionary'\n",
    "    else:\n",
    "        alignment_dir = upstream_non_cds_output_dir\n",
    "        dict_name = 'upstream_conservation_info_dictionary'\n",
    "    alignment_info_dict = {}\n",
    "    file_ids = util.list_files(alignment_dir+'/')\n",
    "    ids = [int(i.split('.')[0]) for i in file_ids]\n",
    "    for group_id in tqdm(ids):\n",
    "        alignment = sar.Alignment(alignment_dir+'/'+str(group_id)+'.fasta', tb_species, 'NT')\n",
    "        alignment_info_dict[group_id] = alignment_analysis.Alignment_Analysis(alignment, num_states, non_cds_offset, seq_type, group_id, fitted_parameters, project_dir, Alignment_HMM_Model)\n",
    "    with open(output_dir + '/' + dict_name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(alignment_info_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e890e0c5-f1e1-4a94-b2e5-5ddccc4aac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_dir + '/upstream_conservation_info_dictionary.pkl', 'rb') as f:\n",
    "    upstream_conservation_info_dictionary = pickle.load(f)\n",
    "with open(output_dir + '/downstream_conservation_info_dictionary.pkl', 'rb') as f:\n",
    "    downstream_conservation_info_dictionary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d610d-9e76-4cbe-be84-188b7ec12515",
   "metadata": {},
   "source": [
    "##### Plot graphics to show sequence and HMM regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71321558-eadf-45f1-9910-d6826253e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conservation_plot(group_id, conservation_info_dictionary):\n",
    "    analysed_alignment = conservation_info_dictionary[group_id]\n",
    "    alignment = analysed_alignment.alignment; buffer_end = analysed_alignment.buffer_end; target_end = analysed_alignment.target_end; start = analysed_alignment.start; end = analysed_alignment.end; \n",
    "    locus_tag = analysed_alignment.locus_tag; cds_strand = analysed_alignment.cds_strand; locus_tag_2 = analysed_alignment.locus_tag_2; locus_strand_2 = analysed_alignment.locus_strand_2; \n",
    "    utr_start = analysed_alignment.utr_start; utr_end = analysed_alignment.utr_end; hmm_model = analysed_alignment.hmm_model\n",
    "\n",
    "    counts_df = lm.alignment_to_matrix(sequences = alignment.modified_sequence_list, to_type = 'counts', characters_to_ignore = '-', pseudocount=0)\n",
    "    background_probs = [0.25, 0.25, 0.25, 0.25]\n",
    "    for i, r in counts_df.iterrows():\n",
    "        temp_relent = []\n",
    "        num_gaps = alignment.num_sequences\n",
    "        for k in range(4):\n",
    "            num_gaps = num_gaps - r.iloc[k]\n",
    "        for k in range(4):\n",
    "            ct = r.iloc[k] + num_gaps*background_probs[k]\n",
    "            if ct == 0:\n",
    "                temp_relent.append(0)\n",
    "            else:\n",
    "                temp_relent.append((ct /alignment.num_sequences) * math.log((ct /alignment.num_sequences)/background_probs[k],2))\n",
    "        for k in range(4):\n",
    "            r.iloc[k] = temp_relent[k]\n",
    "\n",
    "    y = -1        \n",
    "    seqlogo = lm.Logo(counts_df, figsize = [50,2])\n",
    "    seqlogo.ax.plot([0, buffer_end], [y,y], color='skyblue', linewidth=10, solid_capstyle='butt')\n",
    "    seqlogo.ax.plot([target_end, alignment.modified_sequence_length], [y,y], color='skyblue', linewidth=10, solid_capstyle='butt')\n",
    "    for i in alignment.master_species_modified_sequence_insertions:\n",
    "        seqlogo.ax.plot([i[0], i[0]+1], [y-2,y-2], color='red', linewidth=3*i[1], solid_capstyle='butt')\n",
    "    for i in alignment.find_pattern(['TANNNT'],0,alignment.modified_sequence_length,1.3,0, method = 'entropy'):\n",
    "        seqlogo.ax.plot([i, i+5], [y,y], color='orange', linewidth=5, solid_capstyle='butt')\n",
    "#    for i in alignment.find_pattern(['NTG'],0,alignment.modified_sequence_length,1,0,in_frame = True, frame_start = target_end, method = 'entropy'):\n",
    "    for i in alignment.find_pattern(['ATG','GTG','TTG','CTG'],0,alignment.modified_sequence_length,1,1,in_frame = True, frame_start = target_end, method = 'count'):\n",
    "        seqlogo.ax.plot([i, i+2], [y,y], color='green', linewidth=5, solid_capstyle='butt')\n",
    "    for i in alignment.find_pattern(['TAG','TGA','TAA'],0,alignment.modified_sequence_length,1,1,in_frame = True, frame_start = target_end, method = 'count'):\n",
    "        seqlogo.ax.plot([i, i+2], [y,y], color='red', linewidth=5, solid_capstyle='butt')\n",
    "    for i in alignment.find_pattern(['TAG','TGA','TAA'],0,alignment.modified_sequence_length,1,1,in_frame = True, frame_start = buffer_end-2, method = 'count'):\n",
    "        seqlogo.ax.plot([i, i+2], [y-0.5,y-0.5], color='blue', linewidth=5, solid_capstyle='butt')\n",
    "    \n",
    "    seqlogo.ax.plot([utr_start, utr_end],[y-0.5, y-0.5], color='mediumslateblue', linewidth=10, solid_capstyle='butt')\n",
    "    for i, state in enumerate(hmm_model.viterbi_path):\n",
    "        if state in [0]:\n",
    "            seqlogo.highlight_position_range(pmin=i, pmax=i, color='rosybrown')\n",
    "    seqlogo.ax.text(0,4.2*y,locus_tag + ' ('+str(cds_strand)+')',fontsize=12)\n",
    "    seqlogo.ax.text(alignment.modified_sequence_length - buffer_end/2,4.2*y,locus_tag_2+ ' ('+str(locus_strand_2)+')',fontsize=12)\n",
    "    seqlogo.ax.text(0, 4.5*y,int(start), verticalalignment='top', horizontalalignment='left')\n",
    "    seqlogo.style_spines(visible=False)\n",
    "    seqlogo.style_spines(spines=['left'], visible=True, bounds=[0, 2])\n",
    "    seqlogo.ax.set_xticks([])\n",
    "    seqlogo.ax.set_yticks([0,2])\n",
    "    seqlogo.ax.set_ylim([-4, 2])\n",
    "    seqlogo.ax.axhline(y, color = 'k', linewidth = 1)\n",
    "    seqlogo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8afdfa-0cd7-4823-82a3-2d44229dc862",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id = 1337\n",
    "  \n",
    "    #1161 1115 1116 758 1337   1525?List of sRNA in    \n",
    "    #1129\n",
    "    #1169 shows upstream start in DeJesus\n",
    "    #2131 not very well conserved in Arnvig\n",
    "conservation_plot(group_id, upstream_conservation_info_dictionary)\n",
    "conservation_plot(group_id, downstream_conservation_info_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b7266-4668-4b5f-9cc7-7f76837608e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = upstream_conservation_info_dictionary[group_id]\n",
    "alignment = data[0]; alignment_2 = data[1]; alignment_3 = data[2]; cds_end_pos = data[3]; non_cds_end_pos = data[4]; non_cds_offset_start = data[5]; non_cds_offset_end = data[6]; \n",
    "locus_tag = data[7]; cds_strand = data[8]; locus_tag_2 = data[9]; locus_strand_2 = data[10]; utr_start_pos = data[11]; utr_end_pos = data[12]; hmm = data[13]\n",
    "#plt.plot(alignment.relative_entropy);\n",
    "#plt.plot(alignment.mvave_relative_entropy);\n",
    "plt.axvline(x=cds_end_pos, ymin=0, ymax=2, color='r');\n",
    "plt.axvline(x=non_cds_end_pos, ymin=0, ymax=2, color='r');\n",
    "for state in [0]:\n",
    "    plt.plot(hmm.state_probabilities[state]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce922e-bf9c-4616-96ce-c503f2580a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ids = util.list_files(non_cds_output_dir+'/')\n",
    "ids = [int(i.split('.')[0]) for i in file_ids]\n",
    "for id in tqdm(ids):\n",
    "    if id in conservation_info_dict:\n",
    "        temp = conservation_info_dict[id]\n",
    "        viterbi_path = temp[12].viterbi_path\n",
    "        viterbi_path_length = len(viterbi_path) \n",
    "        conserved_length = sum(viterbi_path[50:viterbi_path_length - 50])\n",
    "        num_insertions = len(temp[1].master_species_modified_sequence_insertions)\n",
    "        sequence_length = temp[0].modified_sequence_length\n",
    "        if sequence_length > 150 and conserved_length > 50:\n",
    "            print (id, sequence_length, conserved_length, conserved_length/sequence_length, num_insertions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011e8b96-1a28-4cbd-9325-7f77bdad0c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp= seq_data.sequence_data\n",
    "group_id = (temp[temp['locus_tag'] == 'Rv0243'].iloc[0]['group_id'])\n",
    "temp[temp['group_id'] == group_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909ba5ef-65dd-4e6d-9b5b-74175da14c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp= seq_data.sequence_data\n",
    "temp[temp['group_id'] == 1121]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac6a84-5c08-4c3c-94bb-1f7f6ff69411",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = orthologs.single_copy_orthologs_df\n",
    "temp[temp['group_id'] == 1121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2f2df-70eb-4be9-ba45-6d3a82419aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
