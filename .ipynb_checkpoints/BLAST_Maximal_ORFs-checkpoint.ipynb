{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef24ce4-4729-44b6-8d43-fbdf47b9033a",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Set up packages and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9105f9b4-46be-44fd-b947-d3c47ce2fa01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fft import fft, fftfreq\n",
    "from Bio import Entrez, SeqIO, AlignIO, pairwise2, Align, Seq, motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from scipy.stats import binom\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "from Comparative_Analysis import Sequence_Analysis_Routines as sar\n",
    "from Comparative_Analysis import Utilities as util\n",
    "from Comparative_Analysis import Alignment as align\n",
    "import random\n",
    "import copy\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import subprocess\n",
    "from Bio.Blast import NCBIWWW, NCBIXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1988a242-f558-4643-b3a9-27272fa7bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'D:/Project_Data/Project_6'\n",
    "literature_datasets_dir = project_dir + '/Datasets/Data_From_Publications'\n",
    "output_dir = project_dir + '/Output'\n",
    "refseq_dir = 'D:/Test_3/NCBI_Dataset_Mycobacteria'\n",
    "cryptic_output_path = \"D:/Project_Data/CRYPTIC_DATA/Cryptic_Data_Analysis\"\n",
    "num_cores = 16\n",
    "core_numbers = list(range(1, num_cores+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abef54a8-1fd0-4a05-94de-bc9e2f647844",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = util.list_dirs(refseq_dir)\n",
    "reference_species = 'GCF_000195955.2'\n",
    "species_list_excl_ref = [x for x in species_list if x!= reference_species]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a6e9ec-f8a4-4724-a568-47d69682f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_nts = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f28e8-a111-4d47-a7d6-9fbe2e08e2d4",
   "metadata": {},
   "source": [
    "##### Translation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a3fe56-c71f-43a4-9a6b-e369f4b7b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "codon_dict = {}\n",
    "with open('D:/Project_Data/Project_3/Datasets/Reference_Tables/Standard_Code.txt') as f:\n",
    "    for l in f:\n",
    "        codon_dict[str(l[1:4])] = l[5]\n",
    "def translate_sequence(input_seq, strand, rf):\n",
    "    output_seq = ''\n",
    "    if strand == 1:\n",
    "        seq = input_seq[rf:]\n",
    "    else:\n",
    "        seq = align.reverse_complement(input_seq)[rf:]\n",
    "    for i in range(0,len(seq)-2,3):\n",
    "        if seq[i:(i+3)] in codon_dict:\n",
    "            output_seq += codon_dict[seq[i:(i+3)]]\n",
    "        else:\n",
    "            output_seq += 'X'\n",
    "    return output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f975dff-4e95-44f1-978b-5c46eee3e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_orf(sequence, start, end, strand):\n",
    "    return translate_sequence(sequence[start:end], strand, 0)              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc300757-df8c-42d8-a7a0-352213a45d3f",
   "metadata": {},
   "source": [
    "##### Output nt sequences in FASTA format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab243605-4807-411c-8195-401b1a404c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_blast_file(record_list, output_filename):\n",
    "    with open(output_filename, 'w',  newline='') as outfile:\n",
    "        line_length = 60\n",
    "        for record in tqdm(record_list):\n",
    "            sequence = record[1]\n",
    "            lines = []\n",
    "            sequence_length = len(sequence)\n",
    "            number_of_lines = math.ceil(sequence_length / line_length)\n",
    "            lines.append(\">\" +record[0]+ \"\\n\")\n",
    "            for i in range(number_of_lines):\n",
    "                subsequence = sequence[i*line_length:(i+1)*line_length]\n",
    "                lines.append(subsequence + \"\\n\")\n",
    "            outfile.write(''.join(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc97354-4eec-4741-b8b0-58b7be52aa9b",
   "metadata": {},
   "source": [
    "##### Function to find maximal open reading frame between two co-ordinates with mutation probability less than defined p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23757841-ce5e-4eaa-9f83-c94f63b145a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_maximal_orfs(sequence, seq_start, seq_stop, output_all_orfs = False, min_orf_length = 0):\n",
    "    max_len = 0\n",
    "    orfs_found = []\n",
    "    start_pos = -999\n",
    "    end_pos = -999\n",
    "    for frame in ['Forward', 'Reverse']:\n",
    "        if frame == 'Forward':\n",
    "            temp = (sequence[seq_start: seq_stop])\n",
    "        else:\n",
    "            temp = align.reverse_complement(sequence[seq_start: seq_stop])\n",
    "        seq_len = len(temp)\n",
    "        for rf in range(3):\n",
    "            i = rf\n",
    "            while i < seq_len - 2:\n",
    "                orf_length = 0\n",
    "                test_codon = temp[i: i+3] \n",
    "                if test_codon in ['ATG','GTG','TTG']:  \n",
    "                    for j in range(i + 3, seq_len - 2, 3):\n",
    "                        test_codon_2 = temp[j: j+3] \n",
    "                        if test_codon_2 in ['TAG','TGA','TAA']:\n",
    "                            orf_length = j - i\n",
    "                            break\n",
    "                            \n",
    "                if orf_length > 0:\n",
    "                    if frame == 'Forward':\n",
    "                        orf_start =  seq_start + i\n",
    "                        orf_end = seq_start + j+3\n",
    "                        orf_strand = 1\n",
    "                    else:\n",
    "                        orf_start =  seq_start + seq_len-(j+3)\n",
    "                        orf_end = seq_start + seq_len-i\n",
    "                        orf_strand = -1\n",
    "                    \n",
    "                    if orf_length >= min_orf_length:\n",
    "                        orfs_found.append((orf_start, orf_end, orf_strand, orf_length))\n",
    "\n",
    "                if orf_length > max_len and orf_length >= min_orf_length:                                           \n",
    "                    max_len = orf_length\n",
    "                    start_pos = orf_start\n",
    "                    end_pos = orf_end\n",
    "                    strand = orf_strand \n",
    "\n",
    "                if orf_length > 0:\n",
    "                    i = j\n",
    "                else:\n",
    "                    i +=3\n",
    "    if output_all_orfs == True:\n",
    "        sorted_orfs = sorted(orfs_found, key=lambda x: x[3], reverse=True)\n",
    "        return sorted_orfs                \n",
    "    elif start_pos == -999:\n",
    "        return(0,0,0,0)\n",
    "    else:\n",
    "        return(start_pos, end_pos, strand, max_len)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d030d-93fc-42d5-9a5d-15c81d94f5a9",
   "metadata": {},
   "source": [
    "##### Function to find nearest upstream start to an alignment making it an open reading frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50304da6-9a6a-4049-8652-9b2dd20cd51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_upstream_orf_sequence(sequence, seq_start, seq_stop, strand, max_lookback = 100):\n",
    "    out_seq = ''\n",
    "    if strand == 1:\n",
    "            temp = (sequence[seq_start - max_lookback * 3: seq_stop])\n",
    "    else:\n",
    "            temp = align.reverse_complement(sequence[seq_start: seq_stop + max_lookback * 3])\n",
    "    for lookback in range(max_lookback, -1, -1):\n",
    "        if temp[lookback * 3: (lookback+1) *3 ] in ['TAG','TGA','TAA']:\n",
    "            #  Not possible without first encountering stop - just return original sequence\n",
    "            out_seq = translate_sequence(temp[max_lookback * 3:],1,0)\n",
    "            break\n",
    "        if temp[lookback * 3: (lookback+1) *3 ] in ['ATG','GTG','TTG']:\n",
    "            out_seq = translate_sequence(temp[lookback * 3:],1,0)\n",
    "            break\n",
    "    return(out_seq)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6072f484-eaa0-4045-b08e-0a0cdc9e4348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_downstream_orf_sequence(sequence, seq_start, seq_stop, strand):\n",
    "    max_lookforward = len(sequence) - 5\n",
    "    out_seq = ''\n",
    "    if strand == 1:\n",
    "            temp = sequence[seq_start:seq_stop]\n",
    "    else:\n",
    "            temp = align.reverse_complement(seq_start:seq_stop)\n",
    "    for lookback in range(max_lookforward):\n",
    "        if temp[lookback * 3: (lookback+1) *3 ] in ['TAG','TGA','TAA']:\n",
    "            #  Not possible without first encountering stop - just return original sequence\n",
    "            out_seq = translate_sequence(temp,1,0)\n",
    "            break\n",
    "        if temp[lookback * 3: (lookback+1) *3 ] in ['ATG','GTG','TTG']:\n",
    "            out_seq = translate_sequence(temp[lookback * 3:],1,0)\n",
    "            break\n",
    "    return(out_seq)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1fc097-47b4-4cf3-adda-8c19c8baabd2",
   "metadata": {},
   "source": [
    "#####  Function to process output from BLAST into dataframe with looked up values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c4637-0466-4dd8-8fed-5f36972c1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_blast_output(infile_loc, outfile_loc):\n",
    "    blast_results = pd.read_csv(infile_loc, header = None)\n",
    "    blast_results.columns = ['query_accession_ver', 'subject_accession_ver', 'query_length', 'subject_length', 'percent_identical_matches','alignment_length', 'number_mismatches', 'number_of_gap_openings', 'query_start_alignment', 'query_end_alignment', 'subject_start_alignment', 'subject_end_alignment', 'e_value', 'bit_score']\n",
    "    blast_results['query_info']=  blast_results['query_accession_ver'].map(protein_reference_dict)\n",
    "    blast_results['subject_info']=  blast_results['subject_accession_ver'].map(protein_reference_dict)\n",
    "    blast_results['query_feature']=  blast_results['query_accession_ver'].map(orf_feature_dict)\n",
    "    blast_results['subject_feature']=  blast_results['subject_accession_ver'].map(orf_feature_dict)\n",
    "    for i, r in blast_results.iterrows():\n",
    "        blast_results.at[i, 'query_species'] = '_'.join(r.query_accession_ver.split('_')[0:2])\n",
    "        blast_results.at[i, 'subject_species'] = '_'.join(r.subject_accession_ver.split('_')[0:2])\n",
    "    blast_results = blast_results.query('not (query_species == subject_species)')\n",
    "    blast_results['query_species_name'] = blast_results['query_species'].map(names_dict)\n",
    "    blast_results['subject_species_name'] = blast_results['subject_species'].map(names_dict)\n",
    "    for i, r in blast_results.iterrows():\n",
    "        if r.query_info[2] == 1:\n",
    "            blast_results.at[i, 'query_start_pos'] = r.query_info[0] + (r.query_start_alignment - 1) * 3\n",
    "            blast_results.at[i, 'query_end_pos'] = r.query_info[0] + (r.query_end_alignment - 1) * 3 + 6 # doesn't include stop codon in blast\n",
    "        else:\n",
    "            blast_results.at[i, 'query_start_pos'] = r.query_info[1] - (r.query_end_alignment) * 3\n",
    "            blast_results.at[i, 'query_end_pos'] = r.query_info[1] - (r.query_start_alignment - 1) * 3\n",
    "\n",
    "        if r.subject_info[2] == 1:\n",
    "            blast_results.at[i, 'subject_start_pos'] = r.subject_info[0] + (r.subject_start_alignment - 1) * 3\n",
    "            blast_results.at[i, 'subject_end_pos'] = r.subject_info[0] + (r.subject_end_alignment - 1) * 3 + 6 # doesn't include stop codon in blast\n",
    "        else:\n",
    "            blast_results.at[i, 'subject_start_pos'] = r.subject_info[1] - (r.subject_end_alignment) * 3\n",
    "            blast_results.at[i, 'subject_end_pos'] = r.subject_info[1] - (r.subject_start_alignment - 1) * 3\n",
    "    blast_results = blast_results.loc[blast_results.groupby(['query_accession_ver','subject_species'])['bit_score'].idxmax()]\n",
    "    blast_results['species_count'] = blast_results.groupby('query_accession_ver')['query_accession_ver'].transform('size')\n",
    "    for i, r in blast_results.iterrows():\n",
    "        subject_strand = r.subject_info[2]\n",
    "        blast_results.at[i,'sequence'] = translate_orf(myco_info_dict[r.subject_species][1], int(r.subject_start_pos), int(r.subject_end_pos), subject_strand)\n",
    "        blast_results.at[i,'nearest_upstream_orf_sequence'] = find_nearest_upstream_orf_sequence(myco_info_dict[r.subject_species][1], int(r.subject_start_pos), int(r.subject_end_pos), subject_strand, max_lookback = 100)\n",
    "        blast_results.at[i,'nearest_downstream_orf_sequence'] = find_nearest_downstream_orf_sequence(myco_info_dict[r.subject_species][1], int(r.subject_start_pos), int(r.subject_end_pos), subject_strand)\n",
    "    blast_results.to_csv(outfile_loc)\n",
    "    return blast_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9616c59-268c-4738-9682-0c2d4fa3cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_reciprocal_best_hits(query_df, reverse_query_df, outfile_loc):\n",
    "    temp_1_dict = {}\n",
    "    temp_2_dict = {}\n",
    "    for i, r in query_df.iterrows():\n",
    "        temp_1_dict[r['query_accession_ver']] = r['subject_accession_ver']\n",
    "    for i, r in reverse_query_df.iterrows():\n",
    "        temp_2_dict[r['query_accession_ver']] = r['subject_accession_ver']\n",
    "    for i, r in query_df.iterrows():\n",
    "        if temp_1_dict[r['query_accession_ver']] in temp_2_dict and temp_2_dict[temp_1_dict[r['query_accession_ver']]] == r['query_accession_ver']:\n",
    "            query_df.at[i, 'reciprocal_best_hit'] = 'Y'\n",
    "        else:\n",
    "            query_df.at[i, 'reciprocal_best_hit'] = 'N'\n",
    "    output = query_df[query_df.reciprocal_best_hit == 'Y'] \n",
    "    output.to_csv(outfile_loc)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ef9e8-e455-4ec3-b342-29749e142d86",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Extract full sequences from each organism and create directory of start and stops for each annotated cds (use Mycobrowser for MTb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c760b-8f05-4aba-989f-e3400c233392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_myco_info(num_subsets, subset_num, species_master_list):\n",
    "    output = []\n",
    "    species_list = util.chunk_list(species_master_list, num_subsets, subset_num)\n",
    "    for species in species_list:\n",
    "        features = []\n",
    "        genome_record = next(SeqIO.parse(refseq_dir + '/'+species+'/genomic.gbff', \"genbank\"))\n",
    "        full_sequence = str(genome_record.seq)\n",
    "        if full_sequence.count('A') + full_sequence.count('C') + full_sequence.count('G') + full_sequence.count('T') < len(full_sequence):\n",
    "            continue\n",
    "        organism = genome_record.annotations['organism']\n",
    "        \n",
    "        #  Read feature information\n",
    "        if species == reference_species:\n",
    "            mycobrowser_df = pd.read_excel(literature_datasets_dir+'/Mycobrowser_Release_4.xlsx')\n",
    "            for i, r in mycobrowser_df.iterrows():\n",
    "                if r['Strand'] == '+':\n",
    "                    strand = 1\n",
    "                else:\n",
    "                    strand = -1\n",
    "                features.append((r['Locus'],r['Start']-1, r['Stop'], strand))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            for feature in genome_record.features:\n",
    "                    a = feature.qualifiers\n",
    "                    if a.get(\"locus_tag\")!= None and int(feature.location.end) - int(feature.location.start) < 100000:  #  Exclude strange Biopython parsing where starts with complement join and looks like a CDS is full length of genome!    and feature.type == 'CDS':\n",
    "                        locus_tag = a.get(\"locus_tag\")[0]\n",
    "                        features.append([locus_tag, int(feature.location.start), int(feature.location.end), int(feature.location.strand)])\n",
    "        \n",
    "        #  Find maximal orfs, non-overlapping orfs and their protein sequences, and assign a reference to each\n",
    "        maximal_orfs = find_all_maximal_orfs(full_sequence, 0, len(full_sequence), True, min_nts)\n",
    "        \n",
    "        protein_references = []\n",
    "        maximal_orf_proteins = []\n",
    "        orf_feature_map = []\n",
    "        non_overlapping_maximal_orfs = []\n",
    "        non_overlapping_maximal_orf_proteins = []\n",
    "        for i, orf in enumerate(maximal_orfs):\n",
    "            translation = translate_orf(full_sequence, orf[0], orf[1], orf[2])[:-1]\n",
    "            morf_name = species+'_'+str(i)\n",
    "            maximal_orf_proteins.append([morf_name, translation])\n",
    "            protein_references.append((morf_name, orf))\n",
    "            overlap = False\n",
    "            for cds in features:\n",
    "                if orf[0] <= cds[1] and orf[1] >= cds[2] and orf[2] == cds[3]:\n",
    "                    orf_feature_map.append((morf_name, cds[0]))\n",
    "                if min(cds[2], orf[1]) - max(cds[1], orf[0]) > 0.3 * (orf[1] - orf[0]):\n",
    "                    overlap = True\n",
    "                    break\n",
    "            if overlap == False:\n",
    "                nomorf_name = species+'_NO_'+str(i)\n",
    "                non_overlapping_maximal_orfs.append(orf)\n",
    "                non_overlapping_maximal_orf_proteins.append([nomorf_name, translation])\n",
    "                protein_references.append((nomorf_name, orf))\n",
    "               \n",
    "        output.append((species, organism, full_sequence, features, maximal_orfs, non_overlapping_maximal_orfs, maximal_orf_proteins, non_overlapping_maximal_orf_proteins, protein_references, orf_feature_map))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a62613-b631-468a-90e9-ff3e0fe9255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "myco_info_dict = {}\n",
    "names_dict = {}\n",
    "parallel_output = Parallel(n_jobs=-1)(delayed(generate_myco_info)(num_cores, core_number, species_list) for core_number in core_numbers)\n",
    "for core_output in parallel_output:\n",
    "    for results in core_output:\n",
    "        myco_info_dict[results[0]] = (results[1], results[2], results[3], results[4], results[5], results[6], results[7], results[8], results[9])\n",
    "        names_dict[results[0]] = results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65005d52-45e0-439b-8091-e1d971d6b440",
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_feature_dict = {}\n",
    "protein_reference_dict = {}\n",
    "orf_protein_dict = {}\n",
    "for species in species_list:\n",
    "    for ref in myco_info_dict[species][7]:\n",
    "        protein_reference_dict[ref[0]] = ref[1]\n",
    "        orf_protein_dict[(species, ref[1])] = ref[0]\n",
    "    for ref in myco_info_dict[species][8]:\n",
    "        orf_feature_dict[ref[0]] = ref[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4046ad-c780-42ac-843e-375ce3d2e0aa",
   "metadata": {},
   "source": [
    "##### Output two blast files - one (subject) containing all translated mORFs, the other (query) just the ones for the reference species "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a5ad12-f3b7-4a08-ba72-1960f22779a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_protein_list = []\n",
    "for species in species_list_excl_ref:\n",
    "    for maximal_orf_protein in myco_info_dict[species][5]:\n",
    "        subject_protein_list.append(maximal_orf_protein)\n",
    "produce_blast_file(subject_protein_list, refseq_dir + '/subject_proteins.faa')\n",
    "\n",
    "query_protein_list = myco_info_dict[reference_species][6]\n",
    "produce_blast_file(query_protein_list, refseq_dir + '/no_overlap_morf_query_proteins.faa')\n",
    "\n",
    "query_protein_list = myco_info_dict[reference_species][5]\n",
    "produce_blast_file(query_protein_list, refseq_dir + '/morf_query_proteins.faa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5fe6a4-dcf0-4b12-9257-c73f35691298",
   "metadata": {},
   "source": [
    "##### Create blast databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8fedc-abfd-41b4-a82e-3ccaf8902e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==0:\n",
    "    w_d = os.getcwd()\n",
    "    os.chdir(\"D:/\")\n",
    "    subprocess.run('cd '+ refseq_dir + ' &  makeblastdb -in subject_proteins.faa -dbtype prot -out subj_prot', shell=True, capture_output = True)\n",
    "    subprocess.run('cd '+ refseq_dir + ' &  makeblastdb -in morf_query_proteins.faa -dbtype prot -out query_prot', shell=True, capture_output = True)\n",
    "    subprocess.run('cd '+ refseq_dir + ' &  makeblastdb -in no_overlap_morf_query_proteins.faa -dbtype prot -out no_overlap_query_prot', shell=True, capture_output = True)\n",
    "    os.chdir(w_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d3567-db99-4a95-b433-9efbe359cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==0:\n",
    "    w_d = os.getcwd()\n",
    "    os.chdir(\"D:/\")\n",
    "    subprocess.run('cd d:\\\\BLAST\\\\subj_prot & blastp -query ' + refseq_dir + '/morf_query_proteins.faa -db subj_prot -out blastp_results_query_subject.csv -evalue 1e-7 -seg no -outfmt  \"10 qaccver saccver qlen slen pident length mismatch gapopen qstart qend sstart send evalue bitscore\" -num_threads 16', shell=True, capture_output = True)\n",
    "    subprocess.run('cd d:\\\\BLAST\\\\subj_prot & blastp -query ' + refseq_dir + '/no_overlap_morf_query_proteins.faa -db subj_prot -out blastp_results_no_overlap_query_subject.csv -evalue 1e-7 -seg no -outfmt  \"10 qaccver saccver qlen slen pident length mismatch gapopen qstart qend sstart send evalue bitscore\" -num_threads 16', shell=True, capture_output = True)\n",
    "    subprocess.run('cd d:\\\\BLAST\\\\query_prot & blastp -query ' + refseq_dir + '/subject_proteins.faa -db query_prot -out blastp_results_subject_query.csv -evalue 1e-7 -seg no -outfmt  \"10 qaccver saccver qlen slen pident length mismatch gapopen qstart qend sstart send evalue bitscore\" -num_threads 16', shell=True, capture_output = True)\n",
    "    subprocess.run('cd d:\\\\BLAST\\\\no_overlap_query_prot & blastp -query ' + refseq_dir + '/subject_proteins.faa -db no_overlap_query_prot -out blastp_results_subject_no_overlap_query.csv -evalue 1e-7 -seg no -outfmt  \"10 qaccver saccver qlen slen pident length mismatch gapopen qstart qend sstart send evalue bitscore\" -num_threads 16', shell=True, capture_output = True)\n",
    "    os.chdir(w_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafef7a7-f78b-43b8-afbb-15ffe2b6b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_results_qs = process_blast_output('D:\\\\BLAST\\\\subj_prot\\\\blastp_results_query_subject.csv', project_dir + '/blast_results_qs.csv')\n",
    "blast_results_sq = process_blast_output('D:\\\\BLAST\\\\query_prot\\\\blastp_results_subject_query.csv', project_dir + '/blast_results_sq.csv')\n",
    "blast_results_noqs = process_blast_output('D:\\\\BLAST\\\\subj_prot\\\\blastp_results_no_overlap_query_subject.csv', project_dir + '/blast_results_noqs.csv')\n",
    "blast_results_snoq = process_blast_output('D:\\\\BLAST\\\\no_overlap_query_prot\\\\blastp_results_subject_no_overlap_query.csv', project_dir + '/blast_results_snoq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d11e3-9b39-4dad-8377-06180f4bfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbh_orf = keep_reciprocal_best_hits(blast_results_qs, blast_results_sq, project_dir + '/rbh_orf_results.csv')\n",
    "rbh_non_overlap_orf = keep_reciprocal_best_hits(blast_results_noqs, blast_results_snoq, project_dir + '/rbh_non_overlap_orf_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd1fe9-84a7-4029-b7ff-7595da70df55",
   "metadata": {},
   "source": [
    "#####  Count orthologs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cefd50-8f6f-457a-a8b3-878da5c8d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = rbh_orf.query('not(query_feature.isnull()) and not(subject_feature.isnull())')\n",
    "temp.groupby('subject_species_name').count().to_csv(project_dir + '/reciprocal_ortholog_counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acfa28e-0932-4aad-bde5-a76b8c115cb8",
   "metadata": {},
   "source": [
    "#####  Identify commonly preserved mORFs in non-overlapping areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9516c427-7e1e-46c2-801d-6e54290027ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = rbh_non_overlap_orf[rbh_non_overlap_orf.species_count > 70]\n",
    "temp.to_csv(project_dir + '/nick.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf458b9-185f-41c7-8dba-73405473290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_orf_dict = {}\n",
    "for k, v in orf_feature_dict.items():\n",
    "    feature_orf_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d55aa-3903-4dec-816c-1c2b95783122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rbh_orf[rbh_orf['query_feature'] == 'Rv0007']\n",
    "df.to_csv(project_dir + '/nick2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed6481f-0e5c-4d6c-8760-15c9a2721422",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for i, feature in enumerate(myco_info_dict[reference_species][2]):\n",
    "    strand = feature[3]\n",
    "    name = feature[0]\n",
    "    if strand == 1:\n",
    "        start = feature[1]\n",
    "    else:\n",
    "        start = feature[2]\n",
    "        \n",
    "    if not (feature[0] in feature_orf_dict):\n",
    "        pass\n",
    "    else:\n",
    "\n",
    "        df = rbh_orf.query('query_feature == @feature[0]')[['query_feature', 'query_start_pos', 'query_end_pos']]\n",
    "        if len(df) > 30:\n",
    "            if strand == 1:\n",
    "                df['offset'] = (df['query_start_pos'] - start)/3\n",
    "            else:\n",
    "                df['offset'] = (df['query_end_pos'] - start)/3\n",
    "            df_list.append(df)\n",
    "temp = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee97b8b5-ebf0-4eed-b55d-3403ce87fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.groupby('query_feature')['offset'].agg(pd.Series.mode).to_frame().to_csv(project_dir + '/nick3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2905f0e0-6492-4b59-9a2b-9d86b5a62cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.query('offset > -80 and offset < 80')\n",
    "plt.figure(figsize=(6, 6))\n",
    "g = sns.FacetGrid(temp, col='query_feature', height=3, col_wrap=8)\n",
    "g.map(sns.histplot, 'offset')\n",
    "g.set_titles(row_template = '{row_name}', col_template = '{col_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f3790-d2c1-4863-bb3f-433308803747",
   "metadata": {},
   "source": [
    "##### Violin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b90381-2875-4d69-8e48-647297c3a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp['query_feature'] == 'Rv0003']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f05446-a0bc-46ab-878f-6f49731b58a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "g = sns.FacetGrid(rbh_orf, col='subject_species_name', height=5, col_wrap=3)\n",
    "g.map(sns.scatterplot, 'subject_start_pos', 'query_start_pos', s=2)\n",
    "g.set_titles(row_template = '{row_name}', col_template = '{col_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b17660-8356-498a-9a4a-6703a9eccc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_reference_dict['GCF_000195955.2_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aead327-4194-4c7c-a9d1-b99700ebe234",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Load variant dataset and create variant dictionary (0 indexed for genome position - whereas CRyPtiC data uses 1 start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7638b75f-0ae0-4f3c-a633-97c5be43cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_count_df = pd.read_csv(cryptic_output_path + '/filtered_variant_summary_df.csv')\n",
    "variant_count_df = variant_count_df[variant_count_df['MUTATION_PCT'] < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea312a-e6f6-4166-9b04-8b2a568f0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = variant_count_df.groupby(['GENOME_INDEX'])[['MYKROBE_LINEAGE_NAME_2']].count().reset_index()\n",
    "temp_dict = dict(zip(temp.GENOME_INDEX, temp.MYKROBE_LINEAGE_NAME_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bddba0-89fe-4532-ae03-6247b1ee0157",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_counts_dict = {}\n",
    "for i in tqdm(range(len(myco_info_dict[reference_species][1]))):\n",
    "    if (i+1) in temp_dict:\n",
    "        mutation_counts_dict[i] = temp_dict[(i+1)]\n",
    "    else:\n",
    "        mutation_counts_dict[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c0fc41-e2c9-4d90-8e31-23a7cb729503",
   "metadata": {},
   "source": [
    "##### Define binomial probabilities for testing mutation counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c2e26e-fadd-46f8-a879-fdd9f9da3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_formula(max_bin_counts, tot_bin_counts, in_frame = False):\n",
    "    return 1- binom.cdf(max_bin_counts-1, tot_bin_counts,1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b5020-d385-47b7-a5c2-bc484dfbf9ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mutation_bin_probability(start, end, strand):\n",
    "    mutations = []\n",
    "    for i in range(start,end):\n",
    "        for j in range(mutation_counts_dict[i]):\n",
    "            mutations.append(i)\n",
    "    bin_counts = [0,0,0]\n",
    "    for m in mutations:\n",
    "        if strand == 1:\n",
    "            bin_counts[(m-(start))%3] +=1\n",
    "        else:\n",
    "            bin_counts[((end-1)-m)%3] +=1\n",
    "    if sum(bin_counts) == 0:\n",
    "        return (2)\n",
    "    else:\n",
    "        return (bin_formula(bin_counts[2], sum(bin_counts)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc24677-4372-406c-9b54-dca2d2ed1e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_bin_probability(1282029, 1282218,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b2982e-2c27-4314-a415-64cc168dfd0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
