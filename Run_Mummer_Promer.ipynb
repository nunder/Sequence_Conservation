{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "bd555e82-b9bd-441f-97e1-2ea88e235609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez, SeqIO, AlignIO, pairwise2, Align, Seq, motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from Comparative_Analysis import Utilities as util\n",
    "from Comparative_Analysis import Sequence_Analysis_Routines as sar\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "from Comparative_Analysis import Alignment as align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95848924-ea83-44a5-be33-2aa6957f1656",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = 'D:/Project_Data/Project_6'\n",
    "genome_datasets_dir = project_dir + '/Datasets/NCBI_Datasets'\n",
    "output_dir = project_dir + '/Output'\n",
    "sonic_paranoid_run_name = 'Run_Without_Outgroup'\n",
    "sonic_paranoid_output_loc = output_dir + '/Sonic_Paranoid_Output'\n",
    "ortholog_dir = sonic_paranoid_output_loc + '/runs/' + sonic_paranoid_run_name + '/ortholog_groups'\n",
    "literature_datasets_dir = project_dir + '/Datasets/Data_From_Publications'\n",
    "temp_fileloc = project_dir + '/Temp_Files'\n",
    "reference_species = 'GCF_000195955.2'\n",
    "outgroup_species = 'GCF_000696675.2'\n",
    "NCBIWWW.email = \"nicholas.underhill@sky.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9c0c1-8116-483a-9621-e2937e2da681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_fasta(sequence, name, file):\n",
    "    line_length = 60\n",
    "    lines = []\n",
    "    sequence_length = len(sequence)\n",
    "    number_of_lines = math.ceil(sequence_length / line_length)\n",
    "    lines.append(\">\" + name + \"\\n\")\n",
    "    for i in range(number_of_lines):\n",
    "            subsequence = sequence[i*line_length:(i+1)*line_length]\n",
    "            lines.append(subsequence + \"\\n\")\n",
    "    a = ''.join(lines)\n",
    "    with open(file,'w', newline='') as outfile:\n",
    "        outfile.write(''.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9441be0-b139-451a-91b0-c3cdd6bcdf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "codon_dict = {}\n",
    "with open('D:/Project_Data/Project_3/Datasets/Reference_Tables/Standard_Code.txt') as f:\n",
    "    for l in f:\n",
    "        codon_dict[str(l[1:4])] = l[5]\n",
    "        \n",
    "def translate_sequence(input_seq, strand, rf):\n",
    "    output_seq = ''\n",
    "    if strand == 1:\n",
    "        seq = input_seq[rf:]\n",
    "    else:\n",
    "        seq = align.reverse_complement(input_seq)[rf:]\n",
    "    for i in range(0,len(seq)-2,3):\n",
    "        if seq[i:(i+3)] in codon_dict:\n",
    "            output_seq += codon_dict[seq[i:(i+3)]]\n",
    "        else:\n",
    "            output_seq += 'X'\n",
    "    return output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37ed122-d1e7-4210-9da9-8d2c127471c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = [x for x in util.list_dirs(genome_datasets_dir) if not (x in [reference_species, outgroup_species])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fbd019-5554-4df0-9cba-395f2d4a8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in tqdm(query_list + [reference_species]):\n",
    "    genome_record = next(SeqIO.parse(genome_datasets_dir + '/'+id + '/genomic.gbff', \"genbank\"))\n",
    "    organism_name = genome_record.annotations['organism']\n",
    "    full_sequence = genome_record.seq\n",
    "    write_fasta(str(full_sequence), id, temp_fileloc + '/'+id+'.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807055c-f8de-413c-a78c-e0d08db6055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "    for query_id in tqdm(query_list):\n",
    "        subprocess.run('wsl cd ~; cd mummer4/mummer-4.0.0rc1; promer -p promer '+util.wslname(temp_fileloc + '/'+ reference_species +'.fasta ')+ util.wslname(temp_fileloc + '/'+  query_id +'.fasta ') , shell=True)\n",
    "        temp = subprocess.run('wsl cd ~; cd mummer4/mummer-4.0.0rc1; show-coords -r -k -c -l -L 30 -I 50 -T promer.delta' , shell=True, capture_output=True).stdout.decode('utf-8')\n",
    "        column_names =[ 'S1', 'E1', 'S2', 'E2', 'LEN 1', 'LEN 2', '% IDY', '% SIM', '% STP', 'LEN R', 'LEN Q', 'COV R', 'COV Q', 'FRM_1', 'FRM_2', 'TAGS_1', 'TAGS_2']\n",
    "        temp_df = pd.read_table(StringIO(temp), skiprows=4, index_col=False, header=None, names=column_names)\n",
    "        temp_df.to_csv(project_dir + '/mummer_coords_'+query_id+'_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f85b16-5d93-43a3-816d-96bc670165d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dfs = []\n",
    "for query_id in (query_list):\n",
    "    query_dfs.append(pd.read_csv(project_dir + '/mummer_coords_'+query_id+'_.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef898d5-7b59-4dfa-9fbc-aaa11edbd064",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_species_len = len(next(SeqIO.parse(genome_datasets_dir + '/'+reference_species + '/genomic.gbff', \"genbank\")).seq)\n",
    "reference_protein_dict = {}\n",
    "genome_record = next(SeqIO.parse(genome_datasets_dir + '/'+reference_species + '/genomic.gbff', \"genbank\"))\n",
    "for feature in genome_record.features:\n",
    "        a = feature.qualifiers\n",
    "        if feature.type == 'CDS':\n",
    "            reference_protein_dict[a.get(\"protein_id\")[0]]= a.get(\"locus_tag\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e2c65b-a55d-4464-b5fb-010d1acf98cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conservation_counts = np.zeros(reference_species_len)\n",
    "for df in tqdm(query_dfs):\n",
    "    for i, r in df.iterrows():\n",
    "        if r.FRM_1 > 0:\n",
    "            start = r.S1\n",
    "            end = r.E1\n",
    "        else:\n",
    "            start = r.E1\n",
    "            end = r.S1\n",
    "        for pos in range(start-1, end):\n",
    "            conservation_counts[pos]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968ad4a8-d8a4-40f8-8915-3a0a2732e263",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_cds_boundaries = []\n",
    "mycobrowser_df = pd.read_excel(literature_datasets_dir+'/Mycobrowser_Release_4.xlsx')\n",
    "temp = mycobrowser_df[mycobrowser_df['Feature'] == 'CDS'][['Locus','Start','Stop','Strand']]\n",
    "actual_cds_boundaries = []\n",
    "for i, r in temp.iterrows():\n",
    "    if r['Strand'] == '+':\n",
    "        strand = 1\n",
    "    else:\n",
    "        strand = -1\n",
    "    actual_cds_boundaries.append((r['Locus'],r['Start']-1, r['Stop'], strand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1600e0-eb25-4e0a-adc3-51063d9a2157",
   "metadata": {},
   "outputs": [],
   "source": [
    "orthologs = sar.Ortholog_Grouping(ortholog_dir)\n",
    "all_copy_seq_data = sar.Ortholog_Sequence_Dataset(orthologs, genome_datasets_dir, [x for x in util.list_dirs(genome_datasets_dir)], 50, reference_species, single_copy = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a159912-7ad4-4fbc-92c2-c936d42ba704",
   "metadata": {},
   "outputs": [],
   "source": [
    "for proteinid in all_copy_seq_data.unassigned_genes_dict[reference_species]:\n",
    "    print(proteinid, reference_protein_dict[proteinid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "265135f3-5877-4b40-935a-9c2a31949568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9072c82e79e4a1a9339949008413262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "E_VALUE_THRESH = 0.04\n",
    "tb_seq = str(next(SeqIO.parse(genome_datasets_dir + '/'+reference_species + '/genomic.gbff', \"genbank\")).seq)\n",
    "blast_results_list = []\n",
    "for i in tqdm(range(len(actual_cds_boundaries)):\n",
    "    locus_tag = actual_cds_boundaries[i][0]\n",
    "    start = actual_cds_boundaries[i][1]\n",
    "    end = actual_cds_boundaries[i][2]\n",
    "    strand = actual_cds_boundaries[i][3]\n",
    "    temp=translate_sequence(tb_seq[start:end],strand,0)\n",
    "    result_handle = NCBIWWW.qblast(\"blastp\", \"nr\", temp[:-1], entrez_query= \"all [filter] NOT(txid77643[ORGN]) AND txid85007[ORGN]\")\n",
    "    blast_record = NCBIXML.read(result_handle)\n",
    "    for alignment in blast_record.alignments:\n",
    "        for hsp in alignment.hsps:\n",
    "            if hsp.expect < E_VALUE_THRESH:\n",
    "                 blast_results_list.append([locus_tag, start, end, strand, alignment.title, alignment.accession, alignment.length, hsp.expect, hsp.identities, hsp.query_start, hsp.query_end, hsp.sbjct_start, hsp.sbjct_end, hsp.strand, hsp.score])\n",
    "blast_results_TB_genes_df = pd.DataFrame(blast_results_list, columns = [['locus_tag','locus_start','locus_end','locus_strand','title', 'accession', 'length', 'e_value', 'identities', 'query_start', 'query_end', 'subject_start','subject_end','subject_strand', 'score']])\n",
    "blast_results_TB_genes_df.to_csv(project_dir + '/blast_results_TB_genes_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b8a1aa-6772-480a-8d36-6031d1a369cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp[temp.locus_tag == 'Rv3121']\n",
    "group_id = temp_df.iloc[0]['group_id']\n",
    "temp[temp.group_id == group_id]\n",
    "\n",
    "temp = all_copy_seq_data.sequence_data\n",
    "for i in actual_cds_boundaries:\n",
    "    temp_df = temp[temp.locus_tag == i[0]]\n",
    "    if len(temp_df) > 0:\n",
    "        group_id = temp_df.iloc[0]['group_id']\n",
    "        num_orthologs = len(temp[temp.group_id == group_id]) -1\n",
    "    else:\n",
    "        num_orthologs = 0\n",
    "    print(i[0], i[1], i[2], statistics.mean(conservation_counts[i[1]:i[2]]), num_orthologs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2bd52-c388-4ad4-8bac-7cf93e4cf4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.Series(conservation_counts)\n",
    "a=(d.rolling(10000).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620672b3-3528-48e0-80db-1b52c8c69961",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [i for i,v in enumerate(a) if v < 0.5]\n",
    "z =[v for i, v in enumerate(temp) if i > 1 and v - temp[i-1] > 1]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e0fbc9-0a6f-4b71-ab42-c29dce810d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a[200:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a86ea5-5f75-47cd-93f9-bb18b25c5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(conservation_counts[1650000: 1713090])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ae482-fc09-4e03-a72d-9e3a5e33e7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24502e42-d268-4d84-ae2e-a35961e201a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf70969-cb19-45b8-a1f7-5710b38015c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4f9c5f3-be71-477a-85e8-bca799956e6d",
   "metadata": {},
   "source": [
    "##### Read alignments output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe06472-4bcc-4f68-add1-f09f42c4616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = subprocess.run('wsl cd ~; cd mummer4/mummer-4.0.0rc1; show-aligns promer.delta '+id_list[0]+' '+ id_list[1] , shell=True, capture_output=True).stdout.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d8359-4291-41d9-a63f-79acdb567117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alignments_from_ids():\n",
    "    alignments = subprocess.run('wsl cd ~; cd mummer4/mummer-4.0.0rc1; show-aligns promer.delta '+id_list[0]+' '+ id_list[1] , shell=True, capture_output=True).stdout.decode('utf-8')\n",
    "    # Note that no sorting is done by default for the output of `show-aligns`, so we _may_ assume\n",
    "    # that the order of the matches is the same as their order of appearance in the deltafile\n",
    "\n",
    "    # \"Beginning delimiter\" of every alignment in the `show-aligns` output\n",
    "    begin_alignment_regex = '-- BEGIN alignment \\[ (?P<ref_direction>[+\\-])1 (?P<ref_start>[0-9]+) - (?P<ref_end>[0-9]+) \\|' + \\\n",
    "    ' (?P<query_direction>[+\\-])1 (?P<query_start>[0-9]+) - (?P<query_end>[0-9]+) \\]\\n\\n'\n",
    "    # \"End delimiter\" of every alignment in the `show-aligns` output\n",
    "    end_alignment_regex = '\\n\\n--\\s+END alignment \\[ [+\\-]1 [0-9]+ - [0-9]+ \\| [+\\-]1 [0-9]+ - [0-9]+ \\]'\n",
    "\n",
    "    # Goal is to capture everything between the begin alignment strings and the end alignment strings\n",
    "    parse_regex = '(?s)'+begin_alignment_regex+'(?P<alignment_string>.*?)'+end_alignment_regex\n",
    "    # FYI:    have to use (?s) at beginning to ensure '.' will also match new lines\n",
    "    # See:    https://stackoverflow.com/questions/42302482/python-find-a-string-between-two-strings-repeatedly#comment116031644_42302556\n",
    "    parsed_alignments = [match.groupdict() for match in re.finditer(parse_regex, alignments)]   \n",
    "\n",
    "    parsed_alignments = pd.DataFrame(parsed_alignments)\n",
    "\n",
    "    return parsed_alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b852b3-8a31-462d-ac71-ed6d57705bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_alignments_from_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1bbc2-f3ff-4f5d-917b-bad883d27d70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
